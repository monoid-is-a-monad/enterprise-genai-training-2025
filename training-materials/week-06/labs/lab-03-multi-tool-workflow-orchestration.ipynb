{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40fb7b84",
   "metadata": {},
   "source": [
    "# Lab 3: Multi-Tool Workflow Orchestration\n",
    "\n",
    "**Duration:** 90-120 minutes  \n",
    "**Level:** Advanced\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "1. Chain multiple tools sequentially with parameter passing\n",
    "2. Execute tools in parallel with dependency management\n",
    "3. Build conditional workflows with branching logic\n",
    "4. Create DAG-based workflows for optimal parallelization\n",
    "5. Implement the saga pattern for error recovery\n",
    "6. Monitor and visualize workflow execution\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e547fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai networkx matplotlib -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6e5eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import asyncio\n",
    "from typing import Dict, List, Any, Optional, Callable, Set\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "print(\"✓ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b484ae8d",
   "metadata": {},
   "source": [
    "## Exercise 1: Sequential Tool Chaining\n",
    "\n",
    "Chain tools together, passing outputs as inputs.\n",
    "\n",
    "**Task:** Build a ToolChain that executes tools in sequence with parameter resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f6cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ToolCall:\n",
    "    \"\"\"A tool call in a chain.\"\"\"\n",
    "    name: str\n",
    "    params: Dict[str, Any]\n",
    "    output_key: str  # Where to store output\n",
    "\n",
    "@dataclass\n",
    "class ChainResult:\n",
    "    \"\"\"Result of chain execution.\"\"\"\n",
    "    success: bool\n",
    "    outputs: Dict[str, Any] = field(default_factory=dict)\n",
    "    errors: List[str] = field(default_factory=list)\n",
    "\n",
    "# TODO: Implement ToolChain\n",
    "class ToolChain:\n",
    "    \"\"\"Execute tools sequentially with parameter passing.\"\"\"\n",
    "    \n",
    "    def __init__(self, tools: Dict[str, Callable]):\n",
    "        # TODO: Store available tools\n",
    "        pass\n",
    "    \n",
    "    def resolve_params(\n",
    "        self,\n",
    "        params: Dict[str, Any],\n",
    "        context: Dict[str, Any]\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Resolve parameters using context.\n",
    "        \n",
    "        Example:\n",
    "            params = {\"location\": \"{city}\", \"units\": \"celsius\"}\n",
    "            context = {\"city\": \"London\"}\n",
    "            -> {\"location\": \"London\", \"units\": \"celsius\"}\n",
    "        \"\"\"\n",
    "        # TODO: Replace {key} with values from context\n",
    "        pass\n",
    "    \n",
    "    def execute(self, chain: List[ToolCall]) -> ChainResult:\n",
    "        \"\"\"Execute chain of tools.\"\"\"\n",
    "        context = {}\n",
    "        \n",
    "        for step in chain:\n",
    "            try:\n",
    "                # TODO: Get tool function\n",
    "                # TODO: Resolve parameters\n",
    "                # TODO: Execute tool\n",
    "                # TODO: Store result in context\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                # TODO: Record error and stop\n",
    "                pass\n",
    "        \n",
    "        # TODO: Return result\n",
    "        pass\n",
    "\n",
    "# Test chaining\n",
    "def get_user(user_id: str) -> dict:\n",
    "    \"\"\"Get user data.\"\"\"\n",
    "    return {\"id\": user_id, \"name\": \"Alice\", \"city\": \"London\"}\n",
    "\n",
    "def get_weather(location: str) -> dict:\n",
    "    \"\"\"Get weather for location.\"\"\"\n",
    "    return {\"location\": location, \"temp\": 15, \"condition\": \"Cloudy\"}\n",
    "\n",
    "def send_notification(user_name: str, message: str) -> dict:\n",
    "    \"\"\"Send notification.\"\"\"\n",
    "    return {\"sent\": True, \"to\": user_name, \"message\": message}\n",
    "\n",
    "tools = {\n",
    "    \"get_user\": get_user,\n",
    "    \"get_weather\": get_weather,\n",
    "    \"send_notification\": send_notification\n",
    "}\n",
    "\n",
    "chain = ToolChain(tools)\n",
    "\n",
    "# Build chain: get user -> get weather -> send notification\n",
    "workflow = [\n",
    "    ToolCall(\n",
    "        name=\"get_user\",\n",
    "        params={\"user_id\": \"123\"},\n",
    "        output_key=\"user\"\n",
    "    ),\n",
    "    ToolCall(\n",
    "        name=\"get_weather\",\n",
    "        params={\"location\": \"{user.city}\"},\n",
    "        output_key=\"weather\"\n",
    "    ),\n",
    "    ToolCall(\n",
    "        name=\"send_notification\",\n",
    "        params={\n",
    "            \"user_name\": \"{user.name}\",\n",
    "            \"message\": \"Weather in {weather.location}: {weather.temp}°C, {weather.condition}\"\n",
    "        },\n",
    "        output_key=\"notification\"\n",
    "    )\n",
    "]\n",
    "\n",
    "result = chain.execute(workflow)\n",
    "print(f\"Success: {result.success}\")\n",
    "print(f\"Outputs: {json.dumps(result.outputs, indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e1df0a",
   "metadata": {},
   "source": [
    "## Exercise 2: Parallel Workflow Execution\n",
    "\n",
    "Execute independent tools in parallel.\n",
    "\n",
    "**Task:** Build a WorkflowExecutor that identifies and runs parallel steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43740528",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class WorkflowStep:\n",
    "    \"\"\"A step in a workflow.\"\"\"\n",
    "    id: str\n",
    "    tool_name: str\n",
    "    params: Dict[str, Any]\n",
    "    depends_on: Set[str] = field(default_factory=set)\n",
    "\n",
    "# TODO: Implement WorkflowExecutor\n",
    "class WorkflowExecutor:\n",
    "    \"\"\"Execute workflows with parallel steps.\"\"\"\n",
    "    \n",
    "    def __init__(self, tools: Dict[str, Callable]):\n",
    "        # TODO: Store tools\n",
    "        pass\n",
    "    \n",
    "    async def execute_step(\n",
    "        self,\n",
    "        step: WorkflowStep,\n",
    "        context: Dict[str, Any]\n",
    "    ) -> Any:\n",
    "        \"\"\"Execute a single step.\"\"\"\n",
    "        # TODO: Get tool\n",
    "        # TODO: Resolve parameters from context\n",
    "        # TODO: Execute (with small delay for demo)\n",
    "        pass\n",
    "    \n",
    "    async def execute_workflow(self, steps: List[WorkflowStep]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute workflow with parallel execution.\"\"\"\n",
    "        context = {}\n",
    "        completed = set()\n",
    "        \n",
    "        while len(completed) < len(steps):\n",
    "            # TODO: Find steps ready to execute (dependencies met)\n",
    "            # TODO: Execute ready steps in parallel\n",
    "            # TODO: Store results in context\n",
    "            # TODO: Mark as completed\n",
    "            pass\n",
    "        \n",
    "        return context\n",
    "\n",
    "# Test parallel execution\n",
    "def fetch_user_profile(user_id: str) -> dict:\n",
    "    \"\"\"Fetch user profile.\"\"\"\n",
    "    time.sleep(1)  # Simulate API call\n",
    "    return {\"id\": user_id, \"name\": \"Alice\"}\n",
    "\n",
    "def fetch_user_orders(user_id: str) -> dict:\n",
    "    \"\"\"Fetch user orders.\"\"\"\n",
    "    time.sleep(1)\n",
    "    return {\"user_id\": user_id, \"orders\": [\"Order1\", \"Order2\"]}\n",
    "\n",
    "def fetch_user_reviews(user_id: str) -> dict:\n",
    "    \"\"\"Fetch user reviews.\"\"\"\n",
    "    time.sleep(1)\n",
    "    return {\"user_id\": user_id, \"reviews\": [\"Review1\"]}\n",
    "\n",
    "def aggregate_user_data(profile: dict, orders: dict, reviews: dict) -> dict:\n",
    "    \"\"\"Aggregate all user data.\"\"\"\n",
    "    return {\n",
    "        \"profile\": profile,\n",
    "        \"order_count\": len(orders[\"orders\"]),\n",
    "        \"review_count\": len(reviews[\"reviews\"])\n",
    "    }\n",
    "\n",
    "tools = {\n",
    "    \"fetch_user_profile\": fetch_user_profile,\n",
    "    \"fetch_user_orders\": fetch_user_orders,\n",
    "    \"fetch_user_reviews\": fetch_user_reviews,\n",
    "    \"aggregate_user_data\": aggregate_user_data\n",
    "}\n",
    "\n",
    "executor = WorkflowExecutor(tools)\n",
    "\n",
    "# Define workflow with parallel steps\n",
    "workflow = [\n",
    "    WorkflowStep(\n",
    "        id=\"profile\",\n",
    "        tool_name=\"fetch_user_profile\",\n",
    "        params={\"user_id\": \"123\"}\n",
    "    ),\n",
    "    WorkflowStep(\n",
    "        id=\"orders\",\n",
    "        tool_name=\"fetch_user_orders\",\n",
    "        params={\"user_id\": \"123\"}\n",
    "    ),\n",
    "    WorkflowStep(\n",
    "        id=\"reviews\",\n",
    "        tool_name=\"fetch_user_reviews\",\n",
    "        params={\"user_id\": \"123\"}\n",
    "    ),\n",
    "    WorkflowStep(\n",
    "        id=\"aggregate\",\n",
    "        tool_name=\"aggregate_user_data\",\n",
    "        params={\n",
    "            \"profile\": \"{profile}\",\n",
    "            \"orders\": \"{orders}\",\n",
    "            \"reviews\": \"{reviews}\"\n",
    "        },\n",
    "        depends_on={\"profile\", \"orders\", \"reviews\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "start = time.time()\n",
    "result = await executor.execute_workflow(workflow)\n",
    "duration = time.time() - start\n",
    "\n",
    "print(f\"Execution time: {duration:.2f}s\")\n",
    "print(f\"Result: {json.dumps(result.get('aggregate'), indent=2)}\")\n",
    "print(f\"\\nExpected: ~2s (parallel) vs ~4s (sequential)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941739d0",
   "metadata": {},
   "source": [
    "## Exercise 3: Conditional Workflows\n",
    "\n",
    "Add branching logic to workflows.\n",
    "\n",
    "**Task:** Build conditional execution based on previous step results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea44786",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Condition:\n",
    "    \"\"\"A condition to evaluate.\"\"\"\n",
    "    key: str  # Context key to check\n",
    "    operator: str  # eq, ne, gt, lt, gte, lte, in\n",
    "    value: Any\n",
    "    \n",
    "    def evaluate(self, context: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Evaluate condition.\"\"\"\n",
    "        # TODO: Get value from context using key\n",
    "        # TODO: Apply operator\n",
    "        pass\n",
    "\n",
    "@dataclass\n",
    "class ConditionalStep:\n",
    "    \"\"\"A workflow step with conditions.\"\"\"\n",
    "    id: str\n",
    "    tool_name: str\n",
    "    params: Dict[str, Any]\n",
    "    conditions: List[Condition] = field(default_factory=list)\n",
    "    depends_on: Set[str] = field(default_factory=set)\n",
    "    \n",
    "    def should_execute(self, context: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Check if all conditions are met.\"\"\"\n",
    "        # TODO: Evaluate all conditions\n",
    "        pass\n",
    "\n",
    "# TODO: Implement ConditionalWorkflowExecutor\n",
    "class ConditionalWorkflowExecutor:\n",
    "    \"\"\"Execute workflows with conditional steps.\"\"\"\n",
    "    \n",
    "    def __init__(self, tools: Dict[str, Callable]):\n",
    "        # TODO: Store tools\n",
    "        pass\n",
    "    \n",
    "    def execute_workflow(self, steps: List[ConditionalStep]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute workflow with conditions.\"\"\"\n",
    "        context = {}\n",
    "        completed = set()\n",
    "        skipped = set()\n",
    "        \n",
    "        for step in steps:\n",
    "            # TODO: Check dependencies are met\n",
    "            # TODO: Check conditions\n",
    "            # TODO: Execute if conditions met, skip otherwise\n",
    "            pass\n",
    "        \n",
    "        context[\"_skipped\"] = list(skipped)\n",
    "        return context\n",
    "\n",
    "# Test conditional execution\n",
    "def check_inventory(product_id: str) -> dict:\n",
    "    \"\"\"Check product inventory.\"\"\"\n",
    "    return {\"product_id\": product_id, \"in_stock\": True, \"quantity\": 5}\n",
    "\n",
    "def calculate_price(product_id: str, quantity: int) -> dict:\n",
    "    \"\"\"Calculate price.\"\"\"\n",
    "    return {\"product_id\": product_id, \"total\": quantity * 10.0}\n",
    "\n",
    "def process_payment(total: float) -> dict:\n",
    "    \"\"\"Process payment.\"\"\"\n",
    "    return {\"payment_id\": \"PAY123\", \"amount\": total, \"status\": \"completed\"}\n",
    "\n",
    "def send_error_notification(product_id: str) -> dict:\n",
    "    \"\"\"Send out of stock notification.\"\"\"\n",
    "    return {\"sent\": True, \"reason\": \"out_of_stock\"}\n",
    "\n",
    "tools = {\n",
    "    \"check_inventory\": check_inventory,\n",
    "    \"calculate_price\": calculate_price,\n",
    "    \"process_payment\": process_payment,\n",
    "    \"send_error_notification\": send_error_notification\n",
    "}\n",
    "\n",
    "executor = ConditionalWorkflowExecutor(tools)\n",
    "\n",
    "# Define conditional workflow\n",
    "workflow = [\n",
    "    ConditionalStep(\n",
    "        id=\"inventory\",\n",
    "        tool_name=\"check_inventory\",\n",
    "        params={\"product_id\": \"PROD123\"}\n",
    "    ),\n",
    "    ConditionalStep(\n",
    "        id=\"price\",\n",
    "        tool_name=\"calculate_price\",\n",
    "        params={\"product_id\": \"PROD123\", \"quantity\": 2},\n",
    "        conditions=[\n",
    "            Condition(key=\"inventory.in_stock\", operator=\"eq\", value=True)\n",
    "        ],\n",
    "        depends_on={\"inventory\"}\n",
    "    ),\n",
    "    ConditionalStep(\n",
    "        id=\"payment\",\n",
    "        tool_name=\"process_payment\",\n",
    "        params={\"total\": \"{price.total}\"},\n",
    "        conditions=[\n",
    "            Condition(key=\"inventory.in_stock\", operator=\"eq\", value=True)\n",
    "        ],\n",
    "        depends_on={\"price\"}\n",
    "    ),\n",
    "    ConditionalStep(\n",
    "        id=\"error_notification\",\n",
    "        tool_name=\"send_error_notification\",\n",
    "        params={\"product_id\": \"PROD123\"},\n",
    "        conditions=[\n",
    "            Condition(key=\"inventory.in_stock\", operator=\"eq\", value=False)\n",
    "        ],\n",
    "        depends_on={\"inventory\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "result = executor.execute_workflow(workflow)\n",
    "print(\"Workflow result:\")\n",
    "print(json.dumps({k: v for k, v in result.items() if not k.startswith(\"_\")}, indent=2))\n",
    "print(f\"\\nSkipped steps: {result['_skipped']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049bbf23",
   "metadata": {},
   "source": [
    "## Exercise 4: DAG Workflows\n",
    "\n",
    "Use directed acyclic graphs for optimal parallelization.\n",
    "\n",
    "**Task:** Build DAG-based workflows using networkx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd84154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement DAGWorkflow\n",
    "class DAGWorkflow:\n",
    "    \"\"\"Workflow represented as a DAG.\"\"\"\n",
    "    \n",
    "    def __init__(self, tools: Dict[str, Callable]):\n",
    "        self.tools = tools\n",
    "        # TODO: Initialize networkx DiGraph\n",
    "        pass\n",
    "    \n",
    "    def add_step(\n",
    "        self,\n",
    "        step_id: str,\n",
    "        tool_name: str,\n",
    "        params: Dict[str, Any]\n",
    "    ):\n",
    "        \"\"\"Add a step to the workflow.\"\"\"\n",
    "        # TODO: Add node with step data\n",
    "        pass\n",
    "    \n",
    "    def add_dependency(self, from_step: str, to_step: str):\n",
    "        \"\"\"Add dependency between steps.\"\"\"\n",
    "        # TODO: Add edge from from_step to to_step\n",
    "        pass\n",
    "    \n",
    "    def validate(self) -> bool:\n",
    "        \"\"\"Check if DAG is valid (no cycles).\"\"\"\n",
    "        # TODO: Use nx.is_directed_acyclic_graph\n",
    "        pass\n",
    "    \n",
    "    def get_execution_order(self) -> List[List[str]]:\n",
    "        \"\"\"\n",
    "        Get execution order grouped by level.\n",
    "        Steps in same level can run in parallel.\n",
    "        \"\"\"\n",
    "        # TODO: Use nx.topological_generations\n",
    "        pass\n",
    "    \n",
    "    async def execute(self) -> Dict[str, Any]:\n",
    "        \"\"\"Execute workflow.\"\"\"\n",
    "        if not self.validate():\n",
    "            raise ValueError(\"Workflow contains cycles\")\n",
    "        \n",
    "        context = {}\n",
    "        execution_order = self.get_execution_order()\n",
    "        \n",
    "        for level in execution_order:\n",
    "            # TODO: Execute all steps in this level in parallel\n",
    "            # TODO: Store results in context\n",
    "            pass\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    def visualize(self):\n",
    "        \"\"\"Visualize the workflow DAG.\"\"\"\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        pos = nx.spring_layout(self.graph)\n",
    "        nx.draw(\n",
    "            self.graph,\n",
    "            pos,\n",
    "            with_labels=True,\n",
    "            node_color='lightblue',\n",
    "            node_size=2000,\n",
    "            font_size=10,\n",
    "            arrows=True\n",
    "        )\n",
    "        plt.title(\"Workflow DAG\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Test DAG workflow\n",
    "def step_a() -> str:\n",
    "    time.sleep(0.5)\n",
    "    return \"A done\"\n",
    "\n",
    "def step_b() -> str:\n",
    "    time.sleep(0.5)\n",
    "    return \"B done\"\n",
    "\n",
    "def step_c(a_result: str) -> str:\n",
    "    time.sleep(0.5)\n",
    "    return f\"C done (after {a_result})\"\n",
    "\n",
    "def step_d(a_result: str, b_result: str) -> str:\n",
    "    time.sleep(0.5)\n",
    "    return f\"D done (after {a_result} and {b_result})\"\n",
    "\n",
    "def step_e(c_result: str, d_result: str) -> str:\n",
    "    time.sleep(0.5)\n",
    "    return f\"E done (after {c_result} and {d_result})\"\n",
    "\n",
    "tools = {\n",
    "    \"step_a\": step_a,\n",
    "    \"step_b\": step_b,\n",
    "    \"step_c\": step_c,\n",
    "    \"step_d\": step_d,\n",
    "    \"step_e\": step_e\n",
    "}\n",
    "\n",
    "workflow = DAGWorkflow(tools)\n",
    "\n",
    "# Build DAG\n",
    "workflow.add_step(\"a\", \"step_a\", {})\n",
    "workflow.add_step(\"b\", \"step_b\", {})\n",
    "workflow.add_step(\"c\", \"step_c\", {\"a_result\": \"{a}\"})\n",
    "workflow.add_step(\"d\", \"step_d\", {\"a_result\": \"{a}\", \"b_result\": \"{b}\"})\n",
    "workflow.add_step(\"e\", \"step_e\", {\"c_result\": \"{c}\", \"d_result\": \"{d}\"})\n",
    "\n",
    "workflow.add_dependency(\"a\", \"c\")\n",
    "workflow.add_dependency(\"a\", \"d\")\n",
    "workflow.add_dependency(\"b\", \"d\")\n",
    "workflow.add_dependency(\"c\", \"e\")\n",
    "workflow.add_dependency(\"d\", \"e\")\n",
    "\n",
    "# Visualize\n",
    "workflow.visualize()\n",
    "\n",
    "# Execute\n",
    "print(\"\\nExecution order:\")\n",
    "for i, level in enumerate(workflow.get_execution_order()):\n",
    "    print(f\"Level {i}: {level} (parallel)\")\n",
    "\n",
    "start = time.time()\n",
    "result = await workflow.execute()\n",
    "duration = time.time() - start\n",
    "\n",
    "print(f\"\\nExecution time: {duration:.2f}s\")\n",
    "print(f\"Expected: ~1.5s (parallel) vs ~2.5s (sequential)\")\n",
    "print(f\"\\nResults: {json.dumps(result, indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbe3442",
   "metadata": {},
   "source": [
    "## Exercise 5: Saga Pattern for Error Recovery\n",
    "\n",
    "Implement compensating transactions for distributed workflows.\n",
    "\n",
    "**Task:** Build a saga executor that can rollback on failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56621ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CompensatingAction:\n",
    "    \"\"\"Action to undo a step.\"\"\"\n",
    "    tool_name: str\n",
    "    params: Dict[str, Any]\n",
    "\n",
    "@dataclass\n",
    "class SagaStep:\n",
    "    \"\"\"Step with compensation.\"\"\"\n",
    "    id: str\n",
    "    tool_name: str\n",
    "    params: Dict[str, Any]\n",
    "    compensation: Optional[CompensatingAction] = None\n",
    "\n",
    "# TODO: Implement SagaWorkflowExecutor\n",
    "class SagaWorkflowExecutor:\n",
    "    \"\"\"Execute workflows with saga pattern.\"\"\"\n",
    "    \n",
    "    def __init__(self, tools: Dict[str, Callable]):\n",
    "        # TODO: Store tools\n",
    "        pass\n",
    "    \n",
    "    def execute_saga(self, steps: List[SagaStep]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute saga workflow.\"\"\"\n",
    "        context = {}\n",
    "        completed_steps = []\n",
    "        \n",
    "        try:\n",
    "            for step in steps:\n",
    "                # TODO: Execute step\n",
    "                # TODO: Store result and completed step\n",
    "                pass\n",
    "            \n",
    "            return {\"success\": True, \"context\": context}\n",
    "            \n",
    "        except Exception as e:\n",
    "            # TODO: Rollback completed steps\n",
    "            # TODO: Return error with rollback info\n",
    "            pass\n",
    "    \n",
    "    def _rollback(self, completed_steps: List[SagaStep], context: Dict[str, Any]):\n",
    "        \"\"\"Execute compensating actions in reverse order.\"\"\"\n",
    "        # TODO: Iterate completed steps in reverse\n",
    "        # TODO: Execute compensating actions\n",
    "        pass\n",
    "\n",
    "# Test saga pattern\n",
    "def reserve_inventory(product_id: str, quantity: int) -> dict:\n",
    "    \"\"\"Reserve inventory.\"\"\"\n",
    "    print(f\"✓ Reserved {quantity} units of {product_id}\")\n",
    "    return {\"reservation_id\": \"RES123\", \"product_id\": product_id, \"quantity\": quantity}\n",
    "\n",
    "def release_inventory(reservation_id: str) -> dict:\n",
    "    \"\"\"Release inventory reservation.\"\"\"\n",
    "    print(f\"↺ Released reservation {reservation_id}\")\n",
    "    return {\"released\": True}\n",
    "\n",
    "def charge_payment(amount: float) -> dict:\n",
    "    \"\"\"Charge payment.\"\"\"\n",
    "    print(f\"✓ Charged ${amount}\")\n",
    "    return {\"payment_id\": \"PAY123\", \"amount\": amount}\n",
    "\n",
    "def refund_payment(payment_id: str) -> dict:\n",
    "    \"\"\"Refund payment.\"\"\"\n",
    "    print(f\"↺ Refunded payment {payment_id}\")\n",
    "    return {\"refunded\": True}\n",
    "\n",
    "def ship_order(order_id: str) -> dict:\n",
    "    \"\"\"Ship order - this will fail for demo.\"\"\"\n",
    "    print(f\"✗ Shipping failed for {order_id}\")\n",
    "    raise Exception(\"Shipping service unavailable\")\n",
    "\n",
    "tools = {\n",
    "    \"reserve_inventory\": reserve_inventory,\n",
    "    \"release_inventory\": release_inventory,\n",
    "    \"charge_payment\": charge_payment,\n",
    "    \"refund_payment\": refund_payment,\n",
    "    \"ship_order\": ship_order\n",
    "}\n",
    "\n",
    "executor = SagaWorkflowExecutor(tools)\n",
    "\n",
    "# Define saga\n",
    "saga = [\n",
    "    SagaStep(\n",
    "        id=\"reserve\",\n",
    "        tool_name=\"reserve_inventory\",\n",
    "        params={\"product_id\": \"PROD123\", \"quantity\": 2},\n",
    "        compensation=CompensatingAction(\n",
    "            tool_name=\"release_inventory\",\n",
    "            params={\"reservation_id\": \"{reserve.reservation_id}\"}\n",
    "        )\n",
    "    ),\n",
    "    SagaStep(\n",
    "        id=\"payment\",\n",
    "        tool_name=\"charge_payment\",\n",
    "        params={\"amount\": 100.0},\n",
    "        compensation=CompensatingAction(\n",
    "            tool_name=\"refund_payment\",\n",
    "            params={\"payment_id\": \"{payment.payment_id}\"}\n",
    "        )\n",
    "    ),\n",
    "    SagaStep(\n",
    "        id=\"shipping\",\n",
    "        tool_name=\"ship_order\",\n",
    "        params={\"order_id\": \"ORD123\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"=== Executing Saga ===\")\n",
    "result = executor.execute_saga(saga)\n",
    "\n",
    "print(f\"\\nSuccess: {result['success']}\")\n",
    "if not result['success']:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "    print(f\"Rolled back: {result['rolled_back']} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb20e188",
   "metadata": {},
   "source": [
    "## Exercise 6: Workflow Monitoring\n",
    "\n",
    "Track and visualize workflow execution.\n",
    "\n",
    "**Task:** Build monitoring for workflow performance and status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286c7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkflowStatus(str, Enum):\n",
    "    PENDING = \"pending\"\n",
    "    RUNNING = \"running\"\n",
    "    COMPLETED = \"completed\"\n",
    "    FAILED = \"failed\"\n",
    "\n",
    "@dataclass\n",
    "class StepExecution:\n",
    "    \"\"\"Record of step execution.\"\"\"\n",
    "    step_id: str\n",
    "    tool_name: str\n",
    "    status: WorkflowStatus\n",
    "    start_time: datetime\n",
    "    end_time: Optional[datetime] = None\n",
    "    duration_ms: Optional[float] = None\n",
    "    error: Optional[str] = None\n",
    "\n",
    "# TODO: Implement WorkflowMonitor\n",
    "class WorkflowMonitor:\n",
    "    \"\"\"Monitor workflow execution.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # TODO: Initialize execution records\n",
    "        pass\n",
    "    \n",
    "    def start_step(self, step_id: str, tool_name: str):\n",
    "        \"\"\"Record step start.\"\"\"\n",
    "        # TODO: Create execution record\n",
    "        pass\n",
    "    \n",
    "    def complete_step(self, step_id: str):\n",
    "        \"\"\"Record step completion.\"\"\"\n",
    "        # TODO: Update execution record\n",
    "        pass\n",
    "    \n",
    "    def fail_step(self, step_id: str, error: str):\n",
    "        \"\"\"Record step failure.\"\"\"\n",
    "        # TODO: Update execution record with error\n",
    "        pass\n",
    "    \n",
    "    def get_workflow_summary(self) -> Dict:\n",
    "        \"\"\"Get workflow execution summary.\"\"\"\n",
    "        # TODO: Calculate total duration\n",
    "        # TODO: Count completed, failed steps\n",
    "        # TODO: Calculate success rate\n",
    "        pass\n",
    "    \n",
    "    def get_step_timeline(self) -> List[Dict]:\n",
    "        \"\"\"Get timeline of step executions.\"\"\"\n",
    "        # TODO: Return sorted execution records\n",
    "        pass\n",
    "    \n",
    "    def visualize_timeline(self):\n",
    "        \"\"\"Visualize execution timeline.\"\"\"\n",
    "        # TODO: Create gantt-style chart\n",
    "        pass\n",
    "\n",
    "# TODO: Add monitoring to workflow executor\n",
    "class MonitoredWorkflowExecutor(WorkflowExecutor):\n",
    "    \"\"\"Workflow executor with monitoring.\"\"\"\n",
    "    \n",
    "    def __init__(self, tools: Dict[str, Callable]):\n",
    "        super().__init__(tools)\n",
    "        self.monitor = WorkflowMonitor()\n",
    "    \n",
    "    async def execute_step(\n",
    "        self,\n",
    "        step: WorkflowStep,\n",
    "        context: Dict[str, Any]\n",
    "    ) -> Any:\n",
    "        \"\"\"Execute step with monitoring.\"\"\"\n",
    "        # TODO: Record start\n",
    "        try:\n",
    "            # TODO: Execute step (use parent class)\n",
    "            result = None\n",
    "            # TODO: Record completion\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            # TODO: Record failure\n",
    "            raise\n",
    "\n",
    "# Test monitoring\n",
    "tools = {\n",
    "    \"fetch_user_profile\": fetch_user_profile,\n",
    "    \"fetch_user_orders\": fetch_user_orders,\n",
    "    \"fetch_user_reviews\": fetch_user_reviews,\n",
    "    \"aggregate_user_data\": aggregate_user_data\n",
    "}\n",
    "\n",
    "executor = MonitoredWorkflowExecutor(tools)\n",
    "\n",
    "workflow = [\n",
    "    WorkflowStep(\n",
    "        id=\"profile\",\n",
    "        tool_name=\"fetch_user_profile\",\n",
    "        params={\"user_id\": \"123\"}\n",
    "    ),\n",
    "    WorkflowStep(\n",
    "        id=\"orders\",\n",
    "        tool_name=\"fetch_user_orders\",\n",
    "        params={\"user_id\": \"123\"}\n",
    "    ),\n",
    "    WorkflowStep(\n",
    "        id=\"reviews\",\n",
    "        tool_name=\"fetch_user_reviews\",\n",
    "        params={\"user_id\": \"123\"}\n",
    "    ),\n",
    "    WorkflowStep(\n",
    "        id=\"aggregate\",\n",
    "        tool_name=\"aggregate_user_data\",\n",
    "        params={\n",
    "            \"profile\": \"{profile}\",\n",
    "            \"orders\": \"{orders}\",\n",
    "            \"reviews\": \"{reviews}\"\n",
    "        },\n",
    "        depends_on={\"profile\", \"orders\", \"reviews\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "result = await executor.execute_workflow(workflow)\n",
    "\n",
    "# Get monitoring data\n",
    "summary = executor.monitor.get_workflow_summary()\n",
    "print(\"\\n=== Workflow Summary ===\")\n",
    "print(json.dumps(summary, indent=2))\n",
    "\n",
    "timeline = executor.monitor.get_step_timeline()\n",
    "print(\"\\n=== Step Timeline ===\")\n",
    "for step in timeline:\n",
    "    print(f\"{step['step_id']}: {step['status']} ({step.get('duration_ms', 0):.0f}ms)\")\n",
    "\n",
    "executor.monitor.visualize_timeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225d2bb",
   "metadata": {},
   "source": [
    "## Bonus Exercise: Dynamic Workflow Generation\n",
    "\n",
    "Use LLM to generate workflows from natural language.\n",
    "\n",
    "**Task:** Build a system that creates workflows from user goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14371311",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicWorkflowBuilder:\n",
    "    \"\"\"Generate workflows using LLM.\"\"\"\n",
    "    \n",
    "    def __init__(self, tools: Dict[str, Callable]):\n",
    "        self.tools = tools\n",
    "        self.client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    def generate_workflow(self, goal: str) -> List[WorkflowStep]:\n",
    "        \"\"\"Generate workflow from goal.\"\"\"\n",
    "        # Build tool descriptions\n",
    "        tool_descriptions = \"\\n\".join([\n",
    "            f\"- {name}: {func.__doc__ or 'No description'}\"\n",
    "            for name, func in self.tools.items()\n",
    "        ])\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "Generate a workflow to achieve this goal: {goal}\n",
    "\n",
    "Available tools:\n",
    "{tool_descriptions}\n",
    "\n",
    "Return a JSON array of steps with format:\n",
    "{{\n",
    "  \"id\": \"step_id\",\n",
    "  \"tool_name\": \"tool_name\",\n",
    "  \"params\": {{\"param\": \"value\"}},\n",
    "  \"depends_on\": [\"other_step_id\"]\n",
    "}}\n",
    "\n",
    "Use {{step_id.key}} syntax to reference outputs from previous steps.\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        workflow_json = json.loads(response.choices[0].message.content)\n",
    "        \n",
    "        # Convert to WorkflowStep objects\n",
    "        steps = []\n",
    "        for step_data in workflow_json.get(\"steps\", []):\n",
    "            steps.append(WorkflowStep(\n",
    "                id=step_data[\"id\"],\n",
    "                tool_name=step_data[\"tool_name\"],\n",
    "                params=step_data[\"params\"],\n",
    "                depends_on=set(step_data.get(\"depends_on\", []))\n",
    "            ))\n",
    "        \n",
    "        return steps\n",
    "\n",
    "# Test dynamic workflow generation\n",
    "tools = {\n",
    "    \"get_user\": lambda user_id: {\"id\": user_id, \"name\": \"Alice\", \"email\": \"alice@example.com\"},\n",
    "    \"get_orders\": lambda user_id: {\"orders\": [\"Order1\", \"Order2\"]},\n",
    "    \"calculate_total\": lambda orders: {\"total\": len(orders) * 50.0},\n",
    "    \"send_email\": lambda email, message: {\"sent\": True, \"to\": email}\n",
    "}\n",
    "\n",
    "builder = DynamicWorkflowBuilder(tools)\n",
    "\n",
    "# Generate workflow from natural language\n",
    "goal = \"Get user's orders, calculate total, and email them a summary\"\n",
    "print(f\"Goal: {goal}\\n\")\n",
    "\n",
    "workflow = builder.generate_workflow(goal)\n",
    "\n",
    "print(\"Generated workflow:\")\n",
    "for step in workflow:\n",
    "    print(f\"- {step.id}: {step.tool_name}({step.params})\")\n",
    "    if step.depends_on:\n",
    "        print(f\"  Depends on: {step.depends_on}\")\n",
    "\n",
    "# Execute generated workflow\n",
    "executor = MonitoredWorkflowExecutor(tools)\n",
    "result = await executor.execute_workflow(workflow)\n",
    "\n",
    "print(\"\\nExecution result:\")\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5ca362",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts Covered\n",
    "\n",
    "1. **Sequential Chaining**: Pass outputs between tools\n",
    "2. **Parallel Execution**: Run independent steps concurrently\n",
    "3. **Conditional Logic**: Branch based on runtime conditions\n",
    "4. **DAG Workflows**: Optimal parallelization with dependency graphs\n",
    "5. **Saga Pattern**: Compensating transactions for error recovery\n",
    "6. **Monitoring**: Track execution performance and status\n",
    "7. **Dynamic Generation**: LLM-powered workflow creation\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "- **State Management**: Persist workflow state for resume capability\n",
    "- **Error Recovery**: Implement retry and fallback strategies\n",
    "- **Timeouts**: Set limits on step and workflow duration\n",
    "- **Cancellation**: Support workflow cancellation\n",
    "- **Observability**: Log all state transitions\n",
    "- **Testing**: Test complex dependency graphs thoroughly\n",
    "- **Validation**: Validate DAG structure before execution\n",
    "- **Resource Limits**: Control concurrent step execution\n",
    "- **Audit Trail**: Track who initiated workflows\n",
    "- **Versioning**: Version workflow definitions\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Study distributed workflow engines (Temporal, Airflow)\n",
    "- Explore workflow patterns in microservices\n",
    "- Learn about saga pattern in distributed systems\n",
    "- Practice with real-world workflow requirements"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
