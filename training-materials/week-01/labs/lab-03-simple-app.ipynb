{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1048cb24",
   "metadata": {},
   "source": [
    "# Lab 3: Building a Simple AI Application\n",
    "\n",
    "**Week 1 - GenAI Introduction & Fundamentals**\n",
    "\n",
    "**Provided by:** ADC ENGINEERING & CONSULTING LTD\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab, you will:\n",
    "- Design and build a complete AI-powered application\n",
    "- Implement a text summarizer with multiple modes\n",
    "- Add robust error handling and retry logic\n",
    "- Implement streaming responses for better UX\n",
    "- Create a command-line interface (CLI)\n",
    "- Add logging and monitoring\n",
    "- Deploy best practices for production-ready code\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Labs 1 and 2\n",
    "- Understanding of Python classes and async programming\n",
    "- Familiarity with command-line applications\n",
    "- OpenAI API key configured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565bb1a5",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai python-dotenv tiktoken rich click --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdbb3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict, Optional, Generator\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from openai import OpenAI, OpenAIError, RateLimitError, APIError\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "from rich.progress import Progress, SpinnerColumn, TextColumn\n",
    "from rich.panel import Panel\n",
    "from rich.table import Table\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# Initialize rich console for beautiful output\n",
    "console = Console()\n",
    "\n",
    "console.print(\"[bold green]✓[/bold green] Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c41c27",
   "metadata": {},
   "source": [
    "## Part 1: Application Architecture\n",
    "\n",
    "Before coding, let's design our text summarizer application with a clear architecture.\n",
    "\n",
    "### Core Components\n",
    "\n",
    "1. **SummarizerEngine**: Core logic for text summarization\n",
    "2. **ConfigManager**: Handle configuration and settings\n",
    "3. **ErrorHandler**: Robust error handling with retries\n",
    "4. **StreamingManager**: Handle streaming responses\n",
    "5. **CLI**: User interface\n",
    "6. **Logger**: Track operations and errors\n",
    "\n",
    "### Features to Implement\n",
    "\n",
    "- Multiple summarization modes (concise, detailed, bullet points)\n",
    "- File input/output support\n",
    "- Streaming for long summaries\n",
    "- Cost estimation\n",
    "- Error handling with exponential backoff\n",
    "- Logging and monitoring\n",
    "- Configuration management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee3584",
   "metadata": {},
   "source": [
    "## Part 2: Configuration Management\n",
    "\n",
    "Start by building a configuration system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a54ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Configuration management for the summarizer application.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config_file: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize configuration.\n",
    "        \n",
    "        Args:\n",
    "            config_file: Path to JSON config file (optional)\n",
    "        \"\"\"\n",
    "        # Default configuration\n",
    "        self.defaults = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"temperature\": 0.3,\n",
    "            \"max_tokens\": 500,\n",
    "            \"max_retries\": 3,\n",
    "            \"retry_delay\": 1,\n",
    "            \"log_level\": \"INFO\",\n",
    "            \"cost_warning_threshold\": 0.10\n",
    "        }\n",
    "        \n",
    "        self.config = self.defaults.copy()\n",
    "        \n",
    "        # Load from file if provided\n",
    "        if config_file and Path(config_file).exists():\n",
    "            self.load_from_file(config_file)\n",
    "    \n",
    "    def load_from_file(self, filepath: str):\n",
    "        \"\"\"Load configuration from JSON file.\"\"\"\n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                file_config = json.load(f)\n",
    "                self.config.update(file_config)\n",
    "            console.print(f\"[green]✓[/green] Configuration loaded from {filepath}\")\n",
    "        except Exception as e:\n",
    "            console.print(f\"[yellow]⚠[/yellow] Could not load config: {e}\")\n",
    "    \n",
    "    def save_to_file(self, filepath: str):\n",
    "        \"\"\"Save current configuration to JSON file.\"\"\"\n",
    "        try:\n",
    "            with open(filepath, 'w') as f:\n",
    "                json.dump(self.config, f, indent=2)\n",
    "            console.print(f\"[green]✓[/green] Configuration saved to {filepath}\")\n",
    "        except Exception as e:\n",
    "            console.print(f\"[red]✗[/red] Could not save config: {e}\")\n",
    "    \n",
    "    def get(self, key: str, default=None):\n",
    "        \"\"\"Get configuration value.\"\"\"\n",
    "        return self.config.get(key, default)\n",
    "    \n",
    "    def set(self, key: str, value):\n",
    "        \"\"\"Set configuration value.\"\"\"\n",
    "        self.config[key] = value\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display current configuration.\"\"\"\n",
    "        table = Table(title=\"Current Configuration\")\n",
    "        table.add_column(\"Setting\", style=\"cyan\")\n",
    "        table.add_column(\"Value\", style=\"green\")\n",
    "        \n",
    "        for key, value in self.config.items():\n",
    "            table.add_row(key, str(value))\n",
    "        \n",
    "        console.print(table)\n",
    "\n",
    "# Test configuration\n",
    "config = Config()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53674d8a",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Enhanced Configuration\n",
    "\n",
    "Add these features to the Config class:\n",
    "1. Environment variable override support\n",
    "2. Validation for configuration values\n",
    "3. Configuration profiles (development, production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4adcd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedConfig(Config):\n",
    "    \"\"\"\n",
    "    Enhanced configuration with validation and profiles.\n",
    "    \n",
    "    TODO: Implement:\n",
    "    1. load_from_env() - Load from environment variables\n",
    "    2. validate() - Validate configuration values\n",
    "    3. load_profile(name) - Load a configuration profile\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config_file: Optional[str] = None, profile: str = \"default\"):\n",
    "        super().__init__(config_file)\n",
    "        self.profile = profile\n",
    "        self.profiles = {\n",
    "            \"development\": {\n",
    "                \"model\": \"gpt-3.5-turbo\",\n",
    "                \"temperature\": 0.5,\n",
    "                \"max_tokens\": 300,\n",
    "                \"log_level\": \"DEBUG\"\n",
    "            },\n",
    "            \"production\": {\n",
    "                \"model\": \"gpt-4\",\n",
    "                \"temperature\": 0.2,\n",
    "                \"max_tokens\": 500,\n",
    "                \"log_level\": \"WARNING\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # TODO: Implement enhanced methods\n",
    "    \n",
    "    pass\n",
    "\n",
    "# Test\n",
    "# config = EnhancedConfig(profile=\"production\")\n",
    "# config.validate()\n",
    "# config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5826468f",
   "metadata": {},
   "source": [
    "## Part 3: Error Handling with Retry Logic\n",
    "\n",
    "Implement robust error handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e219b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorHandler:\n",
    "    \"\"\"\n",
    "    Handle API errors with exponential backoff retry logic.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_retries: int = 3, base_delay: float = 1.0):\n",
    "        \"\"\"\n",
    "        Initialize error handler.\n",
    "        \n",
    "        Args:\n",
    "            max_retries: Maximum number of retry attempts\n",
    "            base_delay: Base delay for exponential backoff (seconds)\n",
    "        \"\"\"\n",
    "        self.max_retries = max_retries\n",
    "        self.base_delay = base_delay\n",
    "        self.retry_count = 0\n",
    "    \n",
    "    def handle_with_retry(self, func, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Execute a function with retry logic.\n",
    "        \n",
    "        Args:\n",
    "            func: Function to execute\n",
    "            *args, **kwargs: Arguments for the function\n",
    "        \n",
    "        Returns:\n",
    "            Function result or raises exception after max retries\n",
    "        \"\"\"\n",
    "        last_exception = None\n",
    "        \n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "                self.retry_count = 0  # Reset on success\n",
    "                return result\n",
    "                \n",
    "            except RateLimitError as e:\n",
    "                last_exception = e\n",
    "                delay = self.base_delay * (2 ** attempt)  # Exponential backoff\n",
    "                \n",
    "                console.print(\n",
    "                    f\"[yellow]⚠[/yellow] Rate limit hit. \"\n",
    "                    f\"Retrying in {delay}s... (Attempt {attempt + 1}/{self.max_retries})\"\n",
    "                )\n",
    "                \n",
    "                time.sleep(delay)\n",
    "                \n",
    "            except APIError as e:\n",
    "                last_exception = e\n",
    "                delay = self.base_delay\n",
    "                \n",
    "                console.print(\n",
    "                    f\"[yellow]⚠[/yellow] API error: {str(e)}. \"\n",
    "                    f\"Retrying in {delay}s... (Attempt {attempt + 1}/{self.max_retries})\"\n",
    "                )\n",
    "                \n",
    "                time.sleep(delay)\n",
    "                \n",
    "            except OpenAIError as e:\n",
    "                last_exception = e\n",
    "                console.print(f\"[red]✗[/red] OpenAI error: {str(e)}\")\n",
    "                break  # Don't retry for other OpenAI errors\n",
    "                \n",
    "            except Exception as e:\n",
    "                last_exception = e\n",
    "                console.print(f\"[red]✗[/red] Unexpected error: {str(e)}\")\n",
    "                break\n",
    "        \n",
    "        # If we get here, all retries failed\n",
    "        raise last_exception\n",
    "\n",
    "# Test error handler\n",
    "error_handler = ErrorHandler(max_retries=3)\n",
    "\n",
    "def test_function():\n",
    "    \"\"\"Simulated function that might fail.\"\"\"\n",
    "    import random\n",
    "    if random.random() < 0.5:\n",
    "        raise APIError(\"Simulated API error\")\n",
    "    return \"Success!\"\n",
    "\n",
    "# Uncomment to test\n",
    "# try:\n",
    "#     result = error_handler.handle_with_retry(test_function)\n",
    "#     console.print(f\"[green]✓[/green] {result}\")\n",
    "# except Exception as e:\n",
    "#     console.print(f\"[red]Failed after retries: {e}[/red]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc07b0e",
   "metadata": {},
   "source": [
    "## Part 4: Core Summarization Engine\n",
    "\n",
    "Build the main summarization engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizerEngine:\n",
    "    \"\"\"\n",
    "    Core text summarization engine.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        \"\"\"\n",
    "        Initialize the summarizer.\n",
    "        \n",
    "        Args:\n",
    "            config: Configuration object\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.error_handler = ErrorHandler(\n",
    "            max_retries=config.get(\"max_retries\", 3),\n",
    "            base_delay=config.get(\"retry_delay\", 1)\n",
    "        )\n",
    "        self.token_counter = tiktoken.encoding_for_model(config.get(\"model\"))\n",
    "    \n",
    "    def count_tokens(self, text: str) -> int:\n",
    "        \"\"\"Count tokens in text.\"\"\"\n",
    "        return len(self.token_counter.encode(text))\n",
    "    \n",
    "    def estimate_cost(self, input_tokens: int, output_tokens: int) -> float:\n",
    "        \"\"\"Estimate cost for the operation.\"\"\"\n",
    "        model = self.config.get(\"model\")\n",
    "        pricing = {\n",
    "            \"gpt-3.5-turbo\": {\"input\": 0.0005, \"output\": 0.0015},\n",
    "            \"gpt-4\": {\"input\": 0.03, \"output\": 0.06}\n",
    "        }\n",
    "        \n",
    "        if model not in pricing:\n",
    "            return 0.0\n",
    "        \n",
    "        input_cost = (input_tokens / 1000) * pricing[model][\"input\"]\n",
    "        output_cost = (output_tokens / 1000) * pricing[model][\"output\"]\n",
    "        \n",
    "        return input_cost + output_cost\n",
    "    \n",
    "    def summarize(\n",
    "        self, \n",
    "        text: str, \n",
    "        mode: str = \"concise\",\n",
    "        custom_instructions: Optional[str] = None\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Summarize text with specified mode.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to summarize\n",
    "            mode: Summarization mode ('concise', 'detailed', 'bullets', 'key_points')\n",
    "            custom_instructions: Optional custom instructions\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with summary, tokens, and cost\n",
    "        \"\"\"\n",
    "        # Define prompts for different modes\n",
    "        mode_prompts = {\n",
    "            \"concise\": \"Provide a concise summary in 2-3 sentences capturing the main points.\",\n",
    "            \"detailed\": \"Provide a detailed summary covering all key points and supporting details.\",\n",
    "            \"bullets\": \"Summarize as bullet points, highlighting key information in order of importance.\",\n",
    "            \"key_points\": \"Extract and list the key points, insights, and conclusions.\",\n",
    "            \"executive\": \"Provide an executive summary suitable for business leadership.\",\n",
    "            \"technical\": \"Provide a technical summary preserving important terminology and concepts.\"\n",
    "        }\n",
    "        \n",
    "        # Build the prompt\n",
    "        if custom_instructions:\n",
    "            instruction = custom_instructions\n",
    "        else:\n",
    "            instruction = mode_prompts.get(mode, mode_prompts[\"concise\"])\n",
    "        \n",
    "        prompt = f\"{instruction}\\n\\nText to summarize:\\n{text}\"\n",
    "        \n",
    "        # Count input tokens\n",
    "        input_tokens = self.count_tokens(prompt)\n",
    "        \n",
    "        # Make API call with error handling\n",
    "        def make_api_call():\n",
    "            return client.chat.completions.create(\n",
    "                model=self.config.get(\"model\"),\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert summarizer. Provide clear, accurate summaries.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=self.config.get(\"temperature\"),\n",
    "                max_tokens=self.config.get(\"max_tokens\")\n",
    "            )\n",
    "        \n",
    "        response = self.error_handler.handle_with_retry(make_api_call)\n",
    "        \n",
    "        # Extract results\n",
    "        summary = response.choices[0].message.content\n",
    "        output_tokens = response.usage.completion_tokens\n",
    "        total_tokens = response.usage.total_tokens\n",
    "        \n",
    "        # Calculate cost\n",
    "        cost = self.estimate_cost(input_tokens, output_tokens)\n",
    "        \n",
    "        return {\n",
    "            \"summary\": summary,\n",
    "            \"mode\": mode,\n",
    "            \"input_tokens\": input_tokens,\n",
    "            \"output_tokens\": output_tokens,\n",
    "            \"total_tokens\": total_tokens,\n",
    "            \"cost\": cost,\n",
    "            \"model\": self.config.get(\"model\")\n",
    "        }\n",
    "    \n",
    "    def summarize_stream(\n",
    "        self,\n",
    "        text: str,\n",
    "        mode: str = \"concise\",\n",
    "        custom_instructions: Optional[str] = None\n",
    "    ) -> Generator[str, None, Dict]:\n",
    "        \"\"\"\n",
    "        Summarize with streaming output.\n",
    "        \n",
    "        Yields:\n",
    "            Chunks of the summary as they're generated\n",
    "        \n",
    "        Returns:\n",
    "            Final metadata dictionary\n",
    "        \"\"\"\n",
    "        # Build prompt (same as non-streaming)\n",
    "        mode_prompts = {\n",
    "            \"concise\": \"Provide a concise summary in 2-3 sentences capturing the main points.\",\n",
    "            \"detailed\": \"Provide a detailed summary covering all key points and supporting details.\",\n",
    "            \"bullets\": \"Summarize as bullet points, highlighting key information.\",\n",
    "            \"key_points\": \"Extract and list the key points, insights, and conclusions.\"\n",
    "        }\n",
    "        \n",
    "        instruction = custom_instructions or mode_prompts.get(mode, mode_prompts[\"concise\"])\n",
    "        prompt = f\"{instruction}\\n\\nText to summarize:\\n{text}\"\n",
    "        \n",
    "        # Count tokens\n",
    "        input_tokens = self.count_tokens(prompt)\n",
    "        \n",
    "        # Make streaming API call\n",
    "        def make_streaming_call():\n",
    "            return client.chat.completions.create(\n",
    "                model=self.config.get(\"model\"),\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert summarizer.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=self.config.get(\"temperature\"),\n",
    "                max_tokens=self.config.get(\"max_tokens\"),\n",
    "                stream=True\n",
    "            )\n",
    "        \n",
    "        stream = self.error_handler.handle_with_retry(make_streaming_call)\n",
    "        \n",
    "        full_summary = \"\"\n",
    "        \n",
    "        for chunk in stream:\n",
    "            if chunk.choices[0].delta.content is not None:\n",
    "                content = chunk.choices[0].delta.content\n",
    "                full_summary += content\n",
    "                yield content\n",
    "        \n",
    "        # Calculate final metrics\n",
    "        output_tokens = self.count_tokens(full_summary)\n",
    "        cost = self.estimate_cost(input_tokens, output_tokens)\n",
    "        \n",
    "        return {\n",
    "            \"summary\": full_summary,\n",
    "            \"mode\": mode,\n",
    "            \"input_tokens\": input_tokens,\n",
    "            \"output_tokens\": output_tokens,\n",
    "            \"total_tokens\": input_tokens + output_tokens,\n",
    "            \"cost\": cost,\n",
    "            \"model\": self.config.get(\"model\")\n",
    "        }\n",
    "\n",
    "# Test the summarizer\n",
    "config = Config()\n",
    "summarizer = SummarizerEngine(config)\n",
    "\n",
    "# Sample text\n",
    "sample_text = \"\"\"\n",
    "Machine learning is a method of data analysis that automates analytical model building. \n",
    "It is a branch of artificial intelligence based on the idea that systems can learn from data, \n",
    "identify patterns and make decisions with minimal human intervention. Machine learning algorithms \n",
    "are trained using large amounts of data and can improve their performance over time as they \n",
    "are exposed to more data. The three main types of machine learning are supervised learning, \n",
    "unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to \n",
    "train algorithms, unsupervised learning finds hidden patterns in unlabeled data, and \n",
    "reinforcement learning trains algorithms through trial and error using a reward system.\n",
    "\"\"\"\n",
    "\n",
    "console.print(\"[bold]Testing Summarizer Engine[/bold]\\n\")\n",
    "\n",
    "# Test different modes\n",
    "for mode in [\"concise\", \"bullets\", \"key_points\"]:\n",
    "    console.print(f\"[cyan]Mode: {mode}[/cyan]\")\n",
    "    result = summarizer.summarize(sample_text, mode=mode)\n",
    "    \n",
    "    console.print(Panel(result[\"summary\"], title=f\"{mode.upper()} Summary\"))\n",
    "    console.print(f\"Tokens: {result['total_tokens']} | Cost: ${result['cost']:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f657d18",
   "metadata": {},
   "source": [
    "### Exercise 4.1: Batch Summarization\n",
    "\n",
    "Implement a method to summarize multiple texts in batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73715db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSummarizer(SummarizerEngine):\n",
    "    \"\"\"\n",
    "    Summarizer with batch processing capabilities.\n",
    "    \n",
    "    TODO: Implement:\n",
    "    1. summarize_batch(texts, mode) - Summarize multiple texts\n",
    "    2. Progress tracking\n",
    "    3. Aggregate cost reporting\n",
    "    4. Error handling for individual items\n",
    "    5. Save results to file\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__(config)\n",
    "        self.batch_results = []\n",
    "    \n",
    "    def summarize_batch(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        mode: str = \"concise\",\n",
    "        show_progress: bool = True\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Summarize multiple texts in batch.\n",
    "        \n",
    "        TODO: Implement with progress bar and error handling\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_batch_report(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Generate report for batch operation.\n",
    "        \n",
    "        TODO: Calculate total tokens, costs, success rate\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "# Test\n",
    "# texts = [\"Text 1...\", \"Text 2...\", \"Text 3...\"]\n",
    "# batch_summarizer = BatchSummarizer(config)\n",
    "# results = batch_summarizer.summarize_batch(texts, mode=\"concise\")\n",
    "# print(batch_summarizer.get_batch_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d98b1",
   "metadata": {},
   "source": [
    "## Part 5: File Operations\n",
    "\n",
    "Add support for reading from and writing to files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5d0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileHandler:\n",
    "    \"\"\"\n",
    "    Handle file input/output operations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.supported_formats = ['.txt', '.md', '.json']\n",
    "    \n",
    "    def read_file(self, filepath: str) -> str:\n",
    "        \"\"\"\n",
    "        Read content from file.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to input file\n",
    "        \n",
    "        Returns:\n",
    "            File content as string\n",
    "        \"\"\"\n",
    "        path = Path(filepath)\n",
    "        \n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"File not found: {filepath}\")\n",
    "        \n",
    "        if path.suffix not in self.supported_formats:\n",
    "            raise ValueError(f\"Unsupported file format: {path.suffix}\")\n",
    "        \n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            console.print(f\"[green]✓[/green] Read {len(content)} characters from {filepath}\")\n",
    "            return content\n",
    "            \n",
    "        except Exception as e:\n",
    "            console.print(f\"[red]✗[/red] Error reading file: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def write_file(self, filepath: str, content: str, metadata: Optional[Dict] = None):\n",
    "        \"\"\"\n",
    "        Write content to file.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to output file\n",
    "            content: Content to write\n",
    "            metadata: Optional metadata to include\n",
    "        \"\"\"\n",
    "        path = Path(filepath)\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            with open(path, 'w', encoding='utf-8') as f:\n",
    "                # Add metadata as comment if provided\n",
    "                if metadata:\n",
    "                    f.write(f\"<!-- Generated: {datetime.now().isoformat()} -->\\n\")\n",
    "                    f.write(f\"<!-- Model: {metadata.get('model', 'N/A')} -->\\n\")\n",
    "                    f.write(f\"<!-- Tokens: {metadata.get('total_tokens', 'N/A')} -->\\n\")\n",
    "                    f.write(f\"<!-- Cost: ${metadata.get('cost', 0):.6f} -->\\n\\n\")\n",
    "                \n",
    "                f.write(content)\n",
    "            \n",
    "            console.print(f\"[green]✓[/green] Wrote summary to {filepath}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            console.print(f\"[red]✗[/red] Error writing file: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def read_json(self, filepath: str) -> Dict:\n",
    "        \"\"\"Read JSON file.\"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    def write_json(self, filepath: str, data: Dict):\n",
    "        \"\"\"Write JSON file.\"\"\"\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "\n",
    "# Test file handler\n",
    "file_handler = FileHandler()\n",
    "\n",
    "# Create a test file\n",
    "test_content = \"\"\"\n",
    "Artificial intelligence is rapidly transforming industries worldwide.\n",
    "From healthcare to finance, AI systems are being deployed to solve complex problems.\n",
    "Machine learning algorithms can analyze vast amounts of data to identify patterns\n",
    "and make predictions that would be impossible for humans to achieve manually.\n",
    "\"\"\"\n",
    "\n",
    "# Write test file\n",
    "test_file = \"test_input.txt\"\n",
    "with open(test_file, 'w') as f:\n",
    "    f.write(test_content)\n",
    "\n",
    "# Read file\n",
    "content = file_handler.read_file(test_file)\n",
    "console.print(f\"Read {len(content)} characters\")\n",
    "\n",
    "# Summarize and save\n",
    "result = summarizer.summarize(content, mode=\"concise\")\n",
    "file_handler.write_file(\"test_output.md\", result[\"summary\"], metadata=result)\n",
    "\n",
    "# Clean up\n",
    "os.remove(test_file)\n",
    "console.print(\"[green]✓[/green] File operations test complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247aef2f",
   "metadata": {},
   "source": [
    "## Part 6: Command-Line Interface\n",
    "\n",
    "Build a user-friendly CLI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2844a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizerCLI:\n",
    "    \"\"\"\n",
    "    Command-line interface for the summarizer.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.config = Config()\n",
    "        self.summarizer = SummarizerEngine(self.config)\n",
    "        self.file_handler = FileHandler()\n",
    "    \n",
    "    def display_welcome(self):\n",
    "        \"\"\"Display welcome message.\"\"\"\n",
    "        console.print(Panel.fit(\n",
    "            \"[bold blue]Text Summarizer AI[/bold blue]\\n\"\n",
    "            \"[dim]Provided by: ADC ENGINEERING & CONSULTING LTD[/dim]\",\n",
    "            border_style=\"blue\"\n",
    "        ))\n",
    "    \n",
    "    def get_text_input(self) -> str:\n",
    "        \"\"\"Get text from user.\"\"\"\n",
    "        console.print(\"\\n[cyan]Enter text to summarize (press Ctrl+D or Ctrl+Z when done):[/cyan]\")\n",
    "        lines = []\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                line = input()\n",
    "                lines.append(line)\n",
    "        except EOFError:\n",
    "            pass\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    def select_mode(self) -> str:\n",
    "        \"\"\"Let user select summarization mode.\"\"\"\n",
    "        modes = [\"concise\", \"detailed\", \"bullets\", \"key_points\", \"executive\", \"technical\"]\n",
    "        \n",
    "        console.print(\"\\n[cyan]Select summarization mode:[/cyan]\")\n",
    "        for i, mode in enumerate(modes, 1):\n",
    "            console.print(f\"  {i}. {mode}\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"\\nEnter number (1-6): \"))\n",
    "                if 1 <= choice <= len(modes):\n",
    "                    return modes[choice - 1]\n",
    "            except (ValueError, EOFError):\n",
    "                pass\n",
    "            console.print(\"[red]Invalid choice. Please try again.[/red]\")\n",
    "    \n",
    "    def summarize_interactive(self):\n",
    "        \"\"\"Interactive summarization.\"\"\"\n",
    "        # Get input source\n",
    "        console.print(\"\\n[cyan]Input source:[/cyan]\")\n",
    "        console.print(\"  1. Enter text directly\")\n",
    "        console.print(\"  2. Read from file\")\n",
    "        \n",
    "        try:\n",
    "            choice = int(input(\"\\nEnter number (1-2): \"))\n",
    "        except (ValueError, EOFError):\n",
    "            console.print(\"[red]Invalid input.[/red]\")\n",
    "            return\n",
    "        \n",
    "        # Get text\n",
    "        if choice == 1:\n",
    "            text = self.get_text_input()\n",
    "        elif choice == 2:\n",
    "            filepath = input(\"Enter file path: \").strip()\n",
    "            try:\n",
    "                text = self.file_handler.read_file(filepath)\n",
    "            except Exception as e:\n",
    "                console.print(f\"[red]Error: {e}[/red]\")\n",
    "                return\n",
    "        else:\n",
    "            console.print(\"[red]Invalid choice.[/red]\")\n",
    "            return\n",
    "        \n",
    "        if not text.strip():\n",
    "            console.print(\"[red]No text provided.[/red]\")\n",
    "            return\n",
    "        \n",
    "        # Select mode\n",
    "        mode = self.select_mode()\n",
    "        \n",
    "        # Summarize with progress indicator\n",
    "        console.print(\"\\n[yellow]Generating summary...[/yellow]\")\n",
    "        \n",
    "        with Progress(\n",
    "            SpinnerColumn(),\n",
    "            TextColumn(\"[progress.description]{task.description}\"),\n",
    "            console=console\n",
    "        ) as progress:\n",
    "            task = progress.add_task(\"Summarizing...\", total=None)\n",
    "            result = self.summarizer.summarize(text, mode=mode)\n",
    "        \n",
    "        # Display result\n",
    "        console.print(\"\\n\")\n",
    "        console.print(Panel(\n",
    "            result[\"summary\"],\n",
    "            title=f\"[bold]{mode.upper()} Summary[/bold]\",\n",
    "            border_style=\"green\"\n",
    "        ))\n",
    "        \n",
    "        # Display metadata\n",
    "        console.print(f\"\\n[dim]Model: {result['model']}[/dim]\")\n",
    "        console.print(f\"[dim]Tokens: {result['total_tokens']} | Cost: ${result['cost']:.6f}[/dim]\")\n",
    "        \n",
    "        # Ask to save\n",
    "        save = input(\"\\nSave summary to file? (y/n): \").strip().lower()\n",
    "        if save == 'y':\n",
    "            output_file = input(\"Enter output filename: \").strip()\n",
    "            if output_file:\n",
    "                self.file_handler.write_file(output_file, result[\"summary\"], metadata=result)\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Run the CLI application.\"\"\"\n",
    "        self.display_welcome()\n",
    "        \n",
    "        while True:\n",
    "            console.print(\"\\n[cyan]Main Menu:[/cyan]\")\n",
    "            console.print(\"  1. Summarize text\")\n",
    "            console.print(\"  2. View configuration\")\n",
    "            console.print(\"  3. Exit\")\n",
    "            \n",
    "            try:\n",
    "                choice = input(\"\\nEnter choice: \").strip()\n",
    "            except EOFError:\n",
    "                break\n",
    "            \n",
    "            if choice == \"1\":\n",
    "                self.summarize_interactive()\n",
    "            elif choice == \"2\":\n",
    "                self.config.display()\n",
    "            elif choice == \"3\":\n",
    "                console.print(\"\\n[green]Thank you for using Text Summarizer AI![/green]\")\n",
    "                break\n",
    "            else:\n",
    "                console.print(\"[red]Invalid choice.[/red]\")\n",
    "\n",
    "# Run the CLI (uncomment to test)\n",
    "# cli = SummarizerCLI()\n",
    "# cli.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e23a2",
   "metadata": {},
   "source": [
    "### Exercise 6.1: Enhanced CLI Features\n",
    "\n",
    "Add these features to the CLI:\n",
    "1. Command-line arguments support (using `click` or `argparse`)\n",
    "2. Batch file processing\n",
    "3. Configuration file support\n",
    "4. History of summaries\n",
    "5. Export to different formats (PDF, JSON, HTML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e825c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement enhanced CLI with click\n",
    "\n",
    "import click\n",
    "\n",
    "@click.group()\n",
    "@click.version_option(version='1.0.0')\n",
    "def cli():\n",
    "    \"\"\"Text Summarizer AI - Command Line Interface\"\"\"\n",
    "    pass\n",
    "\n",
    "@cli.command()\n",
    "@click.argument('input_file', type=click.Path(exists=True))\n",
    "@click.option('--mode', '-m', default='concise', \n",
    "              type=click.Choice(['concise', 'detailed', 'bullets', 'key_points']))\n",
    "@click.option('--output', '-o', type=click.Path(), help='Output file path')\n",
    "@click.option('--stream/--no-stream', default=False, help='Enable streaming output')\n",
    "def summarize(input_file, mode, output, stream):\n",
    "    \"\"\"Summarize text from INPUT_FILE.\"\"\"\n",
    "    # TODO: Implement\n",
    "    pass\n",
    "\n",
    "@cli.command()\n",
    "@click.argument('directory', type=click.Path(exists=True))\n",
    "@click.option('--mode', '-m', default='concise')\n",
    "@click.option('--pattern', '-p', default='*.txt', help='File pattern to match')\n",
    "def batch(directory, mode, pattern):\n",
    "    \"\"\"Batch summarize files in DIRECTORY.\"\"\"\n",
    "    # TODO: Implement\n",
    "    pass\n",
    "\n",
    "@cli.command()\n",
    "def config():\n",
    "    \"\"\"Display current configuration.\"\"\"\n",
    "    # TODO: Implement\n",
    "    pass\n",
    "\n",
    "# Run CLI\n",
    "# if __name__ == '__main__':\n",
    "#     cli()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee473e3",
   "metadata": {},
   "source": [
    "## Part 7: Logging and Monitoring\n",
    "\n",
    "Add comprehensive logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f740cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "class AppLogger:\n",
    "    \"\"\"\n",
    "    Application logger with file and console output.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name: str = \"summarizer\", log_file: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize logger.\n",
    "        \n",
    "        Args:\n",
    "            name: Logger name\n",
    "            log_file: Path to log file (optional)\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(name)\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "        \n",
    "        # Create formatters\n",
    "        detailed_formatter = logging.Formatter(\n",
    "            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "            datefmt='%Y-%m-%d %H:%M:%S'\n",
    "        )\n",
    "        \n",
    "        simple_formatter = logging.Formatter(\n",
    "            '%(levelname)s: %(message)s'\n",
    "        )\n",
    "        \n",
    "        # Console handler\n",
    "        console_handler = logging.StreamHandler()\n",
    "        console_handler.setLevel(logging.INFO)\n",
    "        console_handler.setFormatter(simple_formatter)\n",
    "        self.logger.addHandler(console_handler)\n",
    "        \n",
    "        # File handler (if specified)\n",
    "        if log_file:\n",
    "            file_handler = logging.FileHandler(log_file)\n",
    "            file_handler.setLevel(logging.DEBUG)\n",
    "            file_handler.setFormatter(detailed_formatter)\n",
    "            self.logger.addHandler(file_handler)\n",
    "    \n",
    "    def log_operation(self, operation: str, details: Dict):\n",
    "        \"\"\"Log an operation with details.\"\"\"\n",
    "        self.logger.info(f\"Operation: {operation}\")\n",
    "        self.logger.debug(f\"Details: {json.dumps(details, indent=2)}\")\n",
    "    \n",
    "    def log_error(self, error: Exception, context: str = \"\"):\n",
    "        \"\"\"Log an error.\"\"\"\n",
    "        self.logger.error(f\"Error in {context}: {str(error)}\", exc_info=True)\n",
    "    \n",
    "    def log_summary(self, result: Dict):\n",
    "        \"\"\"Log a summarization operation.\"\"\"\n",
    "        self.logger.info(\n",
    "            f\"Summary generated - Mode: {result['mode']}, \"\n",
    "            f\"Tokens: {result['total_tokens']}, \"\n",
    "            f\"Cost: ${result['cost']:.6f}\"\n",
    "        )\n",
    "\n",
    "# Test logger\n",
    "logger = AppLogger(\"test_logger\", log_file=\"summarizer.log\")\n",
    "logger.log_operation(\"test_operation\", {\"key\": \"value\"})\n",
    "logger.log_summary({\n",
    "    \"mode\": \"concise\",\n",
    "    \"total_tokens\": 150,\n",
    "    \"cost\": 0.0005\n",
    "})\n",
    "\n",
    "console.print(\"[green]✓[/green] Logging configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b3c695",
   "metadata": {},
   "source": [
    "## Part 8: Complete Application\n",
    "\n",
    "Integrate all components into a production-ready application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSummarizerApp:\n",
    "    \"\"\"\n",
    "    Complete text summarizer application.\n",
    "    Integrates all components: config, summarizer, file handling, logging.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config_file: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the application.\n",
    "        \n",
    "        Args:\n",
    "            config_file: Path to configuration file (optional)\n",
    "        \"\"\"\n",
    "        # Load configuration\n",
    "        self.config = Config(config_file)\n",
    "        \n",
    "        # Initialize components\n",
    "        self.summarizer = SummarizerEngine(self.config)\n",
    "        self.file_handler = FileHandler()\n",
    "        self.logger = AppLogger(\n",
    "            \"summarizer_app\",\n",
    "            log_file=\"summarizer_app.log\"\n",
    "        )\n",
    "        \n",
    "        # Track session statistics\n",
    "        self.session_stats = {\n",
    "            \"summaries_generated\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"total_cost\": 0.0,\n",
    "            \"start_time\": datetime.now()\n",
    "        }\n",
    "        \n",
    "        self.logger.log_operation(\"app_initialized\", {\n",
    "            \"config\": self.config.config,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "    \n",
    "    def summarize_text(\n",
    "        self,\n",
    "        text: str,\n",
    "        mode: str = \"concise\",\n",
    "        stream: bool = False\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Summarize text with full error handling and logging.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if stream:\n",
    "                return self._summarize_stream(text, mode)\n",
    "            else:\n",
    "                return self._summarize_normal(text, mode)\n",
    "        except Exception as e:\n",
    "            self.logger.log_error(e, \"summarize_text\")\n",
    "            raise\n",
    "    \n",
    "    def _summarize_normal(self, text: str, mode: str) -> Dict:\n",
    "        \"\"\"Non-streaming summarization.\"\"\"\n",
    "        result = self.summarizer.summarize(text, mode=mode)\n",
    "        \n",
    "        # Update statistics\n",
    "        self.session_stats[\"summaries_generated\"] += 1\n",
    "        self.session_stats[\"total_tokens\"] += result[\"total_tokens\"]\n",
    "        self.session_stats[\"total_cost\"] += result[\"cost\"]\n",
    "        \n",
    "        # Log operation\n",
    "        self.logger.log_summary(result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _summarize_stream(self, text: str, mode: str) -> Dict:\n",
    "        \"\"\"Streaming summarization.\"\"\"\n",
    "        console.print(\"\\n[bold]Summary:[/bold]\")\n",
    "        console.print(\"-\" * 80)\n",
    "        \n",
    "        metadata = None\n",
    "        for chunk in self.summarizer.summarize_stream(text, mode=mode):\n",
    "            if isinstance(chunk, dict):\n",
    "                metadata = chunk\n",
    "            else:\n",
    "                console.print(chunk, end=\"\", markup=False)\n",
    "        \n",
    "        console.print(\"\\n\" + \"-\" * 80)\n",
    "        \n",
    "        # Update statistics\n",
    "        if metadata:\n",
    "            self.session_stats[\"summaries_generated\"] += 1\n",
    "            self.session_stats[\"total_tokens\"] += metadata[\"total_tokens\"]\n",
    "            self.session_stats[\"total_cost\"] += metadata[\"cost\"]\n",
    "            \n",
    "            self.logger.log_summary(metadata)\n",
    "        \n",
    "        return metadata or {}\n",
    "    \n",
    "    def summarize_file(\n",
    "        self,\n",
    "        input_file: str,\n",
    "        output_file: Optional[str] = None,\n",
    "        mode: str = \"concise\",\n",
    "        stream: bool = False\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Summarize content from file.\n",
    "        \"\"\"\n",
    "        # Read file\n",
    "        text = self.file_handler.read_file(input_file)\n",
    "        \n",
    "        # Summarize\n",
    "        result = self.summarize_text(text, mode=mode, stream=stream)\n",
    "        \n",
    "        # Save if output specified\n",
    "        if output_file:\n",
    "            self.file_handler.write_file(\n",
    "                output_file,\n",
    "                result[\"summary\"],\n",
    "                metadata=result\n",
    "            )\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_session_report(self) -> Dict:\n",
    "        \"\"\"Get session statistics.\"\"\"\n",
    "        duration = datetime.now() - self.session_stats[\"start_time\"]\n",
    "        \n",
    "        return {\n",
    "            **self.session_stats,\n",
    "            \"duration_seconds\": duration.total_seconds(),\n",
    "            \"avg_tokens_per_summary\": (\n",
    "                self.session_stats[\"total_tokens\"] / self.session_stats[\"summaries_generated\"]\n",
    "                if self.session_stats[\"summaries_generated\"] > 0 else 0\n",
    "            ),\n",
    "            \"avg_cost_per_summary\": (\n",
    "                self.session_stats[\"total_cost\"] / self.session_stats[\"summaries_generated\"]\n",
    "                if self.session_stats[\"summaries_generated\"] > 0 else 0\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def display_session_report(self):\n",
    "        \"\"\"Display session statistics.\"\"\"\n",
    "        report = self.get_session_report()\n",
    "        \n",
    "        table = Table(title=\"Session Report\")\n",
    "        table.add_column(\"Metric\", style=\"cyan\")\n",
    "        table.add_column(\"Value\", style=\"green\")\n",
    "        \n",
    "        table.add_row(\"Summaries Generated\", str(report[\"summaries_generated\"]))\n",
    "        table.add_row(\"Total Tokens\", str(report[\"total_tokens\"]))\n",
    "        table.add_row(\"Total Cost\", f\"${report['total_cost']:.6f}\")\n",
    "        table.add_row(\"Session Duration\", f\"{report['duration_seconds']:.1f}s\")\n",
    "        table.add_row(\"Avg Tokens/Summary\", f\"{report['avg_tokens_per_summary']:.0f}\")\n",
    "        table.add_row(\"Avg Cost/Summary\", f\"${report['avg_cost_per_summary']:.6f}\")\n",
    "        \n",
    "        console.print(\"\\n\")\n",
    "        console.print(table)\n",
    "\n",
    "# Test the complete application\n",
    "app = TextSummarizerApp()\n",
    "\n",
    "console.print(\"\\n[bold]Testing Complete Application[/bold]\\n\")\n",
    "\n",
    "# Test text summarization\n",
    "test_text = \"\"\"\n",
    "Cloud computing has revolutionized how businesses deploy and manage their IT infrastructure.\n",
    "Instead of maintaining physical servers, companies can now rent computing resources on-demand\n",
    "from cloud providers like AWS, Azure, and Google Cloud. This shift offers numerous benefits\n",
    "including cost savings, scalability, reliability, and global reach. Organizations can quickly\n",
    "scale resources up or down based on demand, paying only for what they use. Additionally,\n",
    "cloud providers handle infrastructure maintenance, security updates, and disaster recovery,\n",
    "allowing companies to focus on their core business objectives.\n",
    "\"\"\"\n",
    "\n",
    "result = app.summarize_text(test_text, mode=\"bullets\")\n",
    "\n",
    "console.print(Panel(\n",
    "    result[\"summary\"],\n",
    "    title=\"Summary Result\",\n",
    "    border_style=\"green\"\n",
    "))\n",
    "\n",
    "# Display session report\n",
    "app.display_session_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f005c",
   "metadata": {},
   "source": [
    "## Challenge Projects\n",
    "\n",
    "### Challenge 1: Multi-Document Summarizer\n",
    "\n",
    "Build a system that:\n",
    "- Summarizes multiple related documents\n",
    "- Identifies common themes across documents\n",
    "- Generates a unified summary\n",
    "- Creates a comparison matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc2454",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDocumentSummarizer:\n",
    "    \"\"\"\n",
    "    Summarize multiple documents and find common themes.\n",
    "    \n",
    "    TODO: Implement:\n",
    "    1. Load multiple documents\n",
    "    2. Generate individual summaries\n",
    "    3. Extract common themes\n",
    "    4. Create unified summary\n",
    "    5. Generate comparison matrix\n",
    "    6. Visualize relationships\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, app: TextSummarizerApp):\n",
    "        self.app = app\n",
    "        self.documents = []\n",
    "        self.summaries = []\n",
    "    \n",
    "    # TODO: Implement methods\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2598825b",
   "metadata": {},
   "source": [
    "### Challenge 2: Meeting Transcript Summarizer\n",
    "\n",
    "Build a specialized tool for meeting transcripts:\n",
    "- Identify speakers and their main points\n",
    "- Extract action items and decisions\n",
    "- Generate meeting minutes\n",
    "- Create follow-up task list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91306516",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeetingSummarizer:\n",
    "    \"\"\"\n",
    "    Specialized summarizer for meeting transcripts.\n",
    "    \n",
    "    TODO: Implement:\n",
    "    1. Parse transcript with speaker labels\n",
    "    2. Extract key discussion points per speaker\n",
    "    3. Identify action items\n",
    "    4. Generate structured meeting minutes\n",
    "    5. Create task list with assignments\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, app: TextSummarizerApp):\n",
    "        self.app = app\n",
    "    \n",
    "    # TODO: Implement methods\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa5269",
   "metadata": {},
   "source": [
    "### Challenge 3: Research Paper Summarizer\n",
    "\n",
    "Create a tool for academic papers:\n",
    "- Extract abstract, methodology, results, conclusions\n",
    "- Identify key findings and contributions\n",
    "- Generate citation-ready summaries\n",
    "- Compare with related work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bb0559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchPaperSummarizer:\n",
    "    \"\"\"\n",
    "    Specialized summarizer for research papers.\n",
    "    \n",
    "    TODO: Implement:\n",
    "    1. Parse paper structure (abstract, intro, methods, results, conclusion)\n",
    "    2. Extract key findings\n",
    "    3. Identify contributions\n",
    "    4. Generate structured summary\n",
    "    5. Create citation-ready format\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, app: TextSummarizerApp):\n",
    "        self.app = app\n",
    "    \n",
    "    # TODO: Implement methods\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be948540",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you've built a complete, production-ready AI application with:\n",
    "\n",
    "1. ✅ Configuration management\n",
    "2. ✅ Robust error handling with retry logic\n",
    "3. ✅ Core summarization engine with multiple modes\n",
    "4. ✅ File input/output support\n",
    "5. ✅ Command-line interface\n",
    "6. ✅ Logging and monitoring\n",
    "7. ✅ Streaming responses\n",
    "8. ✅ Session statistics tracking\n",
    "\n",
    "### Key Achievements\n",
    "\n",
    "- **Modular Design**: Clean separation of concerns\n",
    "- **Error Resilience**: Comprehensive error handling\n",
    "- **User Experience**: Rich CLI with progress indicators\n",
    "- **Observability**: Logging and statistics\n",
    "- **Production Ready**: Configuration, monitoring, and best practices\n",
    "\n",
    "### Best Practices Demonstrated\n",
    "\n",
    "1. **Configuration Management**: Centralized, file-based configuration\n",
    "2. **Error Handling**: Exponential backoff, graceful degradation\n",
    "3. **Logging**: Structured logging with multiple outputs\n",
    "4. **Code Organization**: Clear class hierarchy and responsibilities\n",
    "5. **User Experience**: Rich visual feedback and streaming\n",
    "6. **Cost Awareness**: Token counting and cost estimation\n",
    "7. **File Operations**: Safe file handling with validation\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Complete the challenge projects\n",
    "2. Add authentication and user management\n",
    "3. Build a web interface (Flask/FastAPI)\n",
    "4. Add database for storing summaries\n",
    "5. Implement caching for repeated requests\n",
    "6. Add support for more file formats\n",
    "7. Deploy to production environment\n",
    "\n",
    "**Congratulations!** You've completed Week 1 and built your first complete AI application!\n",
    "\n",
    "**Provided by:** ADC ENGINEERING & CONSULTING LTD"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
