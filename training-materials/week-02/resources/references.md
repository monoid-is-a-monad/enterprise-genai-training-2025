# References: Prompt Engineering & LLM Basics

Curated, up-to-date references aligned with Week 2 topics.

## Official Guides
- OpenAI Prompt Engineering Guide: https://platform.openai.com/docs/guides/prompt-engineering
- OpenAI Text Generation: https://platform.openai.com/docs/guides/text-generation
- OpenAI JSON/Structured Output: https://platform.openai.com/docs/guides/structured-outputs
- Anthropic Prompting Guide: https://docs.anthropic.com/claude/docs/prompt-engineering
- Cohere Prompting: https://docs.cohere.com/docs/prompting-overview
- Microsoft Azure OpenAI docs: https://learn.microsoft.com/azure/ai-services/openai/

## Patterns & Best Practices
- Prompt Patterns Catalog (Microsoft): https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#prompting-techniques
- LangChain Prompt Templates: https://python.langchain.com/docs/concepts#prompt-templates
- Anthropic: Chain-of-Thought and thinking styles: https://docs.anthropic.com/claude/docs/chain-of-thought
- Prompting for Reliability (Guardrails): https://www.promptingguide.ai/techniques/guardrails
- Structured Outputs with JSON Schema: https://json-schema.org/learn/getting-started-step-by-step

## Tokenization & Pricing
- tiktoken (OpenAI tokenizer): https://github.com/openai/tiktoken
- Tokenizer playground (OpenAI): https://platform.openai.com/tokenizer
- Model pricing & context windows: https://openai.com/api/pricing

## Evaluation & Prompt Testing
- PromptFoo (prompt testing): https://www.promptfoo.dev/
- LangSmith (observability & eval): https://docs.smith.langchain.com/
- DeepEval: https://docs.confident-ai.com/

## Handy Tools
- Regex101: https://regex101.com/
- JSONLint: https://jsonlint.com/
- Mermaid Live Editor (for diagrams): https://mermaid.live/

## Influential Reads
- Sparks of Artificial General Intelligence (emergent abilities): https://arxiv.org/abs/2303.12712
- Self-Consistency Improves CoT: https://arxiv.org/abs/2203.11171
- RARR: Retrieve-then-Read for factuality: https://arxiv.org/abs/2303.17580

Note: Some links reference later-week content (structured outputs, RAG) to show continuity into Weeks 3â€“4.
