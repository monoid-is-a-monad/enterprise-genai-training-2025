{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed90728",
   "metadata": {},
   "source": [
    "# Lab 2: Few-Shot Learning Experiments\n",
    "\n",
    "**Week 2 - Prompt Engineering & LLM Basics**\n",
    "\n",
    "**Provided by:** ADC ENGINEERING & CONSULTING LTD\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab, you will:\n",
    "- Master zero-shot, one-shot, and few-shot learning techniques\n",
    "- Learn when to use each learning paradigm\n",
    "- Design effective few-shot examples\n",
    "- Build few-shot classifiers and extractors\n",
    "- Understand example selection strategies\n",
    "- Implement dynamic few-shot prompting\n",
    "- Measure and optimize few-shot performance\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Lab 1: Basic Prompt Engineering\n",
    "- Understanding of prompt structure\n",
    "- OpenAI API key configured\n",
    "- Python 3.9+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84112247",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fcde08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai python-dotenv tiktoken numpy scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e3df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import random\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "print(\"âœ“ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c934dd46",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Learning Paradigms\n",
    "\n",
    "Let's explore the three main learning paradigms and when to use each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b076cb42",
   "metadata": {},
   "source": [
    "### Zero-Shot Learning\n",
    "\n",
    "No examples provided - the model relies entirely on its pre-training.\n",
    "\n",
    "**Best for:**\n",
    "- Simple, well-defined tasks\n",
    "- Tasks the model has seen during training\n",
    "- When you don't have examples\n",
    "- General knowledge questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab515e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_example():\n",
    "    \"\"\"Demonstrate zero-shot learning.\"\"\"\n",
    "    \n",
    "    tasks = [\n",
    "        {\n",
    "            \"name\": \"Sentiment Analysis\",\n",
    "            \"prompt\": \"Classify the sentiment of this review as positive, negative, or neutral:\\n\\nReview: The product works well but shipping took forever.\\n\\nSentiment:\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Translation\",\n",
    "            \"prompt\": \"Translate to French: 'Good morning, how are you?'\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Question Answering\",\n",
    "            \"prompt\": \"Question: What is the capital of France?\\nAnswer:\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Text Classification\",\n",
    "            \"prompt\": \"Classify this email as 'spam' or 'not spam':\\n\\nEmail: Congratulations! You've won $1,000,000! Click here now!\\n\\nClassification:\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for task in tasks:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": task[\"prompt\"]}],\n",
    "            temperature=0.3,\n",
    "            max_tokens=100\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Task: {task['name']}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Prompt:\\n{task['prompt']}\\n\")\n",
    "        print(f\"Response:\\n{response.choices[0].message.content}\")\n",
    "\n",
    "zero_shot_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0856a2e6",
   "metadata": {},
   "source": [
    "### One-Shot Learning\n",
    "\n",
    "Provide a single example to demonstrate the task.\n",
    "\n",
    "**Best for:**\n",
    "- Tasks where format needs clarification\n",
    "- Showing desired output structure\n",
    "- Simple pattern matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c2fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_shot_example():\n",
    "    \"\"\"Demonstrate one-shot learning.\"\"\"\n",
    "    \n",
    "    # Task: Extract structured information from text\n",
    "    \n",
    "    prompt = \"\"\"\n",
    "    Extract the person's name, age, and occupation from the text.\n",
    "    \n",
    "    Example:\n",
    "    Text: \"John Smith is a 35-year-old software engineer living in Seattle.\"\n",
    "    Output: {\"name\": \"John Smith\", \"age\": 35, \"occupation\": \"software engineer\"}\n",
    "    \n",
    "    Now extract from this text:\n",
    "    Text: \"Maria Garcia, age 28, works as a data scientist.\"\n",
    "    Output:\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    print(\"One-Shot Learning Example:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Prompt:\\n{prompt}\\n\")\n",
    "    print(f\"Response:\\n{response.choices[0].message.content}\")\n",
    "\n",
    "one_shot_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce40f6",
   "metadata": {},
   "source": [
    "### Few-Shot Learning\n",
    "\n",
    "Provide multiple examples (typically 2-10) to establish a pattern.\n",
    "\n",
    "**Best for:**\n",
    "- Complex or ambiguous tasks\n",
    "- Domain-specific requirements\n",
    "- Consistent formatting needs\n",
    "- Tasks with edge cases\n",
    "- Custom classification categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8bd258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_example():\n",
    "    \"\"\"Demonstrate few-shot learning.\"\"\"\n",
    "    \n",
    "    # Task: Classify customer support tickets by priority\n",
    "    \n",
    "    prompt = \"\"\"\n",
    "    Classify customer support tickets as 'high', 'medium', or 'low' priority.\n",
    "    \n",
    "    Examples:\n",
    "    \n",
    "    Ticket: \"The entire application is down and users cannot log in.\"\n",
    "    Priority: high\n",
    "    \n",
    "    Ticket: \"Can you add a dark mode feature?\"\n",
    "    Priority: low\n",
    "    \n",
    "    Ticket: \"Payment processing is slow, taking 30+ seconds.\"\n",
    "    Priority: medium\n",
    "    \n",
    "    Ticket: \"Some users reporting intermittent issues with file uploads.\"\n",
    "    Priority: medium\n",
    "    \n",
    "    Ticket: \"Typo in the footer copyright year.\"\n",
    "    Priority: low\n",
    "    \n",
    "    Now classify:\n",
    "    Ticket: \"Database connection failing, affecting all transactions.\"\n",
    "    Priority:\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    print(\"Few-Shot Learning Example:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Prompt:\\n{prompt}\\n\")\n",
    "    print(f\"Response:\\n{response.choices[0].message.content}\")\n",
    "\n",
    "few_shot_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a786909",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Compare Learning Paradigms\n",
    "\n",
    "For the task of extracting action items from meeting notes, implement all three paradigms and compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc990b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement all three paradigms for extracting action items\n",
    "\n",
    "meeting_note = \"\"\"\n",
    "Team discussed the Q4 roadmap. Sarah will prepare the budget proposal by Friday. \n",
    "John mentioned we need to upgrade the server infrastructure. Mike volunteered to \n",
    "research cloud providers and present options next week. We should schedule a \n",
    "follow-up meeting for December 5th.\n",
    "\"\"\"\n",
    "\n",
    "# Zero-shot version\n",
    "zero_shot_prompt = \"\"\"\n",
    "# TODO: Create a zero-shot prompt to extract action items\n",
    "\"\"\"\n",
    "\n",
    "# One-shot version\n",
    "one_shot_prompt = \"\"\"\n",
    "# TODO: Create a one-shot prompt with one example\n",
    "\"\"\"\n",
    "\n",
    "# Few-shot version\n",
    "few_shot_prompt = \"\"\"\n",
    "# TODO: Create a few-shot prompt with 3-4 examples\n",
    "\"\"\"\n",
    "\n",
    "# Test each version\n",
    "# for name, prompt in [(\"Zero-shot\", zero_shot_prompt), \n",
    "#                       (\"One-shot\", one_shot_prompt), \n",
    "#                       (\"Few-shot\", few_shot_prompt)]:\n",
    "#     if prompt.strip() and not prompt.startswith(\"# TODO\"):\n",
    "#         response = client.chat.completions.create(\n",
    "#             model=\"gpt-3.5-turbo\",\n",
    "#             messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "#             temperature=0.3\n",
    "#         )\n",
    "#         print(f\"\\n{name}:\")\n",
    "#         print(\"=\"*80)\n",
    "#         print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9dc73b",
   "metadata": {},
   "source": [
    "## Part 2: Designing Effective Few-Shot Examples\n",
    "\n",
    "The quality of your examples determines the quality of results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a882116",
   "metadata": {},
   "source": [
    "### Principle 1: Diverse Examples\n",
    "\n",
    "Examples should cover different scenarios and edge cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ded780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_example_diversity():\n",
    "    \"\"\"Compare homogeneous vs diverse examples.\"\"\"\n",
    "    \n",
    "    # Task: Sentiment classification\n",
    "    \n",
    "    # Homogeneous examples (all similar)\n",
    "    homogeneous_prompt = \"\"\"\n",
    "    Classify sentiment as positive, negative, or neutral.\n",
    "    \n",
    "    Examples:\n",
    "    Text: \"Great product!\"\n",
    "    Sentiment: positive\n",
    "    \n",
    "    Text: \"Love it!\"\n",
    "    Sentiment: positive\n",
    "    \n",
    "    Text: \"Amazing quality!\"\n",
    "    Sentiment: positive\n",
    "    \n",
    "    Now classify:\n",
    "    Text: \"It's okay but shipping was slow and packaging damaged.\"\n",
    "    Sentiment:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Diverse examples (varied scenarios)\n",
    "    diverse_prompt = \"\"\"\n",
    "    Classify sentiment as positive, negative, or neutral.\n",
    "    \n",
    "    Examples:\n",
    "    Text: \"Great product, fast shipping!\"\n",
    "    Sentiment: positive\n",
    "    \n",
    "    Text: \"Terrible quality, broke after one use.\"\n",
    "    Sentiment: negative\n",
    "    \n",
    "    Text: \"It works but nothing special.\"\n",
    "    Sentiment: neutral\n",
    "    \n",
    "    Text: \"Good quality but overpriced.\"\n",
    "    Sentiment: neutral\n",
    "    \n",
    "    Text: \"Arrived damaged, disappointed.\"\n",
    "    Sentiment: negative\n",
    "    \n",
    "    Now classify:\n",
    "    Text: \"It's okay but shipping was slow and packaging damaged.\"\n",
    "    Sentiment:\n",
    "    \"\"\"\n",
    "    \n",
    "    for name, prompt in [(\"Homogeneous Examples\", homogeneous_prompt),\n",
    "                         (\"Diverse Examples\", diverse_prompt)]:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Response: {response.choices[0].message.content}\")\n",
    "\n",
    "compare_example_diversity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc90309",
   "metadata": {},
   "source": [
    "### Principle 2: Clear and Consistent Format\n",
    "\n",
    "Examples must follow a consistent structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091747b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_format_consistency():\n",
    "    \"\"\"Test consistent vs inconsistent formatting.\"\"\"\n",
    "    \n",
    "    # Inconsistent format\n",
    "    inconsistent_prompt = \"\"\"\n",
    "    Extract product name and price:\n",
    "    \n",
    "    \"Buy the SuperWidget for $49.99\"\n",
    "    Product: SuperWidget, Price: $49.99\n",
    "    \n",
    "    \"The MegaGadget costs 79 dollars\"\n",
    "    MegaGadget: $79.00\n",
    "    \n",
    "    From: \"Get the UltraDevice now, only $129\"\n",
    "    Output:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Consistent format\n",
    "    consistent_prompt = \"\"\"\n",
    "    Extract product name and price:\n",
    "    \n",
    "    Input: \"Buy the SuperWidget for $49.99\"\n",
    "    Product: SuperWidget\n",
    "    Price: $49.99\n",
    "    \n",
    "    Input: \"The MegaGadget costs 79 dollars\"\n",
    "    Product: MegaGadget\n",
    "    Price: $79.00\n",
    "    \n",
    "    Input: \"Premium bundle at $299.99 includes the ProTool\"\n",
    "    Product: ProTool\n",
    "    Price: $299.99\n",
    "    \n",
    "    Input: \"Get the UltraDevice now, only $129\"\n",
    "    Product:\n",
    "    \"\"\"\n",
    "    \n",
    "    for name, prompt in [(\"Inconsistent\", inconsistent_prompt),\n",
    "                         (\"Consistent\", consistent_prompt)]:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"{name} Format:\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(response.choices[0].message.content)\n",
    "\n",
    "test_format_consistency()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c46f78a",
   "metadata": {},
   "source": [
    "### Principle 3: Representative Examples\n",
    "\n",
    "Examples should match your real use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa4d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_representative_examples():\n",
    "    \"\"\"Test examples that match vs don't match real use case.\"\"\"\n",
    "    \n",
    "    # Real use case: Classifying technical support tickets\n",
    "    real_ticket = \"API returning 503 errors intermittently since morning deployment.\"\n",
    "    \n",
    "    # Non-representative examples (general categories)\n",
    "    non_representative = \"\"\"\n",
    "    Classify ticket category:\n",
    "    \n",
    "    Ticket: \"How do I reset my password?\"\n",
    "    Category: account\n",
    "    \n",
    "    Ticket: \"My payment didn't go through\"\n",
    "    Category: billing\n",
    "    \n",
    "    Ticket: \"The app looks different\"\n",
    "    Category: ui\n",
    "    \n",
    "    Classify:\n",
    "    Ticket: \"API returning 503 errors intermittently since morning deployment.\"\n",
    "    Category:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Representative examples (technical categories)\n",
    "    representative = \"\"\"\n",
    "    Classify technical ticket category:\n",
    "    \n",
    "    Ticket: \"Database queries timing out after 30 seconds\"\n",
    "    Category: performance\n",
    "    \n",
    "    Ticket: \"API returning 503 errors intermittently\"\n",
    "    Category: infrastructure\n",
    "    \n",
    "    Ticket: \"User authentication tokens expiring too quickly\"\n",
    "    Category: security\n",
    "    \n",
    "    Ticket: \"Memory leak in background job processor\"\n",
    "    Category: performance\n",
    "    \n",
    "    Classify:\n",
    "    Ticket: \"API returning 503 errors intermittently since morning deployment.\"\n",
    "    Category:\n",
    "    \"\"\"\n",
    "    \n",
    "    for name, prompt in [(\"Non-Representative\", non_representative),\n",
    "                         (\"Representative\", representative)]:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"{name} Examples:\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(response.choices[0].message.content)\n",
    "\n",
    "test_representative_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f841fe1",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Design Quality Examples\n",
    "\n",
    "Create high-quality few-shot examples for this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55202f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Design quality few-shot examples\n",
    "\n",
    "# Task: Extract structured data from job postings\n",
    "# Extract: job_title, company, location, salary_range, required_experience\n",
    "\n",
    "job_posting = \"\"\"\n",
    "Senior Python Developer - TechCorp - Remote (US only)\n",
    "We're looking for an experienced Python developer with 5+ years of experience.\n",
    "Competitive salary: $120k-$160k depending on experience.\n",
    "Must have Django and PostgreSQL experience.\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Create a few-shot prompt with 3-4 diverse, consistent, representative examples\n",
    "# Consider:\n",
    "# - Different job types (junior, senior, remote, on-site)\n",
    "# - Various salary formats ($X-Y, $X+, negotiable, not specified)\n",
    "# - Different experience requirements\n",
    "# - Consistent JSON output format\n",
    "\n",
    "few_shot_prompt = \"\"\"\n",
    "# TODO: Your few-shot prompt here\n",
    "\"\"\"\n",
    "\n",
    "# Test your prompt\n",
    "# if few_shot_prompt.strip() and not few_shot_prompt.startswith(\"# TODO\"):\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=\"gpt-3.5-turbo\",\n",
    "#         messages=[{\"role\": \"user\", \"content\": few_shot_prompt}],\n",
    "#         temperature=0.3\n",
    "#     )\n",
    "#     print(\"Extracted Data:\")\n",
    "#     print(\"=\"*80)\n",
    "#     print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db5f71",
   "metadata": {},
   "source": [
    "## Part 3: Building Few-Shot Classifiers\n",
    "\n",
    "Create robust classifiers using few-shot learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f503b90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Example:\n",
    "    \"\"\"A training example for few-shot learning.\"\"\"\n",
    "    input_text: str\n",
    "    output_label: str\n",
    "    metadata: Optional[Dict] = None\n",
    "\n",
    "class FewShotClassifier:\n",
    "    \"\"\"\n",
    "    A few-shot learning classifier.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, task_description: str, labels: List[str]):\n",
    "        \"\"\"\n",
    "        Initialize classifier.\n",
    "        \n",
    "        Args:\n",
    "            task_description: Description of the classification task\n",
    "            labels: List of possible labels\n",
    "        \"\"\"\n",
    "        self.task_description = task_description\n",
    "        self.labels = labels\n",
    "        self.examples: List[Example] = []\n",
    "    \n",
    "    def add_example(self, input_text: str, output_label: str, metadata: Optional[Dict] = None):\n",
    "        \"\"\"Add a training example.\"\"\"\n",
    "        if output_label not in self.labels:\n",
    "            raise ValueError(f\"Label {output_label} not in {self.labels}\")\n",
    "        \n",
    "        self.examples.append(Example(input_text, output_label, metadata))\n",
    "    \n",
    "    def add_examples(self, examples: List[Tuple[str, str]]):\n",
    "        \"\"\"Add multiple examples.\"\"\"\n",
    "        for input_text, output_label in examples:\n",
    "            self.add_example(input_text, output_label)\n",
    "    \n",
    "    def build_prompt(self, input_text: str) -> str:\n",
    "        \"\"\"Build the few-shot prompt.\"\"\"\n",
    "        prompt_parts = [\n",
    "            f\"Task: {self.task_description}\",\n",
    "            f\"Labels: {', '.join(self.labels)}\",\n",
    "            \"\",\n",
    "            \"Examples:\",\n",
    "            \"\"\n",
    "        ]\n",
    "        \n",
    "        # Add examples\n",
    "        for example in self.examples:\n",
    "            prompt_parts.append(f\"Input: {example.input_text}\")\n",
    "            prompt_parts.append(f\"Label: {example.output_label}\")\n",
    "            prompt_parts.append(\"\")\n",
    "        \n",
    "        # Add input to classify\n",
    "        prompt_parts.append(\"Now classify:\")\n",
    "        prompt_parts.append(f\"Input: {input_text}\")\n",
    "        prompt_parts.append(\"Label:\")\n",
    "        \n",
    "        return \"\\n\".join(prompt_parts)\n",
    "    \n",
    "    def classify(self, input_text: str, temperature: float = 0.3) -> Dict:\n",
    "        \"\"\"\n",
    "        Classify input text.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with label and confidence\n",
    "        \"\"\"\n",
    "        prompt = self.build_prompt(input_text)\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperature,\n",
    "            max_tokens=50\n",
    "        )\n",
    "        \n",
    "        predicted_label = response.choices[0].message.content.strip()\n",
    "        \n",
    "        return {\n",
    "            \"input\": input_text,\n",
    "            \"label\": predicted_label,\n",
    "            \"prompt\": prompt,\n",
    "            \"tokens\": response.usage.total_tokens\n",
    "        }\n",
    "    \n",
    "    def classify_batch(self, texts: List[str]) -> List[Dict]:\n",
    "        \"\"\"Classify multiple texts.\"\"\"\n",
    "        return [self.classify(text) for text in texts]\n",
    "\n",
    "# Test the classifier\n",
    "classifier = FewShotClassifier(\n",
    "    task_description=\"Classify customer reviews by product category\",\n",
    "    labels=[\"electronics\", \"clothing\", \"books\", \"home\", \"sports\"]\n",
    ")\n",
    "\n",
    "# Add training examples\n",
    "classifier.add_examples([\n",
    "    (\"The headphones have great sound quality and battery life.\", \"electronics\"),\n",
    "    (\"This sweater is soft and fits perfectly.\", \"clothing\"),\n",
    "    (\"Fascinating biography, couldn't put it down.\", \"books\"),\n",
    "    (\"The coffee maker broke after two weeks.\", \"electronics\"),\n",
    "    (\"Perfect yoga mat, great grip and cushioning.\", \"sports\"),\n",
    "    (\"These curtains match my decor beautifully.\", \"home\"),\n",
    "    (\"The thriller kept me guessing until the end.\", \"books\"),\n",
    "    (\"Running shoes are comfortable for long distances.\", \"sports\")\n",
    "])\n",
    "\n",
    "# Test classification\n",
    "test_reviews = [\n",
    "    \"The smartwatch tracks my workouts accurately.\",\n",
    "    \"This cookbook has amazing recipes.\",\n",
    "    \"The throw pillows added perfect color to my couch.\"\n",
    "]\n",
    "\n",
    "print(\"Few-Shot Classifier Results:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for review in test_reviews:\n",
    "    result = classifier.classify(review)\n",
    "    print(f\"\\nReview: {result['input']}\")\n",
    "    print(f\"Category: {result['label']}\")\n",
    "    print(f\"Tokens used: {result['tokens']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a95532",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Build Your Own Classifier\n",
    "\n",
    "Create a classifier for a custom task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d7f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build a custom classifier\n",
    "\n",
    "# Task ideas:\n",
    "# 1. Email priority classifier (urgent, normal, low)\n",
    "# 2. Code language detector (python, javascript, java, etc.)\n",
    "# 3. Writing tone classifier (formal, casual, technical, friendly)\n",
    "# 4. News category classifier (politics, technology, sports, etc.)\n",
    "\n",
    "# Example structure:\n",
    "# my_classifier = FewShotClassifier(\n",
    "#     task_description=\"...\",\n",
    "#     labels=[...]\n",
    "# )\n",
    "# \n",
    "# my_classifier.add_examples([\n",
    "#     (\"...\", \"label1\"),\n",
    "#     (\"...\", \"label2\"),\n",
    "#     ...\n",
    "# ])\n",
    "#\n",
    "# results = my_classifier.classify_batch(test_inputs)\n",
    "# for result in results:\n",
    "#     print(f\"{result['input']}: {result['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4819e54",
   "metadata": {},
   "source": [
    "## Part 4: Few-Shot Information Extraction\n",
    "\n",
    "Extract structured data using few-shot learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb02ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotExtractor:\n",
    "    \"\"\"\n",
    "    Extract structured information using few-shot learning.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, task_description: str, output_schema: Dict):\n",
    "        \"\"\"\n",
    "        Initialize extractor.\n",
    "        \n",
    "        Args:\n",
    "            task_description: What to extract\n",
    "            output_schema: Structure of output (field names and types)\n",
    "        \"\"\"\n",
    "        self.task_description = task_description\n",
    "        self.output_schema = output_schema\n",
    "        self.examples: List[Tuple[str, Dict]] = []\n",
    "    \n",
    "    def add_example(self, input_text: str, output_data: Dict):\n",
    "        \"\"\"Add an extraction example.\"\"\"\n",
    "        self.examples.append((input_text, output_data))\n",
    "    \n",
    "    def build_prompt(self, input_text: str) -> str:\n",
    "        \"\"\"Build extraction prompt.\"\"\"\n",
    "        prompt_parts = [\n",
    "            f\"Task: {self.task_description}\",\n",
    "            f\"Output format: {json.dumps(self.output_schema, indent=2)}\",\n",
    "            \"\",\n",
    "            \"Examples:\",\n",
    "            \"\"\n",
    "        ]\n",
    "        \n",
    "        # Add examples\n",
    "        for example_input, example_output in self.examples:\n",
    "            prompt_parts.append(f\"Input: {example_input}\")\n",
    "            prompt_parts.append(f\"Output: {json.dumps(example_output)}\")\n",
    "            prompt_parts.append(\"\")\n",
    "        \n",
    "        # Add input to extract from\n",
    "        prompt_parts.append(\"Now extract:\")\n",
    "        prompt_parts.append(f\"Input: {input_text}\")\n",
    "        prompt_parts.append(\"Output:\")\n",
    "        \n",
    "        return \"\\n\".join(prompt_parts)\n",
    "    \n",
    "    def extract(self, input_text: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Extract structured data from input.\n",
    "        \n",
    "        Returns:\n",
    "            Extracted data dictionary\n",
    "        \"\"\"\n",
    "        prompt = self.build_prompt(input_text)\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.2,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            extracted_data = json.loads(response.choices[0].message.content)\n",
    "        except json.JSONDecodeError:\n",
    "            # Fallback if response isn't valid JSON\n",
    "            extracted_data = {\"raw_response\": response.choices[0].message.content}\n",
    "        \n",
    "        return {\n",
    "            \"input\": input_text,\n",
    "            \"extracted\": extracted_data,\n",
    "            \"tokens\": response.usage.total_tokens\n",
    "        }\n",
    "\n",
    "# Test the extractor\n",
    "extractor = FewShotExtractor(\n",
    "    task_description=\"Extract event information from text\",\n",
    "    output_schema={\n",
    "        \"event_name\": \"string\",\n",
    "        \"date\": \"string\",\n",
    "        \"time\": \"string\",\n",
    "        \"location\": \"string\",\n",
    "        \"attendees\": \"number or null\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add examples\n",
    "extractor.add_example(\n",
    "    \"Team meeting on Monday, Jan 15 at 2:00 PM in Conference Room B. All 8 team members should attend.\",\n",
    "    {\n",
    "        \"event_name\": \"Team meeting\",\n",
    "        \"date\": \"Monday, Jan 15\",\n",
    "        \"time\": \"2:00 PM\",\n",
    "        \"location\": \"Conference Room B\",\n",
    "        \"attendees\": 8\n",
    "    }\n",
    ")\n",
    "\n",
    "extractor.add_example(\n",
    "    \"Annual company party scheduled for December 20th, 6 PM at the Grand Hotel ballroom.\",\n",
    "    {\n",
    "        \"event_name\": \"Annual company party\",\n",
    "        \"date\": \"December 20th\",\n",
    "        \"time\": \"6 PM\",\n",
    "        \"location\": \"Grand Hotel ballroom\",\n",
    "        \"attendees\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "extractor.add_example(\n",
    "    \"Client presentation next Thursday at 10 AM via Zoom.\",\n",
    "    {\n",
    "        \"event_name\": \"Client presentation\",\n",
    "        \"date\": \"next Thursday\",\n",
    "        \"time\": \"10 AM\",\n",
    "        \"location\": \"Zoom\",\n",
    "        \"attendees\": None\n",
    "    }\n",
    ")\n",
    "\n",
    "# Test extraction\n",
    "test_text = \"Product launch webinar on Friday, Nov 3 at 3:00 PM. Register at company.com/webinar.\"\n",
    "\n",
    "result = extractor.extract(test_text)\n",
    "\n",
    "print(\"Few-Shot Extraction Results:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Input: {result['input']}\")\n",
    "print(f\"Extracted Data:\")\n",
    "print(json.dumps(result['extracted'], indent=2))\n",
    "print(f\"Tokens used: {result['tokens']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fa8a7a",
   "metadata": {},
   "source": [
    "### Exercise 4.1: Build Custom Extractors\n",
    "\n",
    "Create extractors for these scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a4d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build custom extractors\n",
    "\n",
    "# Scenario 1: Resume parser\n",
    "# Extract: name, email, phone, education, experience_years, skills\n",
    "resume_text = \"\"\"\n",
    "John Doe - johndoe@email.com - (555) 123-4567\n",
    "Education: BS Computer Science, MIT (2015)\n",
    "5 years experience in software development\n",
    "Skills: Python, Java, AWS, Docker, Kubernetes\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Create and test resume extractor\n",
    "# resume_extractor = FewShotExtractor(...)\n",
    "# result = resume_extractor.extract(resume_text)\n",
    "\n",
    "\n",
    "# Scenario 2: Recipe parser\n",
    "# Extract: dish_name, prep_time, cook_time, servings, difficulty, main_ingredients\n",
    "recipe_text = \"\"\"\n",
    "Chocolate Chip Cookies\n",
    "Prep: 15 mins, Bake: 12 mins, Makes 24 cookies\n",
    "Easy recipe perfect for beginners\n",
    "Main ingredients: flour, butter, sugar, chocolate chips, eggs\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Create and test recipe extractor\n",
    "# recipe_extractor = FewShotExtractor(...)\n",
    "# result = recipe_extractor.extract(recipe_text)\n",
    "\n",
    "\n",
    "# Scenario 3: Product listing parser\n",
    "# Extract: product_name, price, condition, seller_rating, shipping\n",
    "listing_text = \"\"\"\n",
    "iPhone 13 Pro - $699 - Excellent condition\n",
    "Seller rating: 4.8/5.0 (250 reviews)\n",
    "Free 2-day shipping included\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Create and test product extractor\n",
    "# product_extractor = FewShotExtractor(...)\n",
    "# result = product_extractor.extract(listing_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81b431e",
   "metadata": {},
   "source": [
    "## Part 5: Dynamic Few-Shot Selection\n",
    "\n",
    "Dynamically select the best examples for each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cd644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicFewShotClassifier:\n",
    "    \"\"\"\n",
    "    Classifier that dynamically selects relevant examples.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, task_description: str, labels: List[str], max_examples: int = 5):\n",
    "        \"\"\"\n",
    "        Initialize dynamic classifier.\n",
    "        \n",
    "        Args:\n",
    "            task_description: Classification task description\n",
    "            labels: Possible labels\n",
    "            max_examples: Maximum examples to include in prompt\n",
    "        \"\"\"\n",
    "        self.task_description = task_description\n",
    "        self.labels = labels\n",
    "        self.max_examples = max_examples\n",
    "        self.example_pool: List[Example] = []\n",
    "    \n",
    "    def add_to_pool(self, input_text: str, output_label: str, metadata: Optional[Dict] = None):\n",
    "        \"\"\"Add example to the pool.\"\"\"\n",
    "        self.example_pool.append(Example(input_text, output_label, metadata))\n",
    "    \n",
    "    def select_examples(self, input_text: str, strategy: str = \"random\") -> List[Example]:\n",
    "        \"\"\"\n",
    "        Select relevant examples for the input.\n",
    "        \n",
    "        Args:\n",
    "            input_text: The text to classify\n",
    "            strategy: 'random', 'diverse', or 'similar'\n",
    "        \n",
    "        Returns:\n",
    "            Selected examples\n",
    "        \"\"\"\n",
    "        if strategy == \"random\":\n",
    "            # Random selection\n",
    "            if len(self.example_pool) <= self.max_examples:\n",
    "                return self.example_pool\n",
    "            return random.sample(self.example_pool, self.max_examples)\n",
    "        \n",
    "        elif strategy == \"diverse\":\n",
    "            # Ensure at least one example per label\n",
    "            selected = []\n",
    "            examples_by_label = {}\n",
    "            \n",
    "            # Group by label\n",
    "            for example in self.example_pool:\n",
    "                if example.output_label not in examples_by_label:\n",
    "                    examples_by_label[example.output_label] = []\n",
    "                examples_by_label[example.output_label].append(example)\n",
    "            \n",
    "            # Take one from each label first\n",
    "            for label in self.labels:\n",
    "                if label in examples_by_label and len(selected) < self.max_examples:\n",
    "                    selected.append(random.choice(examples_by_label[label]))\n",
    "            \n",
    "            # Fill remaining slots randomly\n",
    "            remaining = [e for e in self.example_pool if e not in selected]\n",
    "            while len(selected) < self.max_examples and remaining:\n",
    "                selected.append(remaining.pop(random.randint(0, len(remaining) - 1)))\n",
    "            \n",
    "            return selected\n",
    "        \n",
    "        elif strategy == \"similar\":\n",
    "            # TODO: Implement similarity-based selection\n",
    "            # This would use embeddings to find most similar examples\n",
    "            return self.select_examples(input_text, strategy=\"random\")\n",
    "        \n",
    "        return self.example_pool[:self.max_examples]\n",
    "    \n",
    "    def classify(self, input_text: str, strategy: str = \"diverse\") -> Dict:\n",
    "        \"\"\"Classify with dynamically selected examples.\"\"\"\n",
    "        \n",
    "        # Select relevant examples\n",
    "        selected_examples = self.select_examples(input_text, strategy=strategy)\n",
    "        \n",
    "        # Build prompt\n",
    "        prompt_parts = [\n",
    "            f\"Task: {self.task_description}\",\n",
    "            f\"Labels: {', '.join(self.labels)}\",\n",
    "            \"\",\n",
    "            \"Examples:\",\n",
    "            \"\"\n",
    "        ]\n",
    "        \n",
    "        for example in selected_examples:\n",
    "            prompt_parts.append(f\"Input: {example.input_text}\")\n",
    "            prompt_parts.append(f\"Label: {example.output_label}\")\n",
    "            prompt_parts.append(\"\")\n",
    "        \n",
    "        prompt_parts.append(\"Now classify:\")\n",
    "        prompt_parts.append(f\"Input: {input_text}\")\n",
    "        prompt_parts.append(\"Label:\")\n",
    "        \n",
    "        prompt = \"\\n\".join(prompt_parts)\n",
    "        \n",
    "        # Get prediction\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input\": input_text,\n",
    "            \"label\": response.choices[0].message.content.strip(),\n",
    "            \"examples_used\": len(selected_examples),\n",
    "            \"strategy\": strategy\n",
    "        }\n",
    "\n",
    "# Test dynamic selection\n",
    "dynamic_classifier = DynamicFewShotClassifier(\n",
    "    task_description=\"Classify programming questions by topic\",\n",
    "    labels=[\"syntax\", \"algorithm\", \"debugging\", \"design\", \"performance\"],\n",
    "    max_examples=4\n",
    ")\n",
    "\n",
    "# Add large pool of examples\n",
    "examples_pool = [\n",
    "    (\"How do I declare a variable in Python?\", \"syntax\"),\n",
    "    (\"What's the best sorting algorithm for large datasets?\", \"algorithm\"),\n",
    "    (\"Why am I getting a NullPointerException?\", \"debugging\"),\n",
    "    (\"Should I use inheritance or composition?\", \"design\"),\n",
    "    (\"How can I optimize this database query?\", \"performance\"),\n",
    "    (\"What does the += operator do?\", \"syntax\"),\n",
    "    (\"Explain bubble sort algorithm\", \"algorithm\"),\n",
    "    (\"My code runs but gives wrong output\", \"debugging\"),\n",
    "    (\"How to structure a REST API?\", \"design\"),\n",
    "    (\"Why is my app using too much memory?\", \"performance\"),\n",
    "    (\"What are Python decorators?\", \"syntax\"),\n",
    "    (\"Implement binary search in Python\", \"algorithm\"),\n",
    "    (\"Getting 'index out of range' error\", \"debugging\"),\n",
    "    (\"MVC vs MVVM architecture?\", \"design\"),\n",
    "    (\"Reduce API response time\", \"performance\")\n",
    "]\n",
    "\n",
    "for text, label in examples_pool:\n",
    "    dynamic_classifier.add_to_pool(text, label)\n",
    "\n",
    "# Test with different strategies\n",
    "test_question = \"How do I improve query execution time in PostgreSQL?\"\n",
    "\n",
    "print(\"Dynamic Few-Shot Selection:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for strategy in [\"random\", \"diverse\"]:\n",
    "    result = dynamic_classifier.classify(test_question, strategy=strategy)\n",
    "    print(f\"\\nStrategy: {strategy}\")\n",
    "    print(f\"Question: {result['input']}\")\n",
    "    print(f\"Predicted: {result['label']}\")\n",
    "    print(f\"Examples used: {result['examples_used']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae576944",
   "metadata": {},
   "source": [
    "### Exercise 5.1: Implement Similarity-Based Selection\n",
    "\n",
    "Implement example selection based on semantic similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ded6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement similarity-based example selection\n",
    "\n",
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Get embedding for text using OpenAI's embedding model.\n",
    "    \n",
    "    TODO: Implement this function\n",
    "    Hint: Use client.embeddings.create() with model \"text-embedding-ada-002\"\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two vectors.\n",
    "    \n",
    "    TODO: Implement this function\n",
    "    Hint: Use numpy or manual calculation\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def select_similar_examples(\n",
    "    input_text: str,\n",
    "    example_pool: List[Example],\n",
    "    max_examples: int = 5\n",
    ") -> List[Example]:\n",
    "    \"\"\"\n",
    "    Select examples most similar to input text.\n",
    "    \n",
    "    TODO: Implement this function\n",
    "    Steps:\n",
    "    1. Get embedding for input_text\n",
    "    2. Get embeddings for all examples\n",
    "    3. Calculate similarity scores\n",
    "    4. Return top max_examples\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# Test your implementation\n",
    "# test_text = \"How do I optimize my Python code?\"\n",
    "# similar_examples = select_similar_examples(test_text, example_pool, max_examples=3)\n",
    "# for ex in similar_examples:\n",
    "#     print(f\"- {ex.input_text} ({ex.output_label})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150d204",
   "metadata": {},
   "source": [
    "## Part 6: Evaluating Few-Shot Performance\n",
    "\n",
    "Measure and optimize few-shot classifier performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e51e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluate few-shot classifier performance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, classifier):\n",
    "        \"\"\"Initialize with a classifier.\"\"\"\n",
    "        self.classifier = classifier\n",
    "        self.results = []\n",
    "    \n",
    "    def evaluate(self, test_cases: List[Tuple[str, str]]) -> Dict:\n",
    "        \"\"\"\n",
    "        Evaluate classifier on test cases.\n",
    "        \n",
    "        Args:\n",
    "            test_cases: List of (input, expected_label) tuples\n",
    "        \n",
    "        Returns:\n",
    "            Evaluation metrics\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        total = len(test_cases)\n",
    "        total_tokens = 0\n",
    "        \n",
    "        for input_text, expected_label in test_cases:\n",
    "            result = self.classifier.classify(input_text)\n",
    "            predicted_label = result['label']\n",
    "            \n",
    "            is_correct = predicted_label.lower() == expected_label.lower()\n",
    "            if is_correct:\n",
    "                correct += 1\n",
    "            \n",
    "            total_tokens += result.get('tokens', 0)\n",
    "            \n",
    "            self.results.append({\n",
    "                'input': input_text,\n",
    "                'expected': expected_label,\n",
    "                'predicted': predicted_label,\n",
    "                'correct': is_correct\n",
    "            })\n",
    "        \n",
    "        accuracy = correct / total if total > 0 else 0\n",
    "        avg_tokens = total_tokens / total if total > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'correct': correct,\n",
    "            'total': total,\n",
    "            'avg_tokens_per_prediction': avg_tokens,\n",
    "            'total_tokens': total_tokens\n",
    "        }\n",
    "    \n",
    "    def get_confusion_cases(self) -> List[Dict]:\n",
    "        \"\"\"Get incorrectly classified cases.\"\"\"\n",
    "        return [r for r in self.results if not r['correct']]\n",
    "    \n",
    "    def print_report(self, metrics: Dict):\n",
    "        \"\"\"Print evaluation report.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"EVALUATION REPORT\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Accuracy: {metrics['accuracy']*100:.1f}%\")\n",
    "        print(f\"Correct: {metrics['correct']}/{metrics['total']}\")\n",
    "        print(f\"Avg tokens per prediction: {metrics['avg_tokens_per_prediction']:.1f}\")\n",
    "        print(f\"Total tokens used: {metrics['total_tokens']}\")\n",
    "        \n",
    "        # Show misclassified cases\n",
    "        confusion_cases = self.get_confusion_cases()\n",
    "        if confusion_cases:\n",
    "            print(f\"\\nMisclassified cases ({len(confusion_cases)}):\")\n",
    "            for case in confusion_cases:\n",
    "                print(f\"  Input: {case['input'][:60]}...\")\n",
    "                print(f\"  Expected: {case['expected']} | Predicted: {case['predicted']}\")\n",
    "                print()\n",
    "\n",
    "# Create test dataset\n",
    "test_cases = [\n",
    "    (\"This laptop has amazing performance!\", \"electronics\"),\n",
    "    (\"The novel's plot twist was unexpected\", \"books\"),\n",
    "    (\"These running shoes are very comfortable\", \"sports\"),\n",
    "    (\"The blender works great for smoothies\", \"home\"),\n",
    "    (\"This dress fits perfectly\", \"clothing\"),\n",
    "    (\"The tablet screen is crystal clear\", \"electronics\"),\n",
    "    (\"Excellent mystery thriller\", \"books\"),\n",
    "    (\"Yoga mat provides good cushioning\", \"sports\"),\n",
    "]\n",
    "\n",
    "# Evaluate\n",
    "evaluator = FewShotEvaluator(classifier)\n",
    "metrics = evaluator.evaluate(test_cases)\n",
    "evaluator.print_report(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c932c8f1",
   "metadata": {},
   "source": [
    "### Exercise 6.1: Optimize Classifier Performance\n",
    "\n",
    "Improve classifier accuracy through experimentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05fca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Experiment with different configurations to improve accuracy\n",
    "\n",
    "# Ideas to try:\n",
    "# 1. Add more diverse examples\n",
    "# 2. Improve example quality (clearer, more representative)\n",
    "# 3. Adjust number of examples (3 vs 5 vs 10)\n",
    "# 4. Try different temperature values\n",
    "# 5. Improve prompt formatting\n",
    "# 6. Add instruction clarity\n",
    "\n",
    "# Create baseline\n",
    "# baseline_classifier = FewShotClassifier(...)\n",
    "# baseline_evaluator = FewShotEvaluator(baseline_classifier)\n",
    "# baseline_metrics = baseline_evaluator.evaluate(test_cases)\n",
    "\n",
    "# Create improved version\n",
    "# improved_classifier = FewShotClassifier(...)\n",
    "# improved_evaluator = FewShotEvaluator(improved_classifier)\n",
    "# improved_metrics = improved_evaluator.evaluate(test_cases)\n",
    "\n",
    "# Compare\n",
    "# print(\"Baseline Accuracy:\", baseline_metrics['accuracy'])\n",
    "# print(\"Improved Accuracy:\", improved_metrics['accuracy'])\n",
    "# print(\"Improvement:\", (improved_metrics['accuracy'] - baseline_metrics['accuracy']) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf23f17e",
   "metadata": {},
   "source": [
    "## Challenge Projects\n",
    "\n",
    "### Challenge 1: Multi-Label Few-Shot Classifier\n",
    "\n",
    "Build a classifier that can assign multiple labels to a single input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77359aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelFewShotClassifier:\n",
    "    \"\"\"\n",
    "    Classify inputs into multiple categories simultaneously.\n",
    "    \n",
    "    TODO: Implement a multi-label classifier where:\n",
    "    1. Each input can have multiple labels\n",
    "    2. Examples show inputs with multiple labels\n",
    "    3. Outputs are formatted as lists\n",
    "    4. Evaluation handles multi-label metrics\n",
    "    \n",
    "    Example use case: Article tagging (technology, tutorial, beginner)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, task_description: str, available_labels: List[str]):\n",
    "        self.task_description = task_description\n",
    "        self.available_labels = available_labels\n",
    "        self.examples = []\n",
    "    \n",
    "    # TODO: Implement methods\n",
    "    \n",
    "    pass\n",
    "\n",
    "# Usage example:\n",
    "# tagger = MultiLabelFewShotClassifier(\n",
    "#     task_description=\"Tag articles with relevant categories\",\n",
    "#     available_labels=[\"technology\", \"tutorial\", \"beginner\", \"advanced\", \"web\", \"mobile\"]\n",
    "# )\n",
    "# tagger.add_example(\n",
    "#     \"Introduction to React hooks for beginners\",\n",
    "#     [\"technology\", \"tutorial\", \"beginner\", \"web\"]\n",
    "# )\n",
    "# result = tagger.classify(\"Build your first iOS app with SwiftUI\")\n",
    "# print(result['labels'])  # ['technology', 'tutorial', 'mobile']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0237973d",
   "metadata": {},
   "source": [
    "### Challenge 2: Few-Shot Chain Classifier\n",
    "\n",
    "Build a classifier that makes decisions in multiple steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b978b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChainedFewShotClassifier:\n",
    "    \"\"\"\n",
    "    Multi-stage classification with few-shot learning.\n",
    "    \n",
    "    TODO: Implement a chained classifier where:\n",
    "    1. First stage classifies into broad categories\n",
    "    2. Second stage classifies into specific subcategories\n",
    "    3. Each stage uses relevant few-shot examples\n",
    "    4. Results are hierarchical\n",
    "    \n",
    "    Example: Email -> Category (work/personal) -> Subcategory (urgent/normal/low)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stages = []\n",
    "    \n",
    "    # TODO: Implement chained classification\n",
    "    \n",
    "    pass\n",
    "\n",
    "# Usage example:\n",
    "# chain = ChainedFewShotClassifier()\n",
    "# chain.add_stage(\"category\", [\"work\", \"personal\", \"spam\"])\n",
    "# chain.add_stage(\"priority\", [\"urgent\", \"normal\", \"low\"])\n",
    "# result = chain.classify(\"Meeting moved to 2 PM today\")\n",
    "# print(result)  # {\"category\": \"work\", \"priority\": \"urgent\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdcda1d",
   "metadata": {},
   "source": [
    "### Challenge 3: Active Learning Few-Shot System\n",
    "\n",
    "Build a system that improves by selecting which examples to add:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActiveLearningFewShot:\n",
    "    \"\"\"\n",
    "    Few-shot system that actively selects examples to add.\n",
    "    \n",
    "    TODO: Implement active learning where:\n",
    "    1. System identifies uncertain predictions\n",
    "    2. Requests labels for uncertain cases\n",
    "    3. Adds them to example pool\n",
    "    4. Improves over time\n",
    "    5. Tracks performance improvements\n",
    "    \n",
    "    Use uncertainty metrics like:\n",
    "    - Prediction confidence\n",
    "    - Similarity to existing examples\n",
    "    - Label distribution balance\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, classifier):\n",
    "        self.classifier = classifier\n",
    "        self.uncertainty_threshold = 0.7\n",
    "        self.performance_history = []\n",
    "    \n",
    "    # TODO: Implement active learning loop\n",
    "    \n",
    "    pass\n",
    "\n",
    "# Usage example:\n",
    "# active_system = ActiveLearningFewShot(classifier)\n",
    "# for text in unlabeled_data:\n",
    "#     if active_system.is_uncertain(text):\n",
    "#         label = get_human_label(text)\n",
    "#         active_system.add_to_pool(text, label)\n",
    "# active_system.show_improvement_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290a161a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you've learned:\n",
    "\n",
    "1. âœ… Three learning paradigms (zero-shot, one-shot, few-shot)\n",
    "2. âœ… When to use each paradigm\n",
    "3. âœ… Principles of effective few-shot examples (diverse, consistent, representative)\n",
    "4. âœ… Building few-shot classifiers and extractors\n",
    "5. âœ… Dynamic example selection strategies\n",
    "6. âœ… Evaluating and optimizing few-shot performance\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Few-shot learning** is powerful for tasks with limited data\n",
    "- **Example quality** matters more than quantity\n",
    "- **Diversity** in examples helps generalization\n",
    "- **Consistency** in formatting is crucial\n",
    "- **Representative examples** improve real-world performance\n",
    "- **Dynamic selection** can improve efficiency\n",
    "- **Evaluation** guides optimization\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Start with zero-shot** - try without examples first\n",
    "2. **Add examples gradually** - see when improvement plateaus\n",
    "3. **Ensure diversity** - cover different scenarios and edge cases\n",
    "4. **Maintain format consistency** - strict structural adherence\n",
    "5. **Use representative examples** - match real use cases\n",
    "6. **Balance label distribution** - equal representation when possible\n",
    "7. **Evaluate systematically** - measure accuracy and tokens\n",
    "8. **Iterate based on errors** - analyze misclassifications\n",
    "\n",
    "### Comparison Matrix\n",
    "\n",
    "| Paradigm | Examples | Best For | Token Cost | Accuracy |\n",
    "|----------|----------|----------|------------|----------|\n",
    "| Zero-shot | 0 | Simple, well-known tasks | Low | Medium |\n",
    "| One-shot | 1 | Format clarification | Medium | Good |\n",
    "| Few-shot | 2-10 | Complex, custom tasks | High | Best |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Complete the challenge projects\n",
    "- Build classifiers for your own use cases\n",
    "- Experiment with example selection strategies\n",
    "- Move on to Lab 3: Chain-of-Thought Implementation\n",
    "\n",
    "**Provided by:** ADC ENGINEERING & CONSULTING LTD"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
