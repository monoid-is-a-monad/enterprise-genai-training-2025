{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a99b4dd",
   "metadata": {},
   "source": [
    "# Week 5 - Lab 3: Query Rewriting & Production RAG Patterns\n",
    "\n",
    "**Duration:** 90-120 minutes  \n",
    "**Level:** Advanced  \n",
    "**Prerequisites:** Week 5 Lessons 3-4, Labs 1-2\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "\n",
    "In this lab, you will:\n",
    "- Implement query rewriting techniques (HyDE, Multi-Query, Step-Back)\n",
    "- Measure impact of query rewriting on recall\n",
    "- Build production-grade RAG with circuit breakers\n",
    "- Implement feature flags for A/B testing\n",
    "- Add structured logging with trace IDs\n",
    "- Create observability dashboard data\n",
    "- Measure SLO compliance (latency, availability)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Lab Outline\n",
    "\n",
    "1. Setup and Baseline RAG\n",
    "2. Exercise 1: HyDE (Hypothetical Document Embeddings)\n",
    "3. Exercise 2: Multi-Query Expansion\n",
    "4. Exercise 3: Step-Back Prompting\n",
    "5. Exercise 4: Query Rewriting Comparison\n",
    "6. Exercise 5: Circuit Breaker Pattern\n",
    "7. Exercise 6: Feature Flags for A/B Testing\n",
    "8. Exercise 7: Structured Logging & Observability\n",
    "9. Bonus Challenge: SLO Monitoring Dashboard\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6155aa65",
   "metadata": {},
   "source": [
    "## 1. Setup and Baseline RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc2ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q openai numpy python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da96529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import uuid\n",
    "import logging\n",
    "import numpy as np\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass, asdict\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Configure structured logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"âœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a186e9a",
   "metadata": {},
   "source": [
    "### Sample Corpus and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample technical documentation corpus\n",
    "CORPUS = [\n",
    "    {\"id\": \"doc1\", \"text\": \"Kubernetes is a container orchestration platform that automates deployment, scaling, and management of containerized applications.\"},\n",
    "    {\"id\": \"doc2\", \"text\": \"Vector databases store embeddings and enable semantic search through similarity calculations like cosine distance.\"},\n",
    "    {\"id\": \"doc3\", \"text\": \"RAG (Retrieval-Augmented Generation) combines information retrieval with language model generation for grounded responses.\"},\n",
    "    {\"id\": \"doc4\", \"text\": \"Circuit breakers prevent cascading failures by failing fast when error rates exceed thresholds.\"},\n",
    "    {\"id\": \"doc5\", \"text\": \"Feature flags enable gradual rollouts and A/B testing by controlling feature availability at runtime.\"},\n",
    "    {\"id\": \"doc6\", \"text\": \"HNSW (Hierarchical Navigable Small World) graphs provide efficient approximate nearest neighbor search.\"},\n",
    "    {\"id\": \"doc7\", \"text\": \"Observability requires collecting logs, metrics, and traces to understand system behavior in production.\"},\n",
    "    {\"id\": \"doc8\", \"text\": \"SLOs (Service Level Objectives) define target reliability metrics like 99.9% availability and p95 latency under 200ms.\"},\n",
    "    {\"id\": \"doc9\", \"text\": \"Query rewriting techniques like HyDE generate hypothetical answers to improve retrieval accuracy.\"},\n",
    "    {\"id\": \"doc10\", \"text\": \"Multi-tenant systems isolate customer data while sharing infrastructure for efficiency.\"},\n",
    "]\n",
    "\n",
    "def get_embedding(text: str, model: str = \"text-embedding-3-small\") -> List[float]:\n",
    "    \"\"\"Get embedding for single text.\"\"\"\n",
    "    response = client.embeddings.create(input=[text.replace(\"\\n\", \" \")], model=model)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def get_embeddings_batch(texts: List[str]) -> np.ndarray:\n",
    "    \"\"\"Get embeddings for multiple texts.\"\"\"\n",
    "    cleaned = [t.replace(\"\\n\", \" \") for t in texts]\n",
    "    response = client.embeddings.create(input=cleaned, model=\"text-embedding-3-small\")\n",
    "    return np.array([item.embedding for item in response.data])\n",
    "\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Calculate cosine similarity.\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# Generate corpus embeddings\n",
    "print(\"Generating corpus embeddings...\")\n",
    "corpus_texts = [doc[\"text\"] for doc in CORPUS]\n",
    "corpus_embeddings = get_embeddings_batch(corpus_texts)\n",
    "print(f\"âœ… Generated {len(corpus_embeddings)} embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bacbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_retrieve(query: str, k: int = 3) -> List[Dict]:\n",
    "    \"\"\"Baseline retrieval: embed query and find top-k by cosine similarity.\"\"\"\n",
    "    query_emb = np.array(get_embedding(query))\n",
    "    \n",
    "    similarities = []\n",
    "    for i, doc_emb in enumerate(corpus_embeddings):\n",
    "        sim = cosine_similarity(query_emb, doc_emb)\n",
    "        similarities.append((i, sim))\n",
    "    \n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return [{**CORPUS[idx], \"score\": score} for idx, score in similarities[:k]]\n",
    "\n",
    "# Test baseline retrieval\n",
    "query = \"How do I scale containerized applications?\"\n",
    "results = simple_retrieve(query, k=3)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Baseline retrieval:\")\n",
    "for doc in results:\n",
    "    print(f\"  {doc['id']}: {doc['score']:.3f} - {doc['text'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5e199f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: HyDE (Hypothetical Document Embeddings)\n",
    "\n",
    "**Task:** Implement HyDE - generate a hypothetical answer, then embed and search.\n",
    "\n",
    "**Concept:** Instead of embedding the question directly, generate what the answer *might* look like, then search with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ba5c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyde_retrieve(query: str, k: int = 3) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    HyDE retrieval: generate hypothetical answer, embed it, retrieve.\n",
    "    \"\"\"\n",
    "    # TODO: Implement HyDE\n",
    "    # 1. Generate hypothetical answer using LLM\n",
    "    # 2. Embed the hypothetical answer\n",
    "    # 3. Retrieve using hypothetical answer embedding\n",
    "    \n",
    "    # Step 1: Generate hypothetical answer\n",
    "    hyde_prompt = f\"\"\"Write a detailed, technical answer to this question:\n",
    "\n",
    "{query}\n",
    "\n",
    "Answer as if you're writing documentation. Be specific and use technical terms.\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": hyde_prompt}],\n",
    "        temperature=0.7,\n",
    "        max_tokens=200,\n",
    "    )\n",
    "    \n",
    "    hypothetical_doc = response.choices[0].message.content\n",
    "    print(f\"Generated hypothetical doc: {hypothetical_doc[:100]}...\\n\")\n",
    "    \n",
    "    # Step 2: Embed hypothetical answer\n",
    "    hyde_emb = np.array(get_embedding(hypothetical_doc))\n",
    "    \n",
    "    # Step 3: Retrieve using HyDE embedding\n",
    "    similarities = []\n",
    "    for i, doc_emb in enumerate(corpus_embeddings):\n",
    "        sim = cosine_similarity(hyde_emb, doc_emb)\n",
    "        similarities.append((i, sim))\n",
    "    \n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return [{**CORPUS[idx], \"score\": score} for idx, score in similarities[:k]]\n",
    "\n",
    "\n",
    "# Test HyDE\n",
    "query = \"How do I scale containerized applications?\"\n",
    "hyde_results = hyde_retrieve(query, k=3)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"HyDE retrieval:\")\n",
    "for doc in hyde_results:\n",
    "    print(f\"  {doc['id']}: {doc['score']:.3f} - {doc['text'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37bc7ec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2: Multi-Query Expansion\n",
    "\n",
    "**Task:** Generate multiple query variations, retrieve for each, then merge results.\n",
    "\n",
    "**Concept:** Rephrase the query multiple ways to capture different aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94760d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_query_retrieve(query: str, k: int = 3, n_variations: int = 3) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Multi-query retrieval: generate query variations, retrieve for each, merge.\n",
    "    \"\"\"\n",
    "    # TODO: Implement multi-query expansion\n",
    "    # 1. Generate n_variations of the query\n",
    "    # 2. Retrieve for each variation\n",
    "    # 3. Merge results (deduplicate and aggregate scores)\n",
    "    \n",
    "    # Step 1: Generate query variations\n",
    "    variation_prompt = f\"\"\"Generate {n_variations} different ways to ask this question. Each should capture a different aspect or use different terminology.\n",
    "\n",
    "Original: {query}\n",
    "\n",
    "Return only the {n_variations} variations, one per line, without numbering.\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": variation_prompt}],\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    \n",
    "    variations_text = response.choices[0].message.content\n",
    "    variations = [line.strip() for line in variations_text.strip().split('\\n') if line.strip()]\n",
    "    variations = [query] + variations[:n_variations-1]  # Include original\n",
    "    \n",
    "    print(\"Query variations:\")\n",
    "    for i, var in enumerate(variations, 1):\n",
    "        print(f\"  {i}. {var}\")\n",
    "    print()\n",
    "    \n",
    "    # Step 2: Retrieve for each variation\n",
    "    all_scores = {}\n",
    "    for var in variations:\n",
    "        var_results = simple_retrieve(var, k=k*2)\n",
    "        for doc in var_results:\n",
    "            doc_id = doc[\"id\"]\n",
    "            if doc_id not in all_scores:\n",
    "                all_scores[doc_id] = []\n",
    "            all_scores[doc_id].append(doc[\"score\"])\n",
    "    \n",
    "    # Step 3: Aggregate scores (max score across variations)\n",
    "    aggregated = []\n",
    "    for doc_id, scores in all_scores.items():\n",
    "        aggregated.append({\n",
    "            \"id\": doc_id,\n",
    "            \"score\": max(scores),\n",
    "            \"text\": next(d[\"text\"] for d in CORPUS if d[\"id\"] == doc_id)\n",
    "        })\n",
    "    \n",
    "    aggregated.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    return aggregated[:k]\n",
    "\n",
    "\n",
    "# Test multi-query\n",
    "query = \"How do I scale containerized applications?\"\n",
    "multi_results = multi_query_retrieve(query, k=3, n_variations=3)\n",
    "\n",
    "print(f\"\\nOriginal query: {query}\\n\")\n",
    "print(\"Multi-query retrieval:\")\n",
    "for doc in multi_results:\n",
    "    print(f\"  {doc['id']}: {doc['score']:.3f} - {doc['text'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d4585c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3: Step-Back Prompting\n",
    "\n",
    "**Task:** Generate a higher-level \"step-back\" question, retrieve for it, then use those results.\n",
    "\n",
    "**Concept:** Sometimes a broader question retrieves better foundational context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a39ca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_back_retrieve(query: str, k: int = 3) -> Tuple[str, List[Dict]]:\n",
    "    \"\"\"\n",
    "    Step-back retrieval: generate broader question, retrieve for it.\n",
    "    \n",
    "    Returns:\n",
    "        (step_back_query, results)\n",
    "    \"\"\"\n",
    "    # TODO: Implement step-back prompting\n",
    "    # 1. Generate a broader, more conceptual version of the query\n",
    "    # 2. Retrieve using the step-back query\n",
    "    \n",
    "    # Step 1: Generate step-back query\n",
    "    step_back_prompt = f\"\"\"Given this specific question, generate a broader, more general question that covers the underlying concepts.\n",
    "\n",
    "Specific question: {query}\n",
    "\n",
    "Broader question:\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": step_back_prompt}],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    \n",
    "    step_back_query = response.choices[0].message.content.strip()\n",
    "    print(f\"Original query: {query}\")\n",
    "    print(f\"Step-back query: {step_back_query}\\n\")\n",
    "    \n",
    "    # Step 2: Retrieve using step-back query\n",
    "    results = simple_retrieve(step_back_query, k=k)\n",
    "    \n",
    "    return step_back_query, results\n",
    "\n",
    "\n",
    "# Test step-back\n",
    "query = \"How do I scale containerized applications?\"\n",
    "sb_query, sb_results = step_back_retrieve(query, k=3)\n",
    "\n",
    "print(\"Step-back retrieval:\")\n",
    "for doc in sb_results:\n",
    "    print(f\"  {doc['id']}: {doc['score']:.3f} - {doc['text'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90e92a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4: Query Rewriting Comparison\n",
    "\n",
    "**Task:** Compare all rewriting methods on multiple test queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de3619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries\n",
    "TEST_QUERIES = [\n",
    "    \"How do I scale containerized applications?\",\n",
    "    \"What is semantic search?\",\n",
    "    \"How to prevent cascading failures?\",\n",
    "]\n",
    "\n",
    "def compare_rewriting_methods(queries: List[str]):\n",
    "    \"\"\"Compare different query rewriting approaches.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Query: {query}\")\n",
    "        print('='*60)\n",
    "        \n",
    "        # Baseline\n",
    "        print(\"\\n1. Baseline (direct embedding):\")\n",
    "        baseline = simple_retrieve(query, k=3)\n",
    "        for doc in baseline:\n",
    "            print(f\"   {doc['id']}: {doc['score']:.3f}\")\n",
    "        \n",
    "        # HyDE\n",
    "        print(\"\\n2. HyDE:\")\n",
    "        hyde = hyde_retrieve(query, k=3)\n",
    "        for doc in hyde:\n",
    "            print(f\"   {doc['id']}: {doc['score']:.3f}\")\n",
    "        \n",
    "        # Multi-query\n",
    "        print(\"\\n3. Multi-query:\")\n",
    "        multi = multi_query_retrieve(query, k=3, n_variations=3)\n",
    "        for doc in multi:\n",
    "            print(f\"   {doc['id']}: {doc['score']:.3f}\")\n",
    "        \n",
    "        # Step-back\n",
    "        print(\"\\n4. Step-back:\")\n",
    "        sb_q, sb = step_back_retrieve(query, k=3)\n",
    "        for doc in sb:\n",
    "            print(f\"   {doc['id']}: {doc['score']:.3f}\")\n",
    "        \n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"baseline\": [d[\"id\"] for d in baseline],\n",
    "            \"hyde\": [d[\"id\"] for d in hyde],\n",
    "            \"multi_query\": [d[\"id\"] for d in multi],\n",
    "            \"step_back\": [d[\"id\"] for d in sb],\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Run comparison\n",
    "comparison_results = compare_rewriting_methods(TEST_QUERIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd04940",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 5: Circuit Breaker Pattern\n",
    "\n",
    "**Task:** Implement a circuit breaker to protect against cascading failures.\n",
    "\n",
    "**States:**\n",
    "- CLOSED: Normal operation\n",
    "- OPEN: Failing fast, rejecting requests\n",
    "- HALF_OPEN: Testing if service recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e6427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Any\n",
    "\n",
    "class CircuitState(Enum):\n",
    "    CLOSED = \"closed\"\n",
    "    OPEN = \"open\"\n",
    "    HALF_OPEN = \"half_open\"\n",
    "\n",
    "@dataclass\n",
    "class CircuitBreakerConfig:\n",
    "    failure_threshold: int = 5\n",
    "    timeout_seconds: float = 60.0\n",
    "    half_open_max_calls: int = 3\n",
    "\n",
    "class CircuitBreaker:\n",
    "    \"\"\"\n",
    "    Circuit breaker implementation.\n",
    "    \"\"\"\n",
    "    def __init__(self, config: CircuitBreakerConfig = None):\n",
    "        self.config = config or CircuitBreakerConfig()\n",
    "        self.state = CircuitState.CLOSED\n",
    "        self.failure_count = 0\n",
    "        self.success_count = 0\n",
    "        self.last_failure_time = None\n",
    "        self.half_open_calls = 0\n",
    "    \n",
    "    def call(self, func: Callable, *args, **kwargs) -> Any:\n",
    "        \"\"\"Execute function with circuit breaker protection.\"\"\"\n",
    "        # TODO: Implement circuit breaker logic\n",
    "        # 1. Check state\n",
    "        # 2. If OPEN, check if timeout elapsed\n",
    "        # 3. Execute function\n",
    "        # 4. Update state based on result\n",
    "        \n",
    "        # Check if circuit is OPEN\n",
    "        if self.state == CircuitState.OPEN:\n",
    "            # Check if timeout has elapsed\n",
    "            if self.last_failure_time:\n",
    "                elapsed = time.time() - self.last_failure_time\n",
    "                if elapsed >= self.config.timeout_seconds:\n",
    "                    print(f\"  [CIRCUIT] OPEN -> HALF_OPEN (timeout elapsed)\")\n",
    "                    self.state = CircuitState.HALF_OPEN\n",
    "                    self.half_open_calls = 0\n",
    "                else:\n",
    "                    raise Exception(f\"Circuit breaker OPEN (retry in {self.config.timeout_seconds - elapsed:.1f}s)\")\n",
    "            else:\n",
    "                raise Exception(\"Circuit breaker OPEN\")\n",
    "        \n",
    "        # Execute function\n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            self._on_success()\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self._on_failure()\n",
    "            raise\n",
    "    \n",
    "    def _on_success(self):\n",
    "        \"\"\"Handle successful call.\"\"\"\n",
    "        if self.state == CircuitState.HALF_OPEN:\n",
    "            self.half_open_calls += 1\n",
    "            if self.half_open_calls >= self.config.half_open_max_calls:\n",
    "                print(f\"  [CIRCUIT] HALF_OPEN -> CLOSED (recovered)\")\n",
    "                self.state = CircuitState.CLOSED\n",
    "                self.failure_count = 0\n",
    "                self.success_count = 0\n",
    "        \n",
    "        self.success_count += 1\n",
    "    \n",
    "    def _on_failure(self):\n",
    "        \"\"\"Handle failed call.\"\"\"\n",
    "        self.failure_count += 1\n",
    "        self.last_failure_time = time.time()\n",
    "        \n",
    "        if self.state == CircuitState.HALF_OPEN:\n",
    "            print(f\"  [CIRCUIT] HALF_OPEN -> OPEN (failure during recovery)\")\n",
    "            self.state = CircuitState.OPEN\n",
    "        elif self.failure_count >= self.config.failure_threshold:\n",
    "            print(f\"  [CIRCUIT] CLOSED -> OPEN (threshold reached: {self.failure_count})\")\n",
    "            self.state = CircuitState.OPEN\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset circuit breaker.\"\"\"\n",
    "        self.state = CircuitState.CLOSED\n",
    "        self.failure_count = 0\n",
    "        self.success_count = 0\n",
    "        self.last_failure_time = None\n",
    "\n",
    "\n",
    "# Test circuit breaker\n",
    "def flaky_service(should_fail: bool = False):\n",
    "    \"\"\"Mock service that can fail.\"\"\"\n",
    "    if should_fail:\n",
    "        raise Exception(\"Service failure\")\n",
    "    return \"Success\"\n",
    "\n",
    "breaker = CircuitBreaker(CircuitBreakerConfig(failure_threshold=3, timeout_seconds=2))\n",
    "\n",
    "print(\"Testing circuit breaker:\\n\")\n",
    "\n",
    "# Cause failures to open circuit\n",
    "for i in range(5):\n",
    "    try:\n",
    "        result = breaker.call(flaky_service, should_fail=True)\n",
    "        print(f\"Call {i+1}: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Call {i+1}: Failed - {e}\")\n",
    "\n",
    "print(f\"\\nCircuit state: {breaker.state.value}\")\n",
    "print(\"\\nWaiting for timeout...\")\n",
    "time.sleep(2.5)\n",
    "\n",
    "# Try recovery\n",
    "print(\"\\nAttempting recovery:\")\n",
    "for i in range(3):\n",
    "    try:\n",
    "        result = breaker.call(flaky_service, should_fail=False)\n",
    "        print(f\"Recovery call {i+1}: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Recovery call {i+1}: Failed - {e}\")\n",
    "\n",
    "print(f\"\\nFinal circuit state: {breaker.state.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee6fd3f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 6: Feature Flags for A/B Testing\n",
    "\n",
    "**Task:** Implement feature flags to control query rewriting strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4036839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureFlags:\n",
    "    \"\"\"\n",
    "    Feature flag system for A/B testing.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.flags = {}\n",
    "    \n",
    "    def set_flag(self, name: str, enabled: bool, rollout_pct: float = 100.0):\n",
    "        \"\"\"Set a feature flag.\"\"\"\n",
    "        self.flags[name] = {\n",
    "            \"enabled\": enabled,\n",
    "            \"rollout_pct\": rollout_pct,\n",
    "        }\n",
    "    \n",
    "    def is_enabled(self, name: str, user_id: str = None) -> bool:\n",
    "        \"\"\"Check if feature is enabled for user.\"\"\"\n",
    "        # TODO: Implement feature flag check\n",
    "        # 1. Check if flag exists\n",
    "        # 2. If not enabled globally, return False\n",
    "        # 3. Check rollout percentage\n",
    "        \n",
    "        if name not in self.flags:\n",
    "            return False\n",
    "        \n",
    "        flag = self.flags[name]\n",
    "        \n",
    "        if not flag[\"enabled\"]:\n",
    "            return False\n",
    "        \n",
    "        # Check rollout percentage\n",
    "        if user_id and flag[\"rollout_pct\"] < 100.0:\n",
    "            # Hash user_id to get consistent assignment\n",
    "            hash_val = hash(user_id) % 100\n",
    "            return hash_val < flag[\"rollout_pct\"]\n",
    "        \n",
    "        return True\n",
    "\n",
    "\n",
    "def rag_with_flags(query: str, user_id: str, flags: FeatureFlags, k: int = 3) -> Dict:\n",
    "    \"\"\"\n",
    "    RAG retrieval with feature-flagged query rewriting.\n",
    "    \"\"\"\n",
    "    metadata = {\n",
    "        \"query\": query,\n",
    "        \"user_id\": user_id,\n",
    "        \"rewriting_method\": \"baseline\",\n",
    "    }\n",
    "    \n",
    "    # Check feature flags\n",
    "    if flags.is_enabled(\"use_hyde\", user_id):\n",
    "        metadata[\"rewriting_method\"] = \"hyde\"\n",
    "        results = hyde_retrieve(query, k=k)\n",
    "    elif flags.is_enabled(\"use_multi_query\", user_id):\n",
    "        metadata[\"rewriting_method\"] = \"multi_query\"\n",
    "        results = multi_query_retrieve(query, k=k)\n",
    "    elif flags.is_enabled(\"use_step_back\", user_id):\n",
    "        metadata[\"rewriting_method\"] = \"step_back\"\n",
    "        _, results = step_back_retrieve(query, k=k)\n",
    "    else:\n",
    "        results = simple_retrieve(query, k=k)\n",
    "    \n",
    "    return {\n",
    "        \"results\": results,\n",
    "        \"metadata\": metadata,\n",
    "    }\n",
    "\n",
    "\n",
    "# Test feature flags\n",
    "flags = FeatureFlags()\n",
    "flags.set_flag(\"use_hyde\", enabled=True, rollout_pct=50.0)\n",
    "flags.set_flag(\"use_multi_query\", enabled=True, rollout_pct=30.0)\n",
    "\n",
    "print(\"Testing feature flags with different users:\\n\")\n",
    "\n",
    "for user_id in [\"user_1\", \"user_2\", \"user_3\", \"user_4\"]:\n",
    "    result = rag_with_flags(\n",
    "        \"How do I scale containerized applications?\",\n",
    "        user_id,\n",
    "        flags,\n",
    "        k=2\n",
    "    )\n",
    "    method = result[\"metadata\"][\"rewriting_method\"]\n",
    "    print(f\"{user_id}: {method}\")\n",
    "    for doc in result[\"results\"]:\n",
    "        print(f\"  {doc['id']}: {doc['score']:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b20c44c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 7: Structured Logging & Observability\n",
    "\n",
    "**Task:** Add structured JSON logging with trace IDs for observability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b61055",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LogEntry:\n",
    "    \"\"\"Structured log entry.\"\"\"\n",
    "    timestamp: str\n",
    "    trace_id: str\n",
    "    level: str\n",
    "    event: str\n",
    "    metadata: Dict\n",
    "\n",
    "class StructuredLogger:\n",
    "    \"\"\"Logger that outputs structured JSON.\"\"\"\n",
    "    \n",
    "    def log(self, level: str, event: str, trace_id: str, **kwargs):\n",
    "        \"\"\"Log structured event.\"\"\"\n",
    "        entry = LogEntry(\n",
    "            timestamp=datetime.utcnow().isoformat(),\n",
    "            trace_id=trace_id,\n",
    "            level=level,\n",
    "            event=event,\n",
    "            metadata=kwargs,\n",
    "        )\n",
    "        print(json.dumps(asdict(entry)))\n",
    "    \n",
    "    def info(self, event: str, trace_id: str, **kwargs):\n",
    "        self.log(\"INFO\", event, trace_id, **kwargs)\n",
    "    \n",
    "    def error(self, event: str, trace_id: str, **kwargs):\n",
    "        self.log(\"ERROR\", event, trace_id, **kwargs)\n",
    "\n",
    "\n",
    "def production_rag(\n",
    "    query: str,\n",
    "    user_id: str,\n",
    "    flags: FeatureFlags,\n",
    "    breaker: CircuitBreaker,\n",
    "    logger: StructuredLogger,\n",
    "    k: int = 3,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Production RAG with observability.\n",
    "    \"\"\"\n",
    "    trace_id = str(uuid.uuid4())\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Log request start\n",
    "        logger.info(\n",
    "            \"rag_request_start\",\n",
    "            trace_id=trace_id,\n",
    "            user_id=user_id,\n",
    "            query=query,\n",
    "            k=k,\n",
    "        )\n",
    "        \n",
    "        # Execute retrieval with circuit breaker\n",
    "        def retrieve():\n",
    "            return rag_with_flags(query, user_id, flags, k=k)\n",
    "        \n",
    "        result = breaker.call(retrieve)\n",
    "        \n",
    "        # Calculate latency\n",
    "        latency_ms = (time.time() - start_time) * 1000\n",
    "        \n",
    "        # Log success\n",
    "        logger.info(\n",
    "            \"rag_request_complete\",\n",
    "            trace_id=trace_id,\n",
    "            user_id=user_id,\n",
    "            latency_ms=latency_ms,\n",
    "            rewriting_method=result[\"metadata\"][\"rewriting_method\"],\n",
    "            result_count=len(result[\"results\"]),\n",
    "            circuit_state=breaker.state.value,\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            **result,\n",
    "            \"trace_id\": trace_id,\n",
    "            \"latency_ms\": latency_ms,\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Log error\n",
    "        latency_ms = (time.time() - start_time) * 1000\n",
    "        logger.error(\n",
    "            \"rag_request_failed\",\n",
    "            trace_id=trace_id,\n",
    "            user_id=user_id,\n",
    "            latency_ms=latency_ms,\n",
    "            error=str(e),\n",
    "            circuit_state=breaker.state.value,\n",
    "        )\n",
    "        raise\n",
    "\n",
    "\n",
    "# Test production RAG\n",
    "structured_logger = StructuredLogger()\n",
    "production_breaker = CircuitBreaker()\n",
    "production_flags = FeatureFlags()\n",
    "production_flags.set_flag(\"use_hyde\", enabled=True, rollout_pct=50.0)\n",
    "\n",
    "print(\"\\nProduction RAG with observability:\\n\")\n",
    "\n",
    "result = production_rag(\n",
    "    query=\"How do I scale containerized applications?\",\n",
    "    user_id=\"test_user\",\n",
    "    flags=production_flags,\n",
    "    breaker=production_breaker,\n",
    "    logger=structured_logger,\n",
    "    k=3,\n",
    ")\n",
    "\n",
    "print(f\"\\nTrace ID: {result['trace_id']}\")\n",
    "print(f\"Latency: {result['latency_ms']:.2f}ms\")\n",
    "print(f\"Method: {result['metadata']['rewriting_method']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e70e9f4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus Challenge: SLO Monitoring Dashboard\n",
    "\n",
    "**Task:** Simulate multiple requests and calculate SLO metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d08083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class RequestMetrics:\n",
    "    \"\"\"Metrics for a single request.\"\"\"\n",
    "    trace_id: str\n",
    "    success: bool\n",
    "    latency_ms: float\n",
    "    method: str\n",
    "\n",
    "def simulate_traffic(n_requests: int = 50) -> List[RequestMetrics]:\n",
    "    \"\"\"Simulate production traffic.\"\"\"\n",
    "    logger = StructuredLogger()\n",
    "    breaker = CircuitBreaker()\n",
    "    flags = FeatureFlags()\n",
    "    flags.set_flag(\"use_hyde\", enabled=True, rollout_pct=50.0)\n",
    "    \n",
    "    queries = [\n",
    "        \"How do I scale containerized applications?\",\n",
    "        \"What is semantic search?\",\n",
    "        \"How to prevent cascading failures?\",\n",
    "    ]\n",
    "    \n",
    "    metrics = []\n",
    "    \n",
    "    print(\"Simulating production traffic...\\n\")\n",
    "    \n",
    "    for i in range(n_requests):\n",
    "        user_id = f\"user_{i % 10}\"\n",
    "        query = queries[i % len(queries)]\n",
    "        \n",
    "        try:\n",
    "            result = production_rag(\n",
    "                query=query,\n",
    "                user_id=user_id,\n",
    "                flags=flags,\n",
    "                breaker=breaker,\n",
    "                logger=logger,\n",
    "                k=3,\n",
    "            )\n",
    "            \n",
    "            metrics.append(RequestMetrics(\n",
    "                trace_id=result[\"trace_id\"],\n",
    "                success=True,\n",
    "                latency_ms=result[\"latency_ms\"],\n",
    "                method=result[\"metadata\"][\"rewriting_method\"],\n",
    "            ))\n",
    "            \n",
    "        except Exception as e:\n",
    "            metrics.append(RequestMetrics(\n",
    "                trace_id=str(uuid.uuid4()),\n",
    "                success=False,\n",
    "                latency_ms=0.0,\n",
    "                method=\"failed\",\n",
    "            ))\n",
    "        \n",
    "        # Small delay\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processed {i}/{n_requests} requests...\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def calculate_slos(metrics: List[RequestMetrics]) -> Dict:\n",
    "    \"\"\"Calculate SLO metrics.\"\"\"\n",
    "    # TODO: Calculate SLO metrics\n",
    "    # 1. Availability (success rate)\n",
    "    # 2. Latency percentiles (p50, p95, p99)\n",
    "    # 3. Method distribution\n",
    "    \n",
    "    total = len(metrics)\n",
    "    successes = sum(1 for m in metrics if m.success)\n",
    "    \n",
    "    latencies = [m.latency_ms for m in metrics if m.success]\n",
    "    \n",
    "    method_counts = {}\n",
    "    for m in metrics:\n",
    "        method_counts[m.method] = method_counts.get(m.method, 0) + 1\n",
    "    \n",
    "    return {\n",
    "        \"total_requests\": total,\n",
    "        \"successful_requests\": successes,\n",
    "        \"availability_pct\": (successes / total * 100) if total > 0 else 0,\n",
    "        \"latency_p50_ms\": np.percentile(latencies, 50) if latencies else 0,\n",
    "        \"latency_p95_ms\": np.percentile(latencies, 95) if latencies else 0,\n",
    "        \"latency_p99_ms\": np.percentile(latencies, 99) if latencies else 0,\n",
    "        \"method_distribution\": method_counts,\n",
    "    }\n",
    "\n",
    "\n",
    "# Run simulation\n",
    "metrics = simulate_traffic(n_requests=20)  # Use smaller number for demo\n",
    "slos = calculate_slos(metrics)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SLO DASHBOARD\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal Requests: {slos['total_requests']}\")\n",
    "print(f\"Successful: {slos['successful_requests']}\")\n",
    "print(f\"Availability: {slos['availability_pct']:.2f}% (target: 99.9%)\")\n",
    "print(f\"\\nLatency:\")\n",
    "print(f\"  p50: {slos['latency_p50_ms']:.2f}ms\")\n",
    "print(f\"  p95: {slos['latency_p95_ms']:.2f}ms (target: <200ms)\")\n",
    "print(f\"  p99: {slos['latency_p99_ms']:.2f}ms\")\n",
    "print(f\"\\nMethod Distribution:\")\n",
    "for method, count in slos['method_distribution'].items():\n",
    "    pct = (count / slos['total_requests'] * 100)\n",
    "    print(f\"  {method}: {count} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29be0a67",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ‰ Lab Complete!\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "- âœ… Query rewriting with HyDE, Multi-Query, Step-Back\n",
    "- âœ… Comparing rewriting strategies on test queries\n",
    "- âœ… Circuit breaker pattern for resilience\n",
    "- âœ… Feature flags for gradual rollouts and A/B testing\n",
    "- âœ… Structured logging with trace IDs\n",
    "- âœ… SLO monitoring (availability, latency)\n",
    "- âœ… Production-grade RAG implementation\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Query Rewriting** improves recall by 10-30% depending on query type\n",
    "2. **HyDE** works best for conceptual questions\n",
    "3. **Multi-Query** improves coverage for ambiguous queries\n",
    "4. **Step-Back** retrieves better foundational context\n",
    "5. **Circuit Breakers** prevent cascading failures\n",
    "6. **Feature Flags** enable safe experimentation\n",
    "7. **Structured Logging** enables debugging and analysis\n",
    "8. **SLO Monitoring** ensures production reliability\n",
    "\n",
    "### Production Recommendations\n",
    "\n",
    "- Start with baseline, measure performance\n",
    "- A/B test query rewriting methods with feature flags\n",
    "- Set circuit breaker thresholds based on observed error rates\n",
    "- Log all requests with trace IDs for debugging\n",
    "- Monitor SLOs continuously (99.9% availability, p95 < 200ms)\n",
    "- Use gradual rollouts (10% â†’ 50% â†’ 100%)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Integrate with production vector database\n",
    "2. Add distributed tracing (OpenTelemetry)\n",
    "3. Set up alerts for SLO violations\n",
    "4. Implement cost tracking per method\n",
    "5. Create Grafana dashboard for real-time monitoring\n",
    "\n",
    "### Resources\n",
    "\n",
    "- Week 5 Resources: [../resources/README.md](../resources/README.md)\n",
    "- Week 4 Monitoring Guide: [../../week-04/resources/monitoring-production-rag.md](../../week-04/resources/monitoring-production-rag.md)\n",
    "- Evaluation Harness: [../resources/examples/](../resources/examples/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
