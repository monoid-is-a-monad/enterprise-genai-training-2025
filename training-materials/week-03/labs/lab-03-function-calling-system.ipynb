{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e50a6c3",
   "metadata": {},
   "source": [
    "# Lab 3: Function Calling System\n",
    "\n",
    "**Week 3 - Advanced Prompting & OpenAI API**\n",
    "\n",
    "**Provided by:** ADC ENGINEERING & CONSULTING LTD\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab, you will:\n",
    "- Understand OpenAI function calling mechanism\n",
    "- Define function schemas correctly\n",
    "- Implement tool-augmented assistants\n",
    "- Handle function call execution safely\n",
    "- Build multi-tool systems\n",
    "- Chain multiple function calls\n",
    "- Create autonomous agents with tools\n",
    "- Implement error handling for function calls\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Week 3 Labs 1 & 2\n",
    "- Understanding of JSON schemas\n",
    "- Python functions and decorators\n",
    "- OpenAI API key configured\n",
    "- Python 3.9+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bb548a",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d45792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai python-dotenv tiktoken pydantic requests --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b836888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import inspect\n",
    "from typing import List, Dict, Optional, Any, Callable, get_type_hints\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "print(\"✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d524b0",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Function Calling\n",
    "\n",
    "Function calling allows the model to generate structured calls to external tools/APIs.\n",
    "\n",
    "### How It Works:\n",
    "\n",
    "1. **Define functions**: Specify available functions with JSON schemas\n",
    "2. **Send to API**: Include function definitions in the request\n",
    "3. **Model decides**: LLM decides which function(s) to call\n",
    "4. **Execute function**: Your code executes the function\n",
    "5. **Return results**: Send results back to the model\n",
    "6. **Model responds**: LLM incorporates results into response\n",
    "\n",
    "Let's start with a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89112183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location: str, unit: str = \"celsius\") -> dict:\n",
    "    \"\"\"\n",
    "    Get the current weather for a location.\n",
    "    \n",
    "    Args:\n",
    "        location: City name, e.g. \"London\"\n",
    "        unit: Temperature unit (\"celsius\" or \"fahrenheit\")\n",
    "    \n",
    "    Returns:\n",
    "        Weather information\n",
    "    \"\"\"\n",
    "    # This is a mock function - in reality, you'd call a weather API\n",
    "    weather_data = {\n",
    "        \"London\": {\"temperature\": 15, \"condition\": \"cloudy\"},\n",
    "        \"New York\": {\"temperature\": 22, \"condition\": \"sunny\"},\n",
    "        \"Tokyo\": {\"temperature\": 18, \"condition\": \"rainy\"}\n",
    "    }\n",
    "    \n",
    "    location_key = location.split(\",\")[0].strip()\n",
    "    data = weather_data.get(location_key, {\"temperature\": 20, \"condition\": \"unknown\"})\n",
    "    \n",
    "    return {\n",
    "        \"location\": location,\n",
    "        \"temperature\": data[\"temperature\"],\n",
    "        \"unit\": unit,\n",
    "        \"condition\": data[\"condition\"]\n",
    "    }\n",
    "\n",
    "# Define the function schema for OpenAI\n",
    "weather_function = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Test function calling\n",
    "def test_function_calling():\n",
    "    \"\"\"Test basic function calling.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"What's the weather like in London?\"}\n",
    "    ]\n",
    "    \n",
    "    # First API call with function definitions\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        tools=[weather_function],\n",
    "        tool_choice=\"auto\"  # Let model decide\n",
    "    )\n",
    "    \n",
    "    response_message = response.choices[0].message\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"BASIC FUNCTION CALLING\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nUser: {messages[0]['content']}\")\n",
    "    \n",
    "    # Check if model wants to call a function\n",
    "    if response_message.tool_calls:\n",
    "        print(f\"\\nModel wants to call function: {response_message.tool_calls[0].function.name}\")\n",
    "        \n",
    "        # Execute the function\n",
    "        tool_call = response_message.tool_calls[0]\n",
    "        function_name = tool_call.function.name\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        print(f\"Function arguments: {function_args}\")\n",
    "        \n",
    "        # Call the actual function\n",
    "        function_response = get_current_weather(**function_args)\n",
    "        print(f\"Function result: {function_response}\")\n",
    "        \n",
    "        # Add function result to messages\n",
    "        messages.append(response_message)\n",
    "        messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"content\": json.dumps(function_response)\n",
    "        })\n",
    "        \n",
    "        # Second API call with function result\n",
    "        final_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nFinal response: {final_response.choices[0].message.content}\")\n",
    "    else:\n",
    "        print(f\"\\nDirect response: {response_message.content}\")\n",
    "\n",
    "test_function_calling()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ab8ee3",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Create Your First Function\n",
    "\n",
    "Define and test a simple function with the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d44ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a function and its schema\n",
    "\n",
    "def calculate_tip(bill_amount: float, tip_percentage: float = 15.0) -> dict:\n",
    "    \"\"\"\n",
    "    TODO: Implement tip calculator\n",
    "    \n",
    "    Args:\n",
    "        bill_amount: Total bill amount\n",
    "        tip_percentage: Tip percentage (default 15%)\n",
    "    \n",
    "    Returns:\n",
    "        Dict with tip amount and total\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# TODO: Define the function schema\n",
    "tip_calculator_function = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"calculate_tip\",\n",
    "        \"description\": \"Calculate tip amount and total bill\",\n",
    "        \"parameters\": {\n",
    "            # TODO: Add parameters schema\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# TODO: Test your function\n",
    "# messages = [{\"role\": \"user\", \"content\": \"Calculate a 20% tip on a $50 bill\"}]\n",
    "# response = client.chat.completions.create(\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=messages,\n",
    "#     tools=[tip_calculator_function],\n",
    "#     tool_choice=\"auto\"\n",
    "# )\n",
    "# Process the response and execute function..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a889e5",
   "metadata": {},
   "source": [
    "## Part 2: Function Schema Builder\n",
    "\n",
    "Automatically generate function schemas from Python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accf4350",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionSchemaBuilder:\n",
    "    \"\"\"\n",
    "    Automatically build OpenAI function schemas from Python functions.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def python_type_to_json_type(py_type: type) -> str:\n",
    "        \"\"\"Convert Python type to JSON schema type.\"\"\"\n",
    "        type_mapping = {\n",
    "            str: \"string\",\n",
    "            int: \"integer\",\n",
    "            float: \"number\",\n",
    "            bool: \"boolean\",\n",
    "            list: \"array\",\n",
    "            dict: \"object\"\n",
    "        }\n",
    "        return type_mapping.get(py_type, \"string\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_schema(func: Callable) -> dict:\n",
    "        \"\"\"\n",
    "        Build OpenAI function schema from Python function.\n",
    "        \n",
    "        Args:\n",
    "            func: Python function to convert\n",
    "        \n",
    "        Returns:\n",
    "            OpenAI function schema\n",
    "        \"\"\"\n",
    "        # Get function signature\n",
    "        sig = inspect.signature(func)\n",
    "        type_hints = get_type_hints(func)\n",
    "        \n",
    "        # Extract docstring\n",
    "        doc = inspect.getdoc(func) or \"\"\n",
    "        \n",
    "        # Build parameters schema\n",
    "        properties = {}\n",
    "        required = []\n",
    "        \n",
    "        for param_name, param in sig.parameters.items():\n",
    "            if param_name == \"self\":\n",
    "                continue\n",
    "                \n",
    "            param_type = type_hints.get(param_name, str)\n",
    "            \n",
    "            # Get origin type for generics like List[str]\n",
    "            origin_type = getattr(param_type, \"__origin__\", param_type)\n",
    "            \n",
    "            param_schema = {\n",
    "                \"type\": FunctionSchemaBuilder.python_type_to_json_type(origin_type)\n",
    "            }\n",
    "            \n",
    "            # Try to extract description from docstring\n",
    "            # (Simple extraction - could be more sophisticated)\n",
    "            if param_name in doc:\n",
    "                lines = doc.split(\"\\n\")\n",
    "                for i, line in enumerate(lines):\n",
    "                    if param_name in line and \":\" in line:\n",
    "                        desc = line.split(\":\", 1)[1].strip()\n",
    "                        param_schema[\"description\"] = desc\n",
    "                        break\n",
    "            \n",
    "            properties[param_name] = param_schema\n",
    "            \n",
    "            # Check if parameter is required (no default value)\n",
    "            if param.default == inspect.Parameter.empty:\n",
    "                required.append(param_name)\n",
    "        \n",
    "        # Build complete schema\n",
    "        schema = {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": func.__name__,\n",
    "                \"description\": doc.split(\"\\n\\n\")[0] if doc else func.__name__,\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": properties,\n",
    "                    \"required\": required\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return schema\n",
    "\n",
    "# Test the schema builder\n",
    "def search_database(query: str, limit: int = 10, include_metadata: bool = False) -> list:\n",
    "    \"\"\"\n",
    "    Search the database for matching records.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query string\n",
    "        limit: Maximum number of results to return\n",
    "        include_metadata: Whether to include metadata in results\n",
    "    \n",
    "    Returns:\n",
    "        List of matching records\n",
    "    \"\"\"\n",
    "    # Mock implementation\n",
    "    return [{\"id\": i, \"text\": f\"Result {i} for '{query}'\"} for i in range(min(limit, 3))]\n",
    "\n",
    "# Build schema automatically\n",
    "schema = FunctionSchemaBuilder.build_schema(search_database)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AUTO-GENERATED FUNCTION SCHEMA\")\n",
    "print(\"=\"*80)\n",
    "print(json.dumps(schema, indent=2))\n",
    "\n",
    "# Test it works\n",
    "messages = [{\"role\": \"user\", \"content\": \"Search for 'Python tutorials' in the database, limit to 5 results\"}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    tools=[schema],\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "if response.choices[0].message.tool_calls:\n",
    "    tool_call = response.choices[0].message.tool_calls[0]\n",
    "    print(f\"\\n✓ Model called function: {tool_call.function.name}\")\n",
    "    print(f\"✓ Arguments: {tool_call.function.arguments}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ad4287",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Build Schemas for Multiple Functions\n",
    "\n",
    "Use the schema builder for a set of utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ffa41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create utility functions and auto-generate their schemas\n",
    "\n",
    "def convert_currency(amount: float, from_currency: str, to_currency: str) -> dict:\n",
    "    \"\"\"\n",
    "    TODO: Convert amount from one currency to another\n",
    "    \n",
    "    Args:\n",
    "        amount: Amount to convert\n",
    "        from_currency: Source currency code (e.g., USD)\n",
    "        to_currency: Target currency code (e.g., EUR)\n",
    "    \n",
    "    Returns:\n",
    "        Conversion result\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def calculate_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> dict:\n",
    "    \"\"\"\n",
    "    TODO: Calculate distance between two coordinates\n",
    "    \n",
    "    Args:\n",
    "        lat1: Latitude of first point\n",
    "        lon1: Longitude of first point\n",
    "        lat2: Latitude of second point\n",
    "        lon2: Longitude of second point\n",
    "    \n",
    "    Returns:\n",
    "        Distance in kilometers\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# TODO: Generate schemas\n",
    "# builder = FunctionSchemaBuilder()\n",
    "# currency_schema = builder.build_schema(convert_currency)\n",
    "# distance_schema = builder.build_schema(calculate_distance)\n",
    "\n",
    "# TODO: Test with the API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f240b4d0",
   "metadata": {},
   "source": [
    "## Part 3: Function Registry and Executor\n",
    "\n",
    "Build a system to register and execute functions safely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c94dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionRegistry:\n",
    "    \"\"\"\n",
    "    Registry for managing callable functions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize function registry.\"\"\"\n",
    "        self.functions: Dict[str, Callable] = {}\n",
    "        self.schemas: List[dict] = []\n",
    "    \n",
    "    def register(self, func: Callable, schema: Optional[dict] = None):\n",
    "        \"\"\"\n",
    "        Register a function.\n",
    "        \n",
    "        Args:\n",
    "            func: Function to register\n",
    "            schema: Optional pre-built schema (will auto-generate if not provided)\n",
    "        \"\"\"\n",
    "        func_name = func.__name__\n",
    "        self.functions[func_name] = func\n",
    "        \n",
    "        # Generate schema if not provided\n",
    "        if schema is None:\n",
    "            schema = FunctionSchemaBuilder.build_schema(func)\n",
    "        \n",
    "        self.schemas.append(schema)\n",
    "        print(f\"✓ Registered function: {func_name}\")\n",
    "    \n",
    "    def get_function(self, name: str) -> Optional[Callable]:\n",
    "        \"\"\"Get function by name.\"\"\"\n",
    "        return self.functions.get(name)\n",
    "    \n",
    "    def get_schemas(self) -> List[dict]:\n",
    "        \"\"\"Get all function schemas.\"\"\"\n",
    "        return self.schemas\n",
    "    \n",
    "    def execute(self, function_name: str, arguments: dict) -> Any:\n",
    "        \"\"\"\n",
    "        Execute a registered function safely.\n",
    "        \n",
    "        Args:\n",
    "            function_name: Name of function to execute\n",
    "            arguments: Function arguments\n",
    "        \n",
    "        Returns:\n",
    "            Function result\n",
    "        \"\"\"\n",
    "        func = self.get_function(function_name)\n",
    "        \n",
    "        if func is None:\n",
    "            raise ValueError(f\"Function '{function_name}' not found in registry\")\n",
    "        \n",
    "        try:\n",
    "            result = func(**arguments)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"error\": str(e),\n",
    "                \"function\": function_name,\n",
    "                \"arguments\": arguments\n",
    "            }\n",
    "\n",
    "class FunctionCallingAgent:\n",
    "    \"\"\"\n",
    "    Agent that can call functions to answer questions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        registry: FunctionRegistry,\n",
    "        model: str = \"gpt-3.5-turbo\",\n",
    "        max_iterations: int = 5\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize agent.\n",
    "        \n",
    "        Args:\n",
    "            registry: Function registry\n",
    "            model: OpenAI model to use\n",
    "            max_iterations: Max function calling iterations\n",
    "        \"\"\"\n",
    "        self.registry = registry\n",
    "        self.model = model\n",
    "        self.max_iterations = max_iterations\n",
    "    \n",
    "    def chat(self, user_message: str, verbose: bool = True) -> str:\n",
    "        \"\"\"\n",
    "        Chat with the agent, allowing function calls.\n",
    "        \n",
    "        Args:\n",
    "            user_message: User's message\n",
    "            verbose: Print intermediate steps\n",
    "        \n",
    "        Returns:\n",
    "            Agent's response\n",
    "        \"\"\"\n",
    "        messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"User: {user_message}\")\n",
    "            print(f\"{'='*80}\")\n",
    "        \n",
    "        for iteration in range(self.max_iterations):\n",
    "            response = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                tools=self.registry.get_schemas(),\n",
    "                tool_choice=\"auto\"\n",
    "            )\n",
    "            \n",
    "            response_message = response.choices[0].message\n",
    "            \n",
    "            # Check if model wants to call functions\n",
    "            if not response_message.tool_calls:\n",
    "                # No more function calls, return response\n",
    "                if verbose:\n",
    "                    print(f\"\\nAgent: {response_message.content}\")\n",
    "                return response_message.content\n",
    "            \n",
    "            # Process function calls\n",
    "            messages.append(response_message)\n",
    "            \n",
    "            for tool_call in response_message.tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"\\n🔧 Calling: {function_name}({json.dumps(function_args)})\")\n",
    "                \n",
    "                # Execute function\n",
    "                function_result = self.registry.execute(function_name, function_args)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"📊 Result: {function_result}\")\n",
    "                \n",
    "                # Add function result to messages\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": json.dumps(function_result)\n",
    "                })\n",
    "        \n",
    "        # Max iterations reached\n",
    "        return \"I apologize, but I couldn't complete the task within the allowed steps.\"\n",
    "\n",
    "# Test the system\n",
    "registry = FunctionRegistry()\n",
    "\n",
    "# Register functions\n",
    "registry.register(get_current_weather)\n",
    "registry.register(search_database)\n",
    "\n",
    "# Create agent\n",
    "agent = FunctionCallingAgent(registry)\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"What's the weather in Tokyo?\",\n",
    "    \"Search the database for 'machine learning' topics\",\n",
    "    \"What's the weather in New York and can you search for 'weather data' in the database?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    response = agent.chat(query, verbose=True)\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a72fa",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Build a Multi-Function Agent\n",
    "\n",
    "Create an agent with multiple tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b1bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create multiple utility functions and build an agent\n",
    "\n",
    "def get_current_time(timezone: str = \"UTC\") -> dict:\n",
    "    \"\"\"\n",
    "    TODO: Get current time in a timezone\n",
    "    \n",
    "    Args:\n",
    "        timezone: Timezone name (e.g., \"UTC\", \"America/New_York\")\n",
    "    \n",
    "    Returns:\n",
    "        Current time information\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def calculate_mortgage(\n",
    "    principal: float,\n",
    "    annual_rate: float,\n",
    "    years: int\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    TODO: Calculate monthly mortgage payment\n",
    "    \n",
    "    Args:\n",
    "        principal: Loan amount\n",
    "        annual_rate: Annual interest rate (as percentage, e.g., 3.5)\n",
    "        years: Loan term in years\n",
    "    \n",
    "    Returns:\n",
    "        Payment calculation\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def translate_text(text: str, target_language: str) -> dict:\n",
    "    \"\"\"\n",
    "    TODO: Translate text to target language (mock)\n",
    "    \n",
    "    Args:\n",
    "        text: Text to translate\n",
    "        target_language: Target language code (e.g., \"es\", \"fr\")\n",
    "    \n",
    "    Returns:\n",
    "        Translation result\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# TODO: Register functions and create agent\n",
    "# my_registry = FunctionRegistry()\n",
    "# my_registry.register(get_current_time)\n",
    "# my_registry.register(calculate_mortgage)\n",
    "# my_registry.register(translate_text)\n",
    "\n",
    "# my_agent = FunctionCallingAgent(my_registry)\n",
    "\n",
    "# TODO: Test with complex queries\n",
    "# response = my_agent.chat(\"What time is it in Tokyo and translate 'Hello' to Spanish?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab0ad0",
   "metadata": {},
   "source": [
    "## Part 4: Advanced Function Patterns\n",
    "\n",
    "Implement advanced patterns like parallel calls and chained execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FunctionCallResult:\n",
    "    \"\"\"Result of a function call.\"\"\"\n",
    "    function_name: str\n",
    "    arguments: dict\n",
    "    result: Any\n",
    "    success: bool\n",
    "    error: Optional[str] = None\n",
    "    execution_time: float = 0.0\n",
    "\n",
    "class AdvancedFunctionAgent:\n",
    "    \"\"\"\n",
    "    Advanced agent with parallel execution and chaining.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        registry: FunctionRegistry,\n",
    "        model: str = \"gpt-3.5-turbo\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize advanced agent.\n",
    "        \n",
    "        Args:\n",
    "            registry: Function registry\n",
    "            model: OpenAI model to use\n",
    "        \"\"\"\n",
    "        self.registry = registry\n",
    "        self.model = model\n",
    "        self.call_history: List[FunctionCallResult] = []\n",
    "    \n",
    "    def execute_parallel(\n",
    "        self,\n",
    "        function_calls: List[tuple[str, dict]]\n",
    "    ) -> List[FunctionCallResult]:\n",
    "        \"\"\"\n",
    "        Execute multiple function calls in parallel.\n",
    "        \n",
    "        Args:\n",
    "            function_calls: List of (function_name, arguments) tuples\n",
    "        \n",
    "        Returns:\n",
    "            List of results\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for func_name, args in function_calls:\n",
    "            import time\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                result = self.registry.execute(func_name, args)\n",
    "                success = True\n",
    "                error = None\n",
    "            except Exception as e:\n",
    "                result = None\n",
    "                success = False\n",
    "                error = str(e)\n",
    "            \n",
    "            execution_time = time.time() - start_time\n",
    "            \n",
    "            call_result = FunctionCallResult(\n",
    "                function_name=func_name,\n",
    "                arguments=args,\n",
    "                result=result,\n",
    "                success=success,\n",
    "                error=error,\n",
    "                execution_time=execution_time\n",
    "            )\n",
    "            \n",
    "            results.append(call_result)\n",
    "            self.call_history.append(call_result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def chat_with_parallel_execution(\n",
    "        self,\n",
    "        user_message: str,\n",
    "        max_iterations: int = 5,\n",
    "        verbose: bool = True\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Chat with parallel function execution support.\n",
    "        \n",
    "        Args:\n",
    "            user_message: User's message\n",
    "            max_iterations: Max iterations\n",
    "            verbose: Print steps\n",
    "        \n",
    "        Returns:\n",
    "            Agent's response\n",
    "        \"\"\"\n",
    "        messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"User: {user_message}\")\n",
    "            print(f\"{'='*80}\")\n",
    "        \n",
    "        for iteration in range(max_iterations):\n",
    "            response = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                tools=self.registry.get_schemas(),\n",
    "                tool_choice=\"auto\"\n",
    "            )\n",
    "            \n",
    "            response_message = response.choices[0].message\n",
    "            \n",
    "            if not response_message.tool_calls:\n",
    "                if verbose:\n",
    "                    print(f\"\\nAgent: {response_message.content}\")\n",
    "                return response_message.content\n",
    "            \n",
    "            messages.append(response_message)\n",
    "            \n",
    "            # Collect all function calls for parallel execution\n",
    "            function_calls = []\n",
    "            for tool_call in response_message.tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                function_calls.append((function_name, function_args))\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\n🚀 Executing {len(function_calls)} function(s) in parallel...\")\n",
    "            \n",
    "            # Execute all functions in parallel\n",
    "            results = self.execute_parallel(function_calls)\n",
    "            \n",
    "            # Add results back to messages\n",
    "            for tool_call, result in zip(response_message.tool_calls, results):\n",
    "                if verbose:\n",
    "                    status = \"✓\" if result.success else \"✗\"\n",
    "                    print(f\"{status} {result.function_name}: {result.result} ({result.execution_time:.3f}s)\")\n",
    "                \n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": json.dumps(result.result if result.success else {\"error\": result.error})\n",
    "                })\n",
    "        \n",
    "        return \"Maximum iterations reached.\"\n",
    "    \n",
    "    def get_execution_stats(self) -> dict:\n",
    "        \"\"\"Get statistics about function executions.\"\"\"\n",
    "        if not self.call_history:\n",
    "            return {\"message\": \"No function calls yet\"}\n",
    "        \n",
    "        total_calls = len(self.call_history)\n",
    "        successful = sum(1 for call in self.call_history if call.success)\n",
    "        failed = total_calls - successful\n",
    "        \n",
    "        total_time = sum(call.execution_time for call in self.call_history)\n",
    "        avg_time = total_time / total_calls\n",
    "        \n",
    "        # Function usage\n",
    "        from collections import Counter\n",
    "        function_counts = Counter(call.function_name for call in self.call_history)\n",
    "        \n",
    "        return {\n",
    "            \"total_calls\": total_calls,\n",
    "            \"successful\": successful,\n",
    "            \"failed\": failed,\n",
    "            \"success_rate\": f\"{(successful/total_calls*100):.1f}%\",\n",
    "            \"total_execution_time\": f\"{total_time:.3f}s\",\n",
    "            \"avg_execution_time\": f\"{avg_time:.3f}s\",\n",
    "            \"function_usage\": dict(function_counts)\n",
    "        }\n",
    "\n",
    "# Test advanced agent\n",
    "advanced_registry = FunctionRegistry()\n",
    "advanced_registry.register(get_current_weather)\n",
    "advanced_registry.register(search_database)\n",
    "\n",
    "advanced_agent = AdvancedFunctionAgent(advanced_registry)\n",
    "\n",
    "# Test with query requiring multiple function calls\n",
    "query = \"What's the weather in London, New York, and Tokyo? Also search the database for 'weather patterns'.\"\n",
    "response = advanced_agent.chat_with_parallel_execution(query, verbose=True)\n",
    "\n",
    "# Get execution stats\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXECUTION STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "stats = advanced_agent.get_execution_stats()\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d961ec",
   "metadata": {},
   "source": [
    "### Exercise 4.1: Implement Function Chaining\n",
    "\n",
    "Build a system where one function's output feeds into another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3721f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement function chaining\n",
    "\n",
    "class FunctionChain:\n",
    "    \"\"\"\n",
    "    Execute functions in sequence, passing outputs as inputs.\n",
    "    \n",
    "    TODO: Implement:\n",
    "    1. Define chain of functions\n",
    "    2. Execute in sequence\n",
    "    3. Pass outputs to next function\n",
    "    4. Handle errors in chain\n",
    "    5. Support conditional execution\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, registry: FunctionRegistry):\n",
    "        \"\"\"\n",
    "        Initialize chain.\n",
    "        \n",
    "        Args:\n",
    "            registry: Function registry\n",
    "        \"\"\"\n",
    "        self.registry = registry\n",
    "        self.steps: List[dict] = []\n",
    "    \n",
    "    def add_step(\n",
    "        self,\n",
    "        function_name: str,\n",
    "        arguments: dict,\n",
    "        output_mapping: Optional[dict] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        TODO: Add a step to the chain.\n",
    "        \n",
    "        Args:\n",
    "            function_name: Function to call\n",
    "            arguments: Function arguments (can reference previous outputs)\n",
    "            output_mapping: How to map output to next step's input\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def execute(self, initial_input: dict) -> dict:\n",
    "        \"\"\"\n",
    "        TODO: Execute the entire chain.\n",
    "        \n",
    "        Args:\n",
    "            initial_input: Initial input data\n",
    "        \n",
    "        Returns:\n",
    "            Final result\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "# Usage example:\n",
    "# chain = FunctionChain(registry)\n",
    "# chain.add_step(\"get_current_weather\", {\"location\": \"London\"})\n",
    "# chain.add_step(\"search_database\", {\"query\": \"{previous.condition}\"})  # Use previous result\n",
    "# result = chain.execute({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb137780",
   "metadata": {},
   "source": [
    "## Part 5: Error Handling and Validation\n",
    "\n",
    "Robust error handling for function calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd3834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafeFunctionRegistry(FunctionRegistry):\n",
    "    \"\"\"\n",
    "    Function registry with validation and error handling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize safe registry.\"\"\"\n",
    "        super().__init__()\n",
    "        self.validators: Dict[str, Callable] = {}\n",
    "    \n",
    "    def register_with_validator(\n",
    "        self,\n",
    "        func: Callable,\n",
    "        validator: Optional[Callable] = None,\n",
    "        schema: Optional[dict] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Register function with optional validator.\n",
    "        \n",
    "        Args:\n",
    "            func: Function to register\n",
    "            validator: Function to validate arguments before execution\n",
    "            schema: Optional pre-built schema\n",
    "        \"\"\"\n",
    "        self.register(func, schema)\n",
    "        \n",
    "        if validator:\n",
    "            self.validators[func.__name__] = validator\n",
    "    \n",
    "    def validate_arguments(\n",
    "        self,\n",
    "        function_name: str,\n",
    "        arguments: dict\n",
    "    ) -> tuple[bool, Optional[str]]:\n",
    "        \"\"\"\n",
    "        Validate function arguments.\n",
    "        \n",
    "        Args:\n",
    "            function_name: Function name\n",
    "            arguments: Arguments to validate\n",
    "        \n",
    "        Returns:\n",
    "            (is_valid, error_message)\n",
    "        \"\"\"\n",
    "        validator = self.validators.get(function_name)\n",
    "        \n",
    "        if validator is None:\n",
    "            return True, None\n",
    "        \n",
    "        try:\n",
    "            validator(arguments)\n",
    "            return True, None\n",
    "        except Exception as e:\n",
    "            return False, str(e)\n",
    "    \n",
    "    def execute(self, function_name: str, arguments: dict) -> Any:\n",
    "        \"\"\"\n",
    "        Execute function with validation.\n",
    "        \n",
    "        Args:\n",
    "            function_name: Function name\n",
    "            arguments: Function arguments\n",
    "        \n",
    "        Returns:\n",
    "            Function result or error\n",
    "        \"\"\"\n",
    "        # Validate arguments first\n",
    "        is_valid, error_msg = self.validate_arguments(function_name, arguments)\n",
    "        \n",
    "        if not is_valid:\n",
    "            return {\n",
    "                \"error\": f\"Validation failed: {error_msg}\",\n",
    "                \"function\": function_name,\n",
    "                \"arguments\": arguments\n",
    "            }\n",
    "        \n",
    "        # Execute with error handling\n",
    "        return super().execute(function_name, arguments)\n",
    "\n",
    "# Example validators\n",
    "def validate_weather_args(args: dict):\n",
    "    \"\"\"Validate weather function arguments.\"\"\"\n",
    "    location = args.get(\"location\", \"\")\n",
    "    if len(location) < 2:\n",
    "        raise ValueError(\"Location must be at least 2 characters\")\n",
    "    \n",
    "    unit = args.get(\"unit\", \"celsius\")\n",
    "    if unit not in [\"celsius\", \"fahrenheit\"]:\n",
    "        raise ValueError(f\"Invalid unit: {unit}\")\n",
    "\n",
    "def validate_search_args(args: dict):\n",
    "    \"\"\"Validate search function arguments.\"\"\"\n",
    "    query = args.get(\"query\", \"\")\n",
    "    if len(query) < 3:\n",
    "        raise ValueError(\"Query must be at least 3 characters\")\n",
    "    \n",
    "    limit = args.get(\"limit\", 10)\n",
    "    if not isinstance(limit, int) or limit < 1 or limit > 100:\n",
    "        raise ValueError(\"Limit must be between 1 and 100\")\n",
    "\n",
    "# Test safe registry\n",
    "safe_registry = SafeFunctionRegistry()\n",
    "safe_registry.register_with_validator(\n",
    "    get_current_weather,\n",
    "    validator=validate_weather_args\n",
    ")\n",
    "safe_registry.register_with_validator(\n",
    "    search_database,\n",
    "    validator=validate_search_args\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SAFE FUNCTION EXECUTION WITH VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test valid call\n",
    "print(\"\\n✓ Valid call:\")\n",
    "result = safe_registry.execute(\"get_current_weather\", {\"location\": \"London\", \"unit\": \"celsius\"})\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "# Test invalid call\n",
    "print(\"\\n✗ Invalid call (bad unit):\")\n",
    "result = safe_registry.execute(\"get_current_weather\", {\"location\": \"London\", \"unit\": \"kelvin\"})\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "# Test with agent\n",
    "safe_agent = FunctionCallingAgent(safe_registry)\n",
    "response = safe_agent.chat(\"What's the weather in X?\", verbose=True)  # Should fail validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27d983d",
   "metadata": {},
   "source": [
    "### Exercise 5.1: Build Comprehensive Validation\n",
    "\n",
    "Create validators for complex function arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d1e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create functions with comprehensive validation\n",
    "\n",
    "def book_flight(\n",
    "    origin: str,\n",
    "    destination: str,\n",
    "    date: str,\n",
    "    passengers: int,\n",
    "    class_type: str = \"economy\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    TODO: Book a flight (mock)\n",
    "    \n",
    "    Args:\n",
    "        origin: Origin airport code (3 letters)\n",
    "        destination: Destination airport code (3 letters)\n",
    "        date: Flight date (YYYY-MM-DD)\n",
    "        passengers: Number of passengers (1-9)\n",
    "        class_type: Seat class (economy/business/first)\n",
    "    \n",
    "    Returns:\n",
    "        Booking confirmation\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def validate_flight_booking(args: dict):\n",
    "    \"\"\"\n",
    "    TODO: Validate flight booking arguments\n",
    "    \n",
    "    Should check:\n",
    "    - Airport codes are 3 uppercase letters\n",
    "    - Date format is correct and in future\n",
    "    - Passengers between 1-9\n",
    "    - Class type is valid\n",
    "    - Origin != destination\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# TODO: Register with validation and test\n",
    "# safe_registry = SafeFunctionRegistry()\n",
    "# safe_registry.register_with_validator(book_flight, validate_flight_booking)\n",
    "\n",
    "# Test with various inputs (valid and invalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107e2c9a",
   "metadata": {},
   "source": [
    "## Part 6: Building an Autonomous Agent\n",
    "\n",
    "Create an agent that can use tools to solve complex tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b95b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutonomousAgent:\n",
    "    \"\"\"\n",
    "    Autonomous agent that can plan and execute multi-step tasks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        registry: FunctionRegistry,\n",
    "        model: str = \"gpt-4\",  # Better reasoning with GPT-4\n",
    "        max_steps: int = 10\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize autonomous agent.\n",
    "        \n",
    "        Args:\n",
    "            registry: Function registry\n",
    "            model: OpenAI model to use\n",
    "            max_steps: Maximum steps to take\n",
    "        \"\"\"\n",
    "        self.registry = registry\n",
    "        self.model = model\n",
    "        self.max_steps = max_steps\n",
    "        self.conversation_history: List[dict] = []\n",
    "    \n",
    "    def solve_task(\n",
    "        self,\n",
    "        task: str,\n",
    "        verbose: bool = True\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Solve a complex task autonomously.\n",
    "        \n",
    "        Args:\n",
    "            task: Task description\n",
    "            verbose: Print reasoning steps\n",
    "        \n",
    "        Returns:\n",
    "            Solution with execution trace\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"🎯 TASK: {task}\")\n",
    "            print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        # System message for autonomous behavior\n",
    "        system_message = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are an autonomous agent capable of using tools to solve tasks.\n",
    "            \n",
    "For each step:\n",
    "1. Analyze what information you need\n",
    "2. Decide which tool(s) to use\n",
    "3. Execute the tool(s)\n",
    "4. Review the results\n",
    "5. Determine if task is complete or continue\n",
    "\n",
    "Be methodical and explain your reasoning.\"\"\"\n",
    "        }\n",
    "        \n",
    "        self.conversation_history = [\n",
    "            system_message,\n",
    "            {\"role\": \"user\", \"content\": task}\n",
    "        ]\n",
    "        \n",
    "        steps_taken = []\n",
    "        \n",
    "        for step_num in range(1, self.max_steps + 1):\n",
    "            if verbose:\n",
    "                print(f\"📍 Step {step_num}/{self.max_steps}\")\n",
    "                print(\"-\" * 80)\n",
    "            \n",
    "            # Get model's decision\n",
    "            response = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=self.conversation_history,\n",
    "                tools=self.registry.get_schemas(),\n",
    "                tool_choice=\"auto\"\n",
    "            )\n",
    "            \n",
    "            response_message = response.choices[0].message\n",
    "            \n",
    "            # Check if task is complete\n",
    "            if not response_message.tool_calls:\n",
    "                if verbose:\n",
    "                    print(f\"\\n✅ Task Complete!\")\n",
    "                    print(f\"Final Answer: {response_message.content}\\n\")\n",
    "                \n",
    "                return {\n",
    "                    \"success\": True,\n",
    "                    \"steps_taken\": step_num,\n",
    "                    \"final_answer\": response_message.content,\n",
    "                    \"execution_trace\": steps_taken\n",
    "                }\n",
    "            \n",
    "            # Execute tool calls\n",
    "            self.conversation_history.append(response_message)\n",
    "            \n",
    "            for tool_call in response_message.tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"🔧 Using tool: {function_name}\")\n",
    "                    print(f\"   Arguments: {json.dumps(function_args, indent=2)}\")\n",
    "                \n",
    "                # Execute function\n",
    "                try:\n",
    "                    result = self.registry.execute(function_name, function_args)\n",
    "                    success = True\n",
    "                except Exception as e:\n",
    "                    result = {\"error\": str(e)}\n",
    "                    success = False\n",
    "                \n",
    "                if verbose:\n",
    "                    status = \"✓\" if success else \"✗\"\n",
    "                    print(f\"{status} Result: {result}\\n\")\n",
    "                \n",
    "                # Record step\n",
    "                steps_taken.append({\n",
    "                    \"step\": step_num,\n",
    "                    \"function\": function_name,\n",
    "                    \"arguments\": function_args,\n",
    "                    \"result\": result,\n",
    "                    \"success\": success\n",
    "                })\n",
    "                \n",
    "                # Add result to conversation\n",
    "                self.conversation_history.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": json.dumps(result)\n",
    "                })\n",
    "        \n",
    "        # Max steps reached\n",
    "        if verbose:\n",
    "            print(f\"\\n⚠️  Maximum steps ({self.max_steps}) reached without completion\\n\")\n",
    "        \n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"steps_taken\": self.max_steps,\n",
    "            \"final_answer\": \"Task not completed within step limit\",\n",
    "            \"execution_trace\": steps_taken\n",
    "        }\n",
    "\n",
    "# Create tools for the autonomous agent\n",
    "def get_stock_price(symbol: str) -> dict:\n",
    "    \"\"\"Get current stock price (mock).\"\"\"\n",
    "    # Mock data\n",
    "    prices = {\n",
    "        \"AAPL\": 175.50,\n",
    "        \"GOOGL\": 140.25,\n",
    "        \"MSFT\": 380.75,\n",
    "        \"TSLA\": 245.30\n",
    "    }\n",
    "    return {\n",
    "        \"symbol\": symbol,\n",
    "        \"price\": prices.get(symbol.upper(), 100.0),\n",
    "        \"currency\": \"USD\"\n",
    "    }\n",
    "\n",
    "def calculate_percentage_change(old_value: float, new_value: float) -> dict:\n",
    "    \"\"\"Calculate percentage change.\"\"\"\n",
    "    change = ((new_value - old_value) / old_value) * 100\n",
    "    return {\n",
    "        \"old_value\": old_value,\n",
    "        \"new_value\": new_value,\n",
    "        \"percentage_change\": round(change, 2),\n",
    "        \"direction\": \"up\" if change > 0 else \"down\" if change < 0 else \"unchanged\"\n",
    "    }\n",
    "\n",
    "def calculate_average(numbers: List[float]) -> dict:\n",
    "    \"\"\"Calculate average of numbers.\"\"\"\n",
    "    if not numbers:\n",
    "        return {\"error\": \"Empty list\"}\n",
    "    avg = sum(numbers) / len(numbers)\n",
    "    return {\n",
    "        \"numbers\": numbers,\n",
    "        \"average\": round(avg, 2),\n",
    "        \"count\": len(numbers)\n",
    "    }\n",
    "\n",
    "# Register functions\n",
    "auto_registry = FunctionRegistry()\n",
    "auto_registry.register(get_stock_price)\n",
    "auto_registry.register(calculate_percentage_change)\n",
    "auto_registry.register(calculate_average)\n",
    "auto_registry.register(get_current_weather)\n",
    "\n",
    "# Create autonomous agent\n",
    "auto_agent = AutonomousAgent(auto_registry, model=\"gpt-3.5-turbo\")  # Use gpt-4 for better reasoning\n",
    "\n",
    "# Test with complex task\n",
    "complex_task = \"\"\"\n",
    "Compare the stock prices of Apple (AAPL) and Microsoft (MSFT).\n",
    "Then calculate the average of their prices and tell me which one is performing better.\n",
    "\"\"\"\n",
    "\n",
    "result = auto_agent.solve_task(complex_task, verbose=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TASK SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Success: {result['success']}\")\n",
    "print(f\"Steps taken: {result['steps_taken']}\")\n",
    "print(f\"Final answer: {result['final_answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ee7d6",
   "metadata": {},
   "source": [
    "### Exercise 6.1: Build a Research Assistant\n",
    "\n",
    "Create an autonomous agent that can research topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b62cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build research assistant with these tools\n",
    "\n",
    "def web_search(query: str, num_results: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    TODO: Search the web (mock)\n",
    "    \n",
    "    Args:\n",
    "        query: Search query\n",
    "        num_results: Number of results\n",
    "    \n",
    "    Returns:\n",
    "        Search results\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def extract_key_points(text: str, num_points: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    TODO: Extract key points from text (mock)\n",
    "    \n",
    "    Args:\n",
    "        text: Text to analyze\n",
    "        num_points: Number of key points to extract\n",
    "    \n",
    "    Returns:\n",
    "        Key points\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def summarize_findings(data: List[str]) -> dict:\n",
    "    \"\"\"\n",
    "    TODO: Summarize multiple pieces of information\n",
    "    \n",
    "    Args:\n",
    "        data: List of text to summarize\n",
    "    \n",
    "    Returns:\n",
    "        Summary\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# TODO: Create research assistant agent\n",
    "# research_registry = FunctionRegistry()\n",
    "# research_registry.register(web_search)\n",
    "# research_registry.register(extract_key_points)\n",
    "# research_registry.register(summarize_findings)\n",
    "\n",
    "# research_assistant = AutonomousAgent(research_registry)\n",
    "\n",
    "# TODO: Test with research tasks\n",
    "# task = \"Research the latest developments in quantum computing and summarize the top 3 breakthroughs\"\n",
    "# result = research_assistant.solve_task(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee2c273",
   "metadata": {},
   "source": [
    "## Challenge Projects\n",
    "\n",
    "### Challenge 1: Multi-Agent System\n",
    "\n",
    "Build a system with multiple specialized agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b9487",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAgentSystem:\n",
    "    \"\"\"\n",
    "    System with multiple specialized agents.\n",
    "    \n",
    "    TODO: Implement:\n",
    "    1. Different agents for different domains (research, data analysis, writing)\n",
    "    2. Router agent to delegate tasks\n",
    "    3. Agents can call each other\n",
    "    4. Collaborative problem solving\n",
    "    5. Result synthesis from multiple agents\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize multi-agent system.\"\"\"\n",
    "        self.agents: Dict[str, AutonomousAgent] = {}\n",
    "        self.router = None\n",
    "    \n",
    "    def add_agent(self, name: str, agent: AutonomousAgent):\n",
    "        \"\"\"TODO: Add specialized agent.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def route_task(self, task: str) -> str:\n",
    "        \"\"\"TODO: Route task to appropriate agent.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def solve_collaborative(self, task: str) -> dict:\n",
    "        \"\"\"TODO: Solve task using multiple agents.\"\"\"\n",
    "        pass\n",
    "\n",
    "# Usage example:\n",
    "# system = MultiAgentSystem()\n",
    "# system.add_agent(\"researcher\", research_agent)\n",
    "# system.add_agent(\"analyst\", data_analyst_agent)\n",
    "# system.add_agent(\"writer\", writing_agent)\n",
    "# result = system.solve_collaborative(\"Research AI trends and write a report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85a6b52",
   "metadata": {},
   "source": [
    "### Challenge 2: Function Calling with Memory\n",
    "\n",
    "Build an agent with persistent memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae27a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryAgent:\n",
    "    \"\"\"\n",
    "    Agent with persistent memory of past interactions.\n",
    "    \n",
    "    TODO: Implement:\n",
    "    1. Store conversation history\n",
    "    2. Remember function call results\n",
    "    3. Reference past information in new queries\n",
    "    4. Memory summarization when context grows large\n",
    "    5. Forgetting mechanism for old/irrelevant info\n",
    "    6. Memory search/retrieval\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, registry: FunctionRegistry):\n",
    "        \"\"\"Initialize agent with memory.\"\"\"\n",
    "        self.registry = registry\n",
    "        self.memory = []\n",
    "        self.function_call_cache = {}\n",
    "    \n",
    "    def remember(self, key: str, value: Any):\n",
    "        \"\"\"TODO: Store information in memory.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def recall(self, query: str) -> Any:\n",
    "        \"\"\"TODO: Retrieve information from memory.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def chat_with_memory(self, message: str) -> str:\n",
    "        \"\"\"TODO: Chat using memory.\"\"\"\n",
    "        pass\n",
    "\n",
    "# Usage:\n",
    "# memory_agent = MemoryAgent(registry)\n",
    "# memory_agent.chat_with_memory(\"What's the weather in London?\")\n",
    "# memory_agent.chat_with_memory(\"What was the weather there earlier?\")  # References previous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c2f3be",
   "metadata": {},
   "source": [
    "### Challenge 3: Self-Improving Agent\n",
    "\n",
    "Build an agent that learns from its mistakes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd38348",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfImprovingAgent:\n",
    "    \"\"\"\n",
    "    Agent that learns from execution results.\n",
    "    \n",
    "    TODO: Implement:\n",
    "    1. Track success/failure of function calls\n",
    "    2. Learn which functions work for which tasks\n",
    "    3. Adapt strategy based on past results\n",
    "    4. A/B test different approaches\n",
    "    5. Build knowledge base of solutions\n",
    "    6. Suggest new functions to implement\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, registry: FunctionRegistry):\n",
    "        \"\"\"Initialize self-improving agent.\"\"\"\n",
    "        self.registry = registry\n",
    "        self.performance_history = []\n",
    "        self.learned_strategies = {}\n",
    "    \n",
    "    def record_outcome(self, task: str, strategy: str, success: bool):\n",
    "        \"\"\"TODO: Record task outcome.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def select_strategy(self, task: str) -> str:\n",
    "        \"\"\"TODO: Select best strategy based on learning.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def suggest_new_function(self, failed_task: str) -> dict:\n",
    "        \"\"\"TODO: Suggest function that would help.\"\"\"\n",
    "        pass\n",
    "\n",
    "# Usage:\n",
    "# learning_agent = SelfImprovingAgent(registry)\n",
    "# for task in tasks:\n",
    "#     result = learning_agent.solve_task(task)\n",
    "#     learning_agent.record_outcome(task, result['strategy'], result['success'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc561669",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you've learned:\n",
    "\n",
    "1. ✅ OpenAI function calling fundamentals\n",
    "2. ✅ Automatic function schema generation\n",
    "3. ✅ Function registry and safe execution\n",
    "4. ✅ Advanced patterns (parallel execution, chaining)\n",
    "5. ✅ Comprehensive error handling and validation\n",
    "6. ✅ Building autonomous agents with tools\n",
    "7. ✅ Multi-step task solving\n",
    "8. ✅ Complex agent architectures\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "**Function Calling Benefits:**\n",
    "- Structured outputs from LLMs\n",
    "- Integration with external systems\n",
    "- Deterministic tool usage\n",
    "- Reduced hallucination for factual tasks\n",
    "- Building compound AI systems\n",
    "\n",
    "**Best Practices:**\n",
    "\n",
    "1. **Schema Design:**\n",
    "   - Clear function descriptions\n",
    "   - Detailed parameter descriptions\n",
    "   - Use enums for limited choices\n",
    "   - Mark required parameters\n",
    "   - Provide examples in descriptions\n",
    "\n",
    "2. **Error Handling:**\n",
    "   - Validate arguments before execution\n",
    "   - Catch and report errors gracefully\n",
    "   - Return structured error messages\n",
    "   - Implement retry logic\n",
    "   - Set execution timeouts\n",
    "\n",
    "3. **Safety:**\n",
    "   - Validate all inputs\n",
    "   - Sandbox function execution\n",
    "   - Rate limit function calls\n",
    "   - Log all executions\n",
    "   - Implement authentication/authorization\n",
    "\n",
    "4. **Performance:**\n",
    "   - Execute functions in parallel when possible\n",
    "   - Cache function results\n",
    "   - Set reasonable timeouts\n",
    "   - Monitor execution time\n",
    "   - Limit max iterations\n",
    "\n",
    "### Common Patterns\n",
    "\n",
    "**1. Single Function:** Simple tool use\n",
    "**2. Multiple Functions:** Agent with toolbox\n",
    "**3. Chained Functions:** Output → Input pipeline\n",
    "**4. Parallel Functions:** Multiple simultaneous calls\n",
    "**5. Autonomous Agent:** Self-directed task solving\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Complete the challenge projects\n",
    "- Build your own tool-augmented assistant\n",
    "- Integrate real APIs (weather, database, etc.)\n",
    "- Move on to Week 4: RAG Fundamentals\n",
    "- Experiment with complex multi-agent systems\n",
    "\n",
    "**Provided by:** ADC ENGINEERING & CONSULTING LTD"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
